{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING MODULES\n",
    "import glob\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.signal as ss\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..', '..', 'src'))\n",
    "sys.path.append(module_path)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tools.data_reader_wesad as dr\n",
    "import tools.display_tools as dt\n",
    "import tools.preprocessing as preprocessing\n",
    "\n",
    "from scipy.fft import fft, fftfreq, fftshift\n",
    "\n",
    "import cvxopt.solvers\n",
    "cvxopt.solvers.options['show_progress'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER METHODS\n",
    "import samplerate\n",
    "import scipy\n",
    "\n",
    "def get_time_segments(subject, sr_to_convert=0):\n",
    "    data = dr.get_participant_data(subject)\n",
    "    labels = data[\"label\"]\n",
    "    if sr_to_convert > 0:\n",
    "        step = int(700/sr_to_convert)\n",
    "        resampled = []\n",
    "        for i in range(0, labels.size, step):\n",
    "            resampled.append(labels[i])\n",
    "        labels = np.asarray(resampled)\n",
    "        # labels = samplerate.resample(labels, sr_to_convert/700.0)\n",
    "        # labels = scipy.signal.decimate(labels, int(700.0/sr_to_convert))\n",
    "    curr_value = labels[0]\n",
    "    start_indices = [0]\n",
    "    end_indices = []\n",
    "    i = 1\n",
    "    while i < len(labels):\n",
    "        if labels[i] != curr_value:\n",
    "            end_indices.append(i-1)\n",
    "            start_indices.append(i)\n",
    "            curr_value = labels[i]\n",
    "        i += 1\n",
    "\n",
    "    end_indices.append(len(labels)-1)\n",
    "\n",
    "    time_segments = {}\n",
    "    for i in range(len(start_indices)):\n",
    "        label = labels[start_indices[i]]\n",
    "        if label not in time_segments.keys():\n",
    "            time_segments[label] = [(start_indices[i], end_indices[i])]\n",
    "        else:\n",
    "            time_segments[label].append((start_indices[i], end_indices[i]))\n",
    "    return time_segments\n",
    "\n",
    "\n",
    "# ts = get_time_segments(2)\n",
    "# print(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE SIGNALS INTO INDIVIDUAL CSV FILES\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "importlib.reload(preprocessing)\n",
    "\n",
    "\n",
    "subject_indices = list(range(2, 12)) + list(range(13, 18))\n",
    "subject_indices = [str(i) for i in subject_indices]\n",
    "\n",
    "locations = [dr.WESADKeys.CHEST]\n",
    "# locations = [dr.WESADKeys.WRIST]\n",
    "chest_signals = [\n",
    "    dr.Signals.ACC, dr.Signals.ECG, dr.Signals.EDA, dr.Signals.EMG, \"Resp\", \"Temp\"\n",
    "]\n",
    "wrist_signals = [\n",
    "    dr.Signals.ACC, dr.Signals.BVP, dr.Signals.EDA, dr.Signals.TEMP\n",
    "]\n",
    "phase_label_dict = {\n",
    "    1: dr.Phases.BASE,\n",
    "    2: dr.Phases.TSST,\n",
    "    3: dr.Phases.FUN,\n",
    "    4: [dr.Phases.MEDI_1, dr.Phases.MEDI_2]\n",
    "}\n",
    "\n",
    "phases = dr.Phases.PHASE_ORDER\n",
    "# location = \"wrist\"\n",
    "location = \"chest\"\n",
    "\n",
    "for subject in subject_indices:\n",
    "    data = dr.get_participant_data(subject)\n",
    "    \n",
    "    for signal in chest_signals:\n",
    "    # for signal in wrist_signals:\n",
    "        if location == \"wrist\":\n",
    "            sr = dr.FS_DICT[\"wrist\"][signal]\n",
    "        time_segments = get_time_segments(subject, sr)\n",
    "        signal_data = data[\"signal\"][location][signal]\n",
    "        for label in list(phase_label_dict.keys()):\n",
    "            if signal == \"Temp\" or signal == \"Resp\":\n",
    "                signal = signal.upper()\n",
    "            phase = phase_label_dict[label]\n",
    "            if label == 4:  # 4 corresponds to MEDI 1 and MEDI 2; includes 2 time segment tuples\n",
    "                if signal == dr.Signals.ACC:\n",
    "                    columns_1 = [f\"{location}_{signal}_X_{phase[0]}\", f\"{location}_{signal}_Y_{phase[0]}\", f\"{location}_{signal}_Z_{phase[0]}\"]\n",
    "                else: \n",
    "                    columns_1 = [f\"{location}_{signal}_{phase[0]}\"]\n",
    "                file_name_1 = f\"S{subject}_{location}_{signal}_{phase[0]}.csv\"\n",
    "                file_name_1 = os.path.join(dr.Paths.WESAD, f\"S{subject}\", file_name_1)\n",
    "                start = time_segments[label][0][0]\n",
    "                end = time_segments[label][0][1]\n",
    "                phase_data = signal_data[start:end]\n",
    "                phase_data = pd.DataFrame(data=phase_data, columns=columns_1)\n",
    "                phase_data.to_csv(file_name_1)\n",
    "\n",
    "                if signal == dr.Signals.ACC:\n",
    "                    columns_2 = [f\"{location}_{signal}_X_{phase[1]}\", f\"{location}_{signal}_Y_{phase[1]}\", f\"{location}_{signal}_Z_{phase[1]}\"]\n",
    "                else: \n",
    "                    columns_2 = [f\"{location}_{signal}_{phase[1]}\"]\n",
    "                file_name_2 = f\"S{subject}_{location}_{signal}_{phase[1]}.csv\"\n",
    "                file_name_2 = os.path.join(dr.Paths.WESAD, f\"S{subject}\", file_name_2)\n",
    "                start = time_segments[label][1][0]\n",
    "                end = time_segments[label][1][1]\n",
    "                phase_data = signal_data[start:end]\n",
    "                phase_data = pd.DataFrame(data=phase_data, columns=columns_2)\n",
    "                phase_data.to_csv(file_name_2)\n",
    "            else:\n",
    "                if signal == dr.Signals.ACC:\n",
    "                    columns = [f\"{location}_{signal}_X_{phase}\", f\"{location}_{signal}_Y_{phase}\", f\"{location}_{signal}_Z_{phase}\"]\n",
    "                else: \n",
    "                    columns = [f\"{location}_{signal}_{phase}\"]\n",
    "                file_name = f\"S{subject}_{location}_{signal}_{phase}.csv\"\n",
    "                file_name = os.path.join(dr.Paths.WESAD, f\"S{subject}\", file_name)\n",
    "                start = time_segments[label][0][0]\n",
    "                end = time_segments[label][0][1]\n",
    "                phase_data = signal_data[start:end]\n",
    "                phase_data = pd.DataFrame(data=phase_data, columns=columns)\n",
    "                phase_data.to_csv(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECG METRICS\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "importlib.reload(preprocessing)\n",
    "\n",
    "import biosppy\n",
    "from biosppy.signals import ecg\n",
    "import heartpy\n",
    "import pyhrv\n",
    "import pyhrv.time_domain as td\n",
    "\n",
    "phases = dr.Phases.PHASE_ORDER\n",
    "# metrics = [\"bpm\", \"rmssd\", \"ibi\"]\n",
    "subject_indices = dr.SUBJECTS\n",
    "subject_indices = [str(i) for i in subject_indices]\n",
    "fs = 700.0\n",
    "\n",
    "for phase in phases:\n",
    "    data_files = {\n",
    "        s: dr.Paths.WESAD + f\"/S{s}/S{s}_chest_ECG_{phase}.csv\" for s in subject_indices\n",
    "    }\n",
    "    df_dict = {s: pd.read_csv(data_files[s]) for s in list(data_files.keys())}\n",
    "    metrics_dict = {\n",
    "        # \"bpm\": [],\n",
    "        \"rmssd\": [],\n",
    "        \"sdnn\": []\n",
    "    }\n",
    "    for s in list(df_dict.keys()):\n",
    "        df = df_dict[s]\n",
    "        ecg_signal = df.iloc[:, -1]\n",
    "        # ecg_signal = preprocessing.clean_ecg(ecg_signal).to_numpy().flatten()\n",
    "        # ecg_signal = hp.enhance_ecg_peaks(ecg_signal, fs)\n",
    "        # working_data, measures = hp.process_segmentwise(ecg_signal, fs, segment_width=55, segment_overlap=5/55)\n",
    "        # print(np.isnan(measures[\"bpm\"][0]))\n",
    "        # print(measures[\"bpm\"][0])\n",
    "        \n",
    "        ecg_features = preprocessing.get_ecg_metrics_pyhrv(ecg_signal, fs)\n",
    "        \n",
    "        for metric in list(metrics_dict.keys()):\n",
    "            feature = ecg_features[metric]\n",
    "            feature.insert(0, int(s))\n",
    "            metrics_dict[metric].append(feature)\n",
    "\n",
    "    for metric in list(metrics_dict.keys()):\n",
    "        df = pd.DataFrame(metrics_dict[metric])\n",
    "        metrics_dict[metric] = df\n",
    "    for metric in list(metrics_dict.keys()):\n",
    "        file_name = os.path.join(dr.Paths.METRICS, f\"{metric}_{phase}.csv\")\n",
    "        metrics_dict[metric].to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECG METRICS\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "importlib.reload(preprocessing)\n",
    "\n",
    "import heartpy as hp\n",
    "\n",
    "phases = dr.Phases.PHASE_ORDER\n",
    "# metrics = [\"bpm\", \"rmssd\", \"ibi\"]\n",
    "metrics = [\"sdnn\", \"breathingrate\"]\n",
    "subject_indices = dr.SUBJECTS\n",
    "fs = 700.0\n",
    "\n",
    "for phase in phases:\n",
    "    data_files = {\n",
    "        s: dr.Paths.WESAD + f\"/S{s}/S{s}_chest_ECG_{phase}.csv\" for s in subject_indices\n",
    "    }\n",
    "    df_dict = {s: pd.read_csv(data_files[s]) for s in list(data_files.keys())}\n",
    "    metrics_dict = {\n",
    "        # \"bpm\": [],\n",
    "        # \"rmssd\": [],\n",
    "        # \"ibi\": [],\n",
    "        \"sdnn\": [],\n",
    "        \"breathingrate\": []\n",
    "    }\n",
    "    for s in list(df_dict.keys()):\n",
    "        df = df_dict[s]\n",
    "        ecg_signal = df.iloc[:, -1]\n",
    "        ecg_signal = preprocessing.clean_ecg(ecg_signal).to_numpy().flatten()\n",
    "        working_data, measures = hp.process_segmentwise(ecg_signal, fs, segment_width=55, segment_overlap=5/55)\n",
    "        threshold = 180\n",
    "        # if any(bpm > threshold for bpm in measures[\"bpm\"]):\n",
    "        #     print(f\"BPM for subject {s} contains values greater than {threshold}\") \n",
    "        #     valid_mean = np.mean([bpm for bpm in measures[\"bpm\"] if bpm < threshold])\n",
    "        #     for i in range(len(measures[\"bpm\"])):\n",
    "        #         if measures[\"bpm\"][i] > threshold:\n",
    "        #             measures[\"bpm\"][i] = valid_mean\n",
    "        for metric in list(metrics_dict.keys()):\n",
    "            if np.isnan(np.sum(measures[metric])):\n",
    "                mean = np.nanmean(measures[metric])\n",
    "                measures[metric] = np.nan_to_num(measures[metric], nan=mean).tolist()\n",
    "            measures[metric].insert(0, int(s))\n",
    "            metrics_dict[metric].append(pd.DataFrame(measures[metric]))\n",
    "    for metric in list(metrics_dict.keys()):\n",
    "        df = pd.concat(metrics_dict[metric], axis=1)\n",
    "        df = df.transpose()\n",
    "        metrics_dict[metric] = df\n",
    "    for metric in list(metrics_dict.keys()):\n",
    "        file_name = os.path.join(dr.Paths.METRICS, f\"{metric}_{phase}.csv\")\n",
    "        metrics_dict[metric].to_csv(file_name)\n",
    "        \n",
    "# for phase in phases:\n",
    "#     data_2 = dr.get_data_for_phase(subject, phase, location, dr.Signals.ECG)\n",
    "#     fs = dr.FS_DICT[location][modality]\n",
    "#     wd, m = hp.process(data_2, sample_rate=fs)\n",
    "#     hp.plotter(wd, m, title=f\"Subject {subject}, {phase}, {modality} {location}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HF and LF metrics\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "importlib.reload(preprocessing)\n",
    "\n",
    "phases = dr.Phases.PHASE_ORDER\n",
    "subject_indices = dr.SUBJECTS\n",
    "fs = 700.0\n",
    "\n",
    "for phase in phases:\n",
    "    data_files = {\n",
    "        s: dr.Paths.WESAD + f\"/S{s}/S{s}_chest_ECG_{phase}.csv\" for s in subject_indices\n",
    "    }\n",
    "    df_dict = {s: pd.read_csv(data_files[s]) for s in list(data_files.keys())}\n",
    "    metrics_dict = {\n",
    "        \"lf_rr\": [],\n",
    "        \"hf_rr\": [],\n",
    "    }\n",
    "    for s in list(df_dict.keys()):\n",
    "        df = df_dict[s]\n",
    "        ecg_signal = df.iloc[:, -1]\n",
    "        ecg_signal = preprocessing.clean_ecg(ecg_signal)\n",
    "        lf_rr = preprocessing.get_lf_rr(ecg_signal, fs)\n",
    "        lf_rr = np.insert(lf_rr, 0, s)\n",
    "        lf_rr = pd.DataFrame(lf_rr).dropna(axis=1)\n",
    "\n",
    "        hf_rr = preprocessing.get_hf_rr(ecg_signal, fs)\n",
    "        hf_rr = np.insert(hf_rr, 0, s)\n",
    "        hf_rr = pd.DataFrame(hf_rr).dropna(axis=1)\n",
    "\n",
    "        metrics_dict[\"lf_rr\"].append(lf_rr)\n",
    "        metrics_dict[\"hf_rr\"].append(hf_rr)\n",
    "    for metric in list(metrics_dict.keys()):\n",
    "        df = pd.concat(metrics_dict[metric], axis=1)\n",
    "        df = df.transpose()\n",
    "        metrics_dict[metric] = df\n",
    "    for metric in list(metrics_dict.keys()):\n",
    "        file_name = os.path.join(dr.Paths.METRICS, f\"{metric}_{phase}.csv\")\n",
    "        metrics_dict[metric].to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cleaning data for 8\n"
     ]
    }
   ],
   "source": [
    "# FEATURE EXTRACTION - EDA\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "importlib.reload(preprocessing)\n",
    "importlib.reload(eda)\n",
    "\n",
    "import biosppy\n",
    "from biosppy.signals import eda\n",
    "\n",
    "\n",
    "phases = dr.Phases.PHASE_ORDER\n",
    "subject_indices = dr.SUBJECTS\n",
    "fs = 700.0\n",
    "\n",
    "for phase in phases:\n",
    "    data_files = {\n",
    "        s: dr.Paths.WESAD + f\"/S{s}/S{s}_chest_EDA_{phase}.csv\" for s in subject_indices\n",
    "    }\n",
    "    df_dict = {s: pd.read_csv(data_files[s]) for s in list(data_files.keys())}\n",
    "    metrics_dict = {\n",
    "        \"mean_SCL\": [],\n",
    "        \"SCR_rate\": [],\n",
    "    }\n",
    "    for s in list(df_dict.keys()):\n",
    "        df = df_dict[s]\n",
    "        eda_signal = df.iloc[:, -1]\n",
    "        try:\n",
    "            out = eda.eda(signal=eda_signal, sampling_rate=fs, show=False)\n",
    "            eda_signal = out[\"filtered\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Error cleaning data for {s}\")\n",
    "\n",
    "        mean_scl = preprocessing.get_mean_SCL(eda_signal, fs)\n",
    "        mean_scl = np.insert(mean_scl, 0, s)\n",
    "        mean_scl = pd.DataFrame(mean_scl).dropna(axis=1)\n",
    "\n",
    "        scr_rate = preprocessing.get_SCR_rate(eda_signal, fs)\n",
    "        scr_rate = np.insert(scr_rate, 0, s)\n",
    "        scr_rate = pd.DataFrame(scr_rate).dropna(axis=1)\n",
    "\n",
    "        metrics_dict[\"mean_SCL\"].append(mean_scl)\n",
    "        metrics_dict[\"SCR_rate\"].append(scr_rate)\n",
    "\n",
    "    for metric in list(metrics_dict.keys()):\n",
    "        df = pd.concat(metrics_dict[metric], axis=1)\n",
    "        df = df.transpose()\n",
    "        metrics_dict[metric] = df\n",
    "        \n",
    "    for metric in list(metrics_dict.keys()):\n",
    "        file_name = os.path.join(dr.Paths.METRICS, f\"{metric}_{phase}.csv\")\n",
    "        metrics_dict[metric].to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE EXTRACTION - WRIST ACC\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "importlib.reload(preprocessing)\n",
    "\n",
    "\n",
    "phases = dr.Phases.PHASE_ORDER\n",
    "subject_indices = dr.SUBJECTS\n",
    "\n",
    "for phase in phases:\n",
    "    data_files = {\n",
    "        s: dr.Paths.WESAD + f\"/S{s}/S{s}_wrist_ACC_{phase}.csv\" for s in subject_indices\n",
    "    }\n",
    "    df_dict = {s: pd.read_csv(data_files[s]) for s in list(data_files.keys())}\n",
    "    metrics_dict = {\n",
    "        \"peak_wrist_acc\": [],\n",
    "        \"mean_wrist_activity\": [],\n",
    "    }\n",
    "    for s in list(df_dict.keys()):\n",
    "        df = df_dict[s]\n",
    "        data = df.iloc[:, 1:]\n",
    "        peak_acc = preprocessing.get_peak_acc_value(data, acc_type=\"wrist\")\n",
    "        peak_acc = np.insert(peak_acc, 0, s)\n",
    "        peak_acc = pd.DataFrame(peak_acc).dropna(axis=1)\n",
    "\n",
    "        mean_act = preprocessing.get_mean_ankle_activity(data)\n",
    "        mean_act = np.insert(mean_act, 0, s)\n",
    "        mean_act = pd.DataFrame(mean_act).dropna(axis=1)\n",
    "\n",
    "        metrics_dict[\"peak_wrist_acc\"].append(peak_acc)\n",
    "        metrics_dict[\"mean_wrist_activity\"].append(mean_act)\n",
    "    for metric in list(metrics_dict.keys()):\n",
    "        df = pd.concat(metrics_dict[metric], axis=1)\n",
    "        df = df.transpose()\n",
    "        metrics_dict[metric] = df\n",
    "    for metric in list(metrics_dict.keys()):\n",
    "        file_name = os.path.join(dr.Paths.METRICS, f\"{metric}_{phase}.csv\")\n",
    "        metrics_dict[metric].to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE EXTRACTION - TORSO ACC\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "importlib.reload(preprocessing)\n",
    "\n",
    "\n",
    "phases = dr.Phases.PHASE_ORDER\n",
    "subject_indices = dr.SUBJECTS\n",
    "fs = 700.0\n",
    "\n",
    "for phase in phases:\n",
    "    data_files = {\n",
    "        s: dr.Paths.WESAD + f\"/S{s}/S{s}_chest_ACC_{phase}.csv\" for s in subject_indices\n",
    "    }\n",
    "    df_dict = {s: pd.read_csv(data_files[s]) for s in list(data_files.keys())}\n",
    "    metrics_dict = {\n",
    "        \"mean_post\": [],\n",
    "        \"mean_post_act\": [],\n",
    "    }\n",
    "    for s in list(df_dict.keys()):\n",
    "        df = df_dict[s]\n",
    "        data = df.iloc[:, 1:]\n",
    "        mean_post = preprocessing.get_mean_posture(data)\n",
    "        mean_post = np.insert(mean_post, 0, s)\n",
    "        mean_post = pd.DataFrame(mean_post).dropna(axis=1)\n",
    "\n",
    "        mean_act = preprocessing.get_mean_activity_torso(data)\n",
    "        mean_act = np.insert(mean_act, 0, s)\n",
    "        mean_act = pd.DataFrame(mean_act).dropna(axis=1)\n",
    "\n",
    "        metrics_dict[\"mean_post\"].append(mean_post)\n",
    "        metrics_dict[\"mean_post_act\"].append(mean_act)\n",
    "    for metric in list(metrics_dict.keys()):\n",
    "        df = pd.concat(metrics_dict[metric], axis=1)\n",
    "        df = df.transpose()\n",
    "        metrics_dict[metric] = df\n",
    "    for metric in list(metrics_dict.keys()):\n",
    "        file_name = os.path.join(dr.Paths.METRICS, f\"{metric}_{phase}.csv\")\n",
    "        metrics_dict[metric].to_csv(file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aecf4e853c2a06e9a3d98203b0bfcb89edde136ff484aed399b3da44301ece48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
