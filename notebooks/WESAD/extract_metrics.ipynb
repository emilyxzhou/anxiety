{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING MODULES\n",
    "import glob\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.signal as ss\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..', '..', 'src'))\n",
    "sys.path.append(module_path)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tools.data_reader_wesad as dr\n",
    "import tools.display_tools as dt\n",
    "import tools.preprocessing as preprocessing\n",
    "\n",
    "from scipy.fft import fft, fftfreq, fftshift\n",
    "\n",
    "import cvxopt.solvers\n",
    "cvxopt.solvers.options['show_progress'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER METHODS\n",
    "import samplerate\n",
    "import scipy\n",
    "\n",
    "def get_time_segments(subject, sr_to_convert=0):\n",
    "    data = dr.get_participant_data(subject)\n",
    "    labels = data[\"label\"]\n",
    "    if sr_to_convert > 0:\n",
    "        step = int(700/sr_to_convert)\n",
    "        resampled = []\n",
    "        for i in range(0, labels.size, step):\n",
    "            resampled.append(labels[i])\n",
    "        labels = np.asarray(resampled)\n",
    "        # labels = samplerate.resample(labels, sr_to_convert/700.0)\n",
    "        # labels = scipy.signal.decimate(labels, int(700.0/sr_to_convert))\n",
    "    curr_value = labels[0]\n",
    "    start_indices = [0]\n",
    "    end_indices = []\n",
    "    i = 1\n",
    "    while i < len(labels):\n",
    "        if labels[i] != curr_value:\n",
    "            end_indices.append(i-1)\n",
    "            start_indices.append(i)\n",
    "            curr_value = labels[i]\n",
    "        i += 1\n",
    "\n",
    "    end_indices.append(len(labels)-1)\n",
    "\n",
    "    time_segments = {}\n",
    "    for i in range(len(start_indices)):\n",
    "        label = labels[start_indices[i]]\n",
    "        if label not in time_segments.keys():\n",
    "            time_segments[label] = [(start_indices[i], end_indices[i])]\n",
    "        else:\n",
    "            time_segments[label].append((start_indices[i], end_indices[i]))\n",
    "    return time_segments\n",
    "\n",
    "\n",
    "# ts = get_time_segments(2)\n",
    "# print(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE SIGNALS INTO INDIVIDUAL CSV FILES\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "importlib.reload(preprocessing)\n",
    "\n",
    "\n",
    "subject_indices = list(range(2, 12)) + list(range(13, 18))\n",
    "subject_indices = [str(i) for i in subject_indices]\n",
    "\n",
    "locations = [dr.WESADKeys.CHEST]\n",
    "# locations = [dr.WESADKeys.WRIST]\n",
    "chest_signals = [\n",
    "    # dr.Signals.ACC, dr.Signals.ECG, dr.Signals.EDA, dr.Signals.EMG, \"Resp\", \"Temp\"\n",
    "    dr.Signals.ECG, dr.Signals.EDA, \n",
    "]\n",
    "wrist_signals = [\n",
    "    dr.Signals.ACC, dr.Signals.BVP, dr.Signals.EDA, dr.Signals.TEMP\n",
    "]\n",
    "phase_label_dict = {\n",
    "    1: dr.Phases.BASE,\n",
    "    2: dr.Phases.TSST,\n",
    "    3: dr.Phases.FUN,\n",
    "    4: [dr.Phases.MEDI_1, dr.Phases.MEDI_2]\n",
    "}\n",
    "\n",
    "phases = dr.Phases.PHASE_ORDER\n",
    "# location = \"wrist\"\n",
    "location = \"chest\"\n",
    "\n",
    "for subject in subject_indices:\n",
    "    data = dr.get_participant_data(subject)\n",
    "    \n",
    "    for signal in chest_signals:\n",
    "    # for signal in wrist_signals:\n",
    "        if location == \"wrist\":\n",
    "            sr = dr.FS_DICT[\"wrist\"][signal]\n",
    "        else:\n",
    "            sr = 700.0\n",
    "        time_segments = get_time_segments(subject, sr)\n",
    "        signal_data = data[\"signal\"][location][signal]\n",
    "        for label in list(phase_label_dict.keys()):\n",
    "            if signal == \"Temp\" or signal == \"Resp\":\n",
    "                signal = signal.upper()\n",
    "            phase = phase_label_dict[label]\n",
    "            if label == 4:  # 4 corresponds to MEDI 1 and MEDI 2; includes 2 time segment tuples\n",
    "                if signal == dr.Signals.ACC:\n",
    "                    columns_1 = [f\"{location}_{signal}_X_{phase[0]}\", f\"{location}_{signal}_Y_{phase[0]}\", f\"{location}_{signal}_Z_{phase[0]}\"]\n",
    "                else: \n",
    "                    columns_1 = [f\"{location}_{signal}_{phase[0]}\"]\n",
    "                file_name_1 = f\"S{subject}_{location}_{signal}_{phase[0]}.csv\"\n",
    "                file_name_1 = os.path.join(dr.Paths.WESAD, f\"S{subject}\", file_name_1)\n",
    "                start = time_segments[label][0][0]\n",
    "                end = time_segments[label][0][1]\n",
    "                phase_data = signal_data[start:end]\n",
    "                phase_data = pd.DataFrame(data=phase_data, columns=columns_1)\n",
    "                phase_data.to_csv(file_name_1)\n",
    "\n",
    "                if signal == dr.Signals.ACC:\n",
    "                    columns_2 = [f\"{location}_{signal}_X_{phase[1]}\", f\"{location}_{signal}_Y_{phase[1]}\", f\"{location}_{signal}_Z_{phase[1]}\"]\n",
    "                else: \n",
    "                    columns_2 = [f\"{location}_{signal}_{phase[1]}\"]\n",
    "                file_name_2 = f\"S{subject}_{location}_{signal}_{phase[1]}.csv\"\n",
    "                file_name_2 = os.path.join(dr.Paths.WESAD, f\"S{subject}\", file_name_2)\n",
    "                start = time_segments[label][1][0]\n",
    "                end = time_segments[label][1][1]\n",
    "                phase_data = signal_data[start:end]\n",
    "                phase_data = pd.DataFrame(data=phase_data, columns=columns_2)\n",
    "                phase_data.to_csv(file_name_2)\n",
    "            else:\n",
    "                if signal == dr.Signals.ACC:\n",
    "                    columns = [f\"{location}_{signal}_X_{phase}\", f\"{location}_{signal}_Y_{phase}\", f\"{location}_{signal}_Z_{phase}\"]\n",
    "                else: \n",
    "                    columns = [f\"{location}_{signal}_{phase}\"]\n",
    "                file_name = f\"S{subject}_{location}_{signal}_{phase}.csv\"\n",
    "                file_name = os.path.join(dr.Paths.WESAD, f\"S{subject}\", file_name)\n",
    "                start = time_segments[label][0][0]\n",
    "                end = time_segments[label][0][1]\n",
    "                phase_data = signal_data[start:end]\n",
    "                phase_data = pd.DataFrame(data=phase_data, columns=columns)\n",
    "                phase_data.to_csv(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base\n",
      "TSST\n",
      "Medi_1\n",
      "Fun\n",
      "Medi_2\n"
     ]
    }
   ],
   "source": [
    "# ECG METRICS\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "importlib.reload(preprocessing)\n",
    "\n",
    "import biosppy\n",
    "from biosppy.signals import ecg\n",
    "import heartpy\n",
    "import pyhrv\n",
    "import pyhrv.time_domain as td\n",
    "\n",
    "phases = dr.Phases.PHASE_ORDER\n",
    "metric = \"bpm\"\n",
    "subject_indices = dr.SUBJECTS\n",
    "subject_indices = [str(i) for i in subject_indices]\n",
    "fs = 700.0\n",
    "\n",
    "for phase in phases:\n",
    "    print(phase)\n",
    "    data = []\n",
    "    data_files = {\n",
    "        s: dr.Paths.WESAD + f\"/S{s}/S{s}_chest_ECG_{phase}.csv\" for s in subject_indices\n",
    "    }\n",
    "    df_dict = {s: pd.read_csv(data_files[s]) for s in list(data_files.keys())}\n",
    "    for s in list(df_dict.keys()):\n",
    "        df = df_dict[s]\n",
    "        ecg_signal = df.iloc[:, -1]\n",
    "        \n",
    "        bpm = preprocessing.get_bpm_biosppy(ecg_signal, fs=fs)\n",
    "\n",
    "        bpm.insert(0, int(s))\n",
    "        data.append(bpm)\n",
    "\n",
    "    file_name = os.path.join(dr.Paths.METRICS, f\"{metric}_{phase}.csv\")\n",
    "    df = pd.DataFrame(data=data)\n",
    "    df.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECG METRICS\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "importlib.reload(preprocessing)\n",
    "\n",
    "import biosppy\n",
    "from biosppy.signals import ecg\n",
    "import heartpy\n",
    "import pyhrv\n",
    "import pyhrv.time_domain as td\n",
    "\n",
    "phases = dr.Phases.PHASE_ORDER\n",
    "subject_indices = dr.SUBJECTS\n",
    "subject_indices = [str(i) for i in subject_indices]\n",
    "fs = 700.0\n",
    "\n",
    "for phase in phases:\n",
    "    data_files = {\n",
    "        s: dr.Paths.WESAD + f\"/S{s}/S{s}_chest_ECG_{phase}.csv\" for s in subject_indices\n",
    "    }\n",
    "    df_dict = {s: pd.read_csv(data_files[s]) for s in list(data_files.keys())}\n",
    "    metrics_dict = {\n",
    "        # \"bpm\": [],\n",
    "        \"rmssd\": [],\n",
    "        \"sdnn\": []\n",
    "    }\n",
    "    for s in list(df_dict.keys()):\n",
    "        df = df_dict[s]\n",
    "        ecg_signal = df.iloc[:, -1]\n",
    "        # ecg_signal = preprocessing.clean_ecg(ecg_signal).to_numpy().flatten()\n",
    "        # ecg_signal = hp.enhance_ecg_peaks(ecg_signal, fs)\n",
    "        # working_data, measures = hp.process_segmentwise(ecg_signal, fs, segment_width=55, segment_overlap=5/55)\n",
    "        # print(np.isnan(measures[\"bpm\"][0]))\n",
    "        # print(measures[\"bpm\"][0])\n",
    "        \n",
    "        ecg_features = preprocessing.get_ecg_metrics_pyhrv(ecg_signal, fs=fs)\n",
    "        \n",
    "        for metric in list(metrics_dict.keys()):\n",
    "            feature = ecg_features[metric]\n",
    "            feature.insert(0, int(s))\n",
    "            metrics_dict[metric].append(feature)\n",
    "\n",
    "    for metric in list(metrics_dict.keys()):\n",
    "        df = pd.DataFrame(metrics_dict[metric])\n",
    "        metrics_dict[metric] = df\n",
    "    for metric in list(metrics_dict.keys()):\n",
    "        file_name = os.path.join(dr.Paths.METRICS, f\"{metric}_{phase}.csv\")\n",
    "        metrics_dict[metric].to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HF and LF metrics\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "importlib.reload(preprocessing)\n",
    "\n",
    "from biosppy.signals import ecg\n",
    "\n",
    "\n",
    "phases = dr.Phases.PHASE_ORDER\n",
    "subject_indices = dr.SUBJECTS\n",
    "fs = 700.0\n",
    "\n",
    "for phase in phases:\n",
    "    data_files = {\n",
    "        s: dr.Paths.WESAD + f\"/S{s}/S{s}_chest_ECG_{phase}.csv\" for s in subject_indices\n",
    "    }\n",
    "    df_dict = {s: pd.read_csv(data_files[s]) for s in list(data_files.keys())}\n",
    "    metrics_dict = {\n",
    "        \"lf_rr\": [],\n",
    "        \"hf_rr\": [],\n",
    "    }\n",
    "    for s in list(df_dict.keys()):\n",
    "        df = df_dict[s]\n",
    "        ecg_signal = df.iloc[:, -1]\n",
    "        out = ecg.ecg(signal=ecg_signal, sampling_rate=fs, show=False)\n",
    "        ecg_signal = out[\"filtered\"]\n",
    "        lf_rr = preprocessing.get_lf_rr(ecg_signal, fs)\n",
    "        lf_rr = np.insert(lf_rr, 0, s)\n",
    "        lf_rr = pd.DataFrame(lf_rr).dropna(axis=1)\n",
    "\n",
    "        hf_rr = preprocessing.get_hf_rr(ecg_signal, fs)\n",
    "        hf_rr = np.insert(hf_rr, 0, s)\n",
    "        hf_rr = pd.DataFrame(hf_rr).dropna(axis=1)\n",
    "\n",
    "        metrics_dict[\"lf_rr\"].append(lf_rr)\n",
    "        metrics_dict[\"hf_rr\"].append(hf_rr)\n",
    "\n",
    "    for metric in list(metrics_dict.keys()):\n",
    "        df = pd.concat(metrics_dict[metric], axis=1)\n",
    "        df = df.transpose()\n",
    "        metrics_dict[metric] = df\n",
    "    for metric in list(metrics_dict.keys()):\n",
    "        file_name = os.path.join(dr.Paths.METRICS, f\"{metric}_{phase}.csv\")\n",
    "        metrics_dict[metric].to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base\n"
     ]
    }
   ],
   "source": [
    "# FEATURE EXTRACTION - EDA\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "importlib.reload(preprocessing)\n",
    "\n",
    "import biosppy\n",
    "from biosppy.signals import ecg\n",
    "from biosppy.signals import eda\n",
    "from heartpy.preprocessing import scale_data\n",
    "\n",
    "\n",
    "phases = dr.Phases.PHASE_ORDER\n",
    "# phases = [dr.Phases.PHASE_ORDER[0]]\n",
    "subject_indices = dr.SUBJECTS\n",
    "fs = 700.0\n",
    "\n",
    "for phase in phases:\n",
    "    print(f\"{phase}\")\n",
    "    data_files = {\n",
    "        s: dr.Paths.WESAD + f\"/S{s}/S{s}_chest_EDA_{phase}.csv\" for s in subject_indices\n",
    "    }\n",
    "    df_dict = {s: pd.read_csv(data_files[s]) for s in list(data_files.keys())}\n",
    "    metrics_dict = {\n",
    "        \"mean_SCL\": [],\n",
    "        # \"SCR_rate\": [],\n",
    "    }\n",
    "    for s in list(df_dict.keys()):\n",
    "        df = df_dict[s]\n",
    "        eda_signal = df.iloc[:, -1]\n",
    "        eda_signal = scale_data(eda_signal)\n",
    "        try:\n",
    "            out = eda.eda(signal=eda_signal, sampling_rate=fs, show=False)\n",
    "            eda_signal = out[\"filtered\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Error cleaning data for {s}\")\n",
    "\n",
    "        mean_scl = preprocessing.get_mean_SCL(eda_signal, fs)\n",
    "        mean_scl = np.insert(mean_scl, 0, s)\n",
    "        mean_scl = pd.DataFrame(mean_scl).dropna(axis=1)\n",
    "\n",
    "        # scr_rate = preprocessing.get_SCR_rate(eda_signal, fs)\n",
    "        # scr_rate = np.insert(scr_rate, 0, s)\n",
    "        # scr_rate = pd.DataFrame(scr_rate).dropna(axis=1)\n",
    "\n",
    "        # print(f\"mean SCL:\\n{mean_scl}\\nSCR rate:\\n{scr_rate}\")\n",
    "\n",
    "        metrics_dict[\"mean_SCL\"].append(mean_scl)\n",
    "        # metrics_dict[\"SCR_rate\"].append(scr_rate)\n",
    "\n",
    "    for metric in list(metrics_dict.keys()):\n",
    "        df = pd.concat(metrics_dict[metric], axis=1)\n",
    "        df = df.transpose()\n",
    "        metrics_dict[metric] = df\n",
    "        \n",
    "    for metric in list(metrics_dict.keys()):\n",
    "        file_name = os.path.join(dr.Paths.METRICS, f\"{metric}_{phase}.csv\")\n",
    "        metrics_dict[metric].to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE EXTRACTION -- STATISTICAL FEATURES\n",
    "# mean, median, std, variance, IQR, RMS, skewness, kurtosis\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "importlib.reload(preprocessing)\n",
    "\n",
    "import biosppy\n",
    "from biosppy.signals import eda\n",
    "from biosppy.signals import ecg\n",
    "from heartpy.preprocessing import scale_data\n",
    "from scipy.stats import iqr, skew, kurtosis\n",
    "\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.mean(x**2))\n",
    "\n",
    "metrics = {\n",
    "    \"mean\": np.nanmean,\n",
    "    \"median\": np.nanmedian,\n",
    "    \"std\": np.nanstd,\n",
    "    \"var\": np.nanvar,\n",
    "    \"iqr\": iqr,\n",
    "    \"rms\": rms,\n",
    "    \"skew\": skew,\n",
    "    \"kurtosis\": kurtosis\n",
    "}\n",
    "\n",
    "phases = dr.Phases.PHASE_ORDER\n",
    "subject_indices = dr.SUBJECTS\n",
    "subject_indices = [str(i) for i in subject_indices]\n",
    "fs = 700.0\n",
    "\n",
    "for metric in metrics:\n",
    "    for phase in phases:\n",
    "        data = []\n",
    "        data_files = {\n",
    "            s: dr.Paths.WESAD + f\"/S{s}/S{s}_chest_ECG_{phase}.csv\" for s in subject_indices\n",
    "        }\n",
    "        df_dict = {s: pd.read_csv(data_files[s]) for s in list(data_files.keys())}\n",
    "        for s in list(df_dict.keys()):\n",
    "            df = df_dict[s]\n",
    "            ecg_signal = df.iloc[:, -1]\n",
    "            ecg_signal = scale_data(ecg_signal)\n",
    "            out = ecg.ecg(signal=ecg_signal, sampling_rate=fs, show=False)\n",
    "            ecg_signal = out[\"filtered\"]\n",
    "\n",
    "            value = preprocessing.get_statistical_metrics(ecg_signal, metrics[metric], fs)\n",
    "            value = np.insert(value, 0, s)\n",
    "            data.append(value)\n",
    "\n",
    "        file_name = os.path.join(dr.Paths.METRICS, f\"ecg_{metric}_{phase}.csv\")\n",
    "        df = pd.DataFrame(data=data)\n",
    "        df.to_csv(file_name)\n",
    "\n",
    "for metric in metrics:\n",
    "    for phase in phases:\n",
    "        data = []\n",
    "        data_files = {\n",
    "            s: dr.Paths.WESAD + f\"/S{s}/S{s}_chest_EDA_{phase}.csv\" for s in subject_indices\n",
    "        }\n",
    "        df_dict = {s: pd.read_csv(data_files[s]) for s in list(data_files.keys())}\n",
    "        for s in list(df_dict.keys()):\n",
    "            df = df_dict[s]\n",
    "            eda_signal = df.iloc[:, -1]\n",
    "            eda_signal = scale_data(eda_signal)\n",
    "            out = eda.eda(signal=eda_signal, sampling_rate=fs, show=False)\n",
    "            eda_signal = out[\"filtered\"]\n",
    "\n",
    "            value = preprocessing.get_statistical_metrics(eda_signal, metrics[metric], fs)\n",
    "            value = np.insert(value, 0, s)\n",
    "            data.append(value)\n",
    "\n",
    "        file_name = os.path.join(dr.Paths.METRICS, f\"eda_{metric}_{phase}.csv\")\n",
    "        df = pd.DataFrame(data=data)\n",
    "        df.to_csv(file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aecf4e853c2a06e9a3d98203b0bfcb89edde136ff484aed399b3da44301ece48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
