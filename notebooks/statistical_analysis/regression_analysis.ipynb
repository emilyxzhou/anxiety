{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING MODULES\n",
    "import glob\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "cvx_path = os.path.abspath(os.path.join('..', '..', 'cvxEDA', 'src'))\n",
    "module_path = os.path.abspath(os.path.join('..', '..', 'src'))\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy.signal as ss\n",
    "import sys\n",
    "sys.path.append(module_path)\n",
    "\n",
    "import tools.data_reader_apd as dr_a\n",
    "import tools.data_reader_wesad as dr_w\n",
    "import tools.data_reader_popane as dr_p\n",
    "import tools.display_tools as dt\n",
    "import tools.preprocessing as preprocessing\n",
    "import train\n",
    "\n",
    "from scipy.fft import fft, fftfreq, fftshift\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import cvxopt.solvers\n",
    "cvxopt.solvers.options['show_progress'] = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", \n",
    "    category=RuntimeWarning\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = [\n",
    "    [ # ECG time\n",
    "        train.Metrics.BPM, \n",
    "        train.Metrics.IBI, \n",
    "        train.Metrics.SDNN, \n",
    "        train.Metrics.RMSSD, \n",
    "    ],\n",
    "    [ # ECG frequency\n",
    "        train.Metrics.HF_RR, \n",
    "        train.Metrics.LF_RR\n",
    "    ],\n",
    "    [ # EDA metrics\n",
    "        train.Metrics.MEAN_SCL, \n",
    "        train.Metrics.SCR_RATE\n",
    "    ],\n",
    "    [ # all\n",
    "        train.Metrics.BPM, \n",
    "        train.Metrics.IBI, \n",
    "        train.Metrics.SDNN, \n",
    "        train.Metrics.RMSSD, \n",
    "        train.Metrics.HF_RR,\n",
    "        train.Metrics.LF_RR,\n",
    "        train.Metrics.MEAN_SCL, \n",
    "        train.Metrics.SCR_RATE\n",
    "    ]\n",
    "]\n",
    "\n",
    "single_metrics = [\n",
    "    train.Metrics.BPM, \n",
    "    train.Metrics.IBI, \n",
    "    train.Metrics.SDNN, \n",
    "    train.Metrics.RMSSD, \n",
    "    train.Metrics.HF_RR,\n",
    "    train.Metrics.LF_RR,\n",
    "    train.Metrics.MEAN_SCL, \n",
    "    train.Metrics.SCR_RATE\n",
    "]\n",
    "\n",
    "threshold = \"fixed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD TRAIN AND TEST DATA\n",
    "importlib.reload(train)\n",
    "importlib.reload(dr_a)\n",
    "importlib.reload(dt)\n",
    "\n",
    "\n",
    "model_phases = [\n",
    "    [\n",
    "        \"Baseline_Rest\", \n",
    "        \"BugBox_Relax\", \"BugBox_Anticipate\", \"BugBox_Exposure\", \"BugBox_Break\",\n",
    "        \"Speech_Relax\", \"Speech_Anticipate\", \"Speech_Exposure\", \"Speech_Break\"\n",
    "    ],\n",
    "    [\n",
    "        \"Baseline_Rest\", \n",
    "        \"BugBox_Relax\", \"BugBox_Anticipate\", \"BugBox_Break\",\n",
    "        \"Speech_Relax\", \"Speech_Anticipate\", \"Speech_Break\"\n",
    "    ],\n",
    "    [\n",
    "        \"Baseline_Rest\", \n",
    "        \"BugBox_Relax\", \"BugBox_Anticipate\", \n",
    "        \"Speech_Relax\", \"Speech_Anticipate\"\n",
    "    ],\n",
    "    [\n",
    "        \"Baseline_Rest\", \n",
    "        \"BugBox_Relax\",\n",
    "        \"Speech_Relax\"\n",
    "    ],\n",
    "    [\"BugBox_Break\", \"Speech_Break\"],\n",
    "    [\"BugBox_Exposure\", \"Speech_Exposure\"]\n",
    "]\n",
    "\n",
    "anxiety_label_type = \"Anxiety\"\n",
    "\n",
    "for phases in model_phases:\n",
    "    print(f\"PHASES: {phases} \" + \"-\"*30)\n",
    "    for metrics in metrics_list:\n",
    "        print(f\"METRICS: {metrics}\")\n",
    "        x, y = train.Train_APD.get_apd_data_ranking(metrics, phases, verbose=False, anxiety_label_type=anxiety_label_type, threshold=threshold)\n",
    "        x = x.drop([\"phaseId\"], axis=1)\n",
    "        # drop subjects with noisy data\n",
    "        x = x[x['subject'] != 84.0]\n",
    "        y = y[y['subject'] != 84.0]\n",
    "        # x = x[x['subject'] != 8.0]\n",
    "        # y = y[y['subject'] != 8.0]\n",
    "\n",
    "        x.drop(labels=[\"anxietyGroup\"], axis=1)\n",
    "\n",
    "        # 0-1 scaling\n",
    "        for i in range(3, len(x.columns)):\n",
    "            data_col = x[x.columns[i]]\n",
    "            data_col = (data_col - data_col.min())/(data_col.max() - data_col.min())\n",
    "            x[x.columns[i]] = data_col\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(x, y)\n",
    "        # print(model.intercept_) \n",
    "        # print(model.coef_)\n",
    "        print(f\"R2: {model.score(x, y)}\\n\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "for phases in model_phases:\n",
    "    print(f\"PHASES: {phases} \" + \"-\"*30)\n",
    "    for metric in single_metrics:\n",
    "        print(f\"METRICS: {metric}\")\n",
    "        x, y = train.Train_APD.get_apd_data_ranking(metrics, phases, verbose=False, anxiety_label_type=anxiety_label_type, threshold=threshold)\n",
    "        x = x.drop([\"phaseId\"], axis=1)\n",
    "        # drop subjects with noisy data\n",
    "        x = x[x['subject'] != 84.0]\n",
    "        y = y[y['subject'] != 84.0]\n",
    "        # x = x[x['subject'] != 8.0]\n",
    "        # y = y[y['subject'] != 8.0]\n",
    "\n",
    "        x.drop(labels=[\"anxietyGroup\"], axis=1)\n",
    "\n",
    "        # 0-1 scaling\n",
    "        for i in range(3, len(x.columns)):\n",
    "            data_col = x[x.columns[i]]\n",
    "            data_col = (data_col - data_col.min())/(data_col.max() - data_col.min())\n",
    "            x[x.columns[i]] = data_col\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(x, y)\n",
    "        # print(model.intercept_) \n",
    "        # print(model.coef_)\n",
    "        print(f\"R2: {model.score(x, y)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD TRAIN AND TEST DATA\n",
    "importlib.reload(train)\n",
    "importlib.reload(dr_w)\n",
    "importlib.reload(dt)\n",
    "\n",
    "model_phases = [\n",
    "    [\n",
    "        dr_w.Phases.BASE,\n",
    "        dr_w.Phases.FUN,\n",
    "        dr_w.Phases.TSST,\n",
    "        dr_w.Phases.MEDI_1,\n",
    "        dr_w.Phases.MEDI_2\n",
    "    ],\n",
    "    [\n",
    "        dr_w.Phases.BASE,\n",
    "        dr_w.Phases.TSST,\n",
    "        dr_w.Phases.MEDI_1,\n",
    "        dr_w.Phases.MEDI_2\n",
    "    ],\n",
    "    [\n",
    "        dr_w.Phases.BASE,\n",
    "        dr_w.Phases.MEDI_1,\n",
    "        dr_w.Phases.MEDI_2\n",
    "    ],\n",
    "    [\n",
    "        dr_w.Phases.BASE,\n",
    "    ]\n",
    "]\n",
    "\n",
    "label_type = \"stai\"\n",
    "\n",
    "for phases in model_phases:\n",
    "    print(f\"PHASES: {phases} \" + \"-\"*30)\n",
    "    for metrics in metrics_list:\n",
    "        print(f\"METRICS: {metrics}\")\n",
    "        x, y = train.Train_WESAD.get_wesad_data(metrics, phases, verbose=False, label_type=label_type, threshold=threshold)\n",
    "        x = x.drop([\"phaseId\"], axis=1)\n",
    "\n",
    "        # 0-1 scaling\n",
    "        for i in range(3, len(x.columns)):\n",
    "            data_col = x[x.columns[i]]\n",
    "            data_col = (data_col - data_col.min())/(data_col.max() - data_col.min())\n",
    "            x[x.columns[i]] = data_col\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(x, y)\n",
    "        # print(model.intercept_) \n",
    "        # print(model.coef_)\n",
    "        print(f\"R2: {model.score(x, y)}\\n\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "for phases in model_phases:\n",
    "    print(f\"PHASES: {phases} \" + \"-\"*30)\n",
    "    for metric in single_metrics:\n",
    "        print(f\"METRICS: {metric}\")\n",
    "        x, y = train.Train_WESAD.get_wesad_data(metrics, phases, verbose=False, label_type=label_type, threshold=threshold)\n",
    "        x = x.drop([\"phaseId\"], axis=1)\n",
    "\n",
    "        # 0-1 scaling\n",
    "        for i in range(3, len(x.columns)):\n",
    "            data_col = x[x.columns[i]]\n",
    "            data_col = (data_col - data_col.min())/(data_col.max() - data_col.min())\n",
    "            x[x.columns[i]] = data_col\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(x, y)\n",
    "        # print(model.intercept_) \n",
    "        # print(model.coef_)\n",
    "        print(f\"R2: {model.score(x, y)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study1 ------------------------------------------------------------\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd']\n",
      "R2: 0.5025300268771222\n",
      "\n",
      "METRICS: ['hf_rr', 'lf_rr']\n",
      "R2: 0.5077266581692784\n",
      "\n",
      "METRICS: ['mean_SCL', 'SCR_rate']\n",
      "R2: 0.5079038075771718\n",
      "\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd', 'hf_rr', 'lf_rr', 'mean_SCL', 'SCR_rate']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 43\u001b[0m\n\u001b[0;32m     39\u001b[0m     x[x\u001b[39m.\u001b[39mcolumns[i]] \u001b[39m=\u001b[39m data_col\n\u001b[0;32m     41\u001b[0m model \u001b[39m=\u001b[39m LinearRegression()\n\u001b[1;32m---> 43\u001b[0m model\u001b[39m.\u001b[39;49mfit(x, y)\n\u001b[0;32m     44\u001b[0m \u001b[39m# print(model.intercept_) \u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39m# print(model.coef_)\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mR2: \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39mscore(x,\u001b[39m \u001b[39my)\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zhoux\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_base.py:648\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    644\u001b[0m n_jobs_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs\n\u001b[0;32m    646\u001b[0m accept_sparse \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositive \u001b[39melse\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcoo\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m--> 648\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    649\u001b[0m     X, y, accept_sparse\u001b[39m=\u001b[39;49maccept_sparse, y_numeric\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m    650\u001b[0m )\n\u001b[0;32m    652\u001b[0m sample_weight \u001b[39m=\u001b[39m _check_sample_weight(\n\u001b[0;32m    653\u001b[0m     sample_weight, X, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype, only_non_negative\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    654\u001b[0m )\n\u001b[0;32m    656\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[39m=\u001b[39m _preprocess_data(\n\u001b[0;32m    657\u001b[0m     X,\n\u001b[0;32m    658\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    661\u001b[0m     sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[0;32m    662\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\zhoux\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    564\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 565\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    568\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\zhoux\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1109\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1110\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1111\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1112\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1113\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1114\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1115\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1116\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1117\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1118\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\zhoux\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m         )\n\u001b[0;32m    920\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[0;32m    922\u001b[0m             array,\n\u001b[0;32m    923\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    924\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    925\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    926\u001b[0m         )\n\u001b[0;32m    928\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Users\\zhoux\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# LOAD TRAIN AND TEST DATA\n",
    "importlib.reload(train)\n",
    "importlib.reload(dr_p)\n",
    "importlib.reload(dt)\n",
    "\n",
    "\n",
    "popane_phases = {\n",
    "    \"Study1\": dr_p.Study1.ALL,\n",
    "    \"Study2\": dr_p.Study2.ALL,\n",
    "    \"Study3\": dr_p.Study3.ALL,\n",
    "    \"Study4\": dr_p.Study4.ALL,\n",
    "    \"Study5\": dr_p.Study5.ALL,\n",
    "    # \"Study6\": dr_p.Study6.ALL,\n",
    "    # \"Study7\": dr_p.Study7.ALL\n",
    "}\n",
    "\n",
    "label_type = \"affect\"\n",
    "\n",
    "for study in popane_phases.keys():\n",
    "    print(f\"{study} \" + \"-\"*60)\n",
    "    phases = popane_phases[study]\n",
    "    for phase in phases:\n",
    "        for metrics in metrics_list:\n",
    "            print(f\"METRICS: {metrics}\")\n",
    "            x, y = train.Train_POPANE.get_popane_data(study, metrics, [phase], verbose=False, label_type=label_type, threshold=threshold)\n",
    "            # x = x.drop([\"phaseId\"], axis=1)\n",
    "            # nan_idx = x[x.isna().any(axis=1)].index\n",
    "            # x = x.drop(index=nan_idx)\n",
    "            # y = y.drop(index=nan_idx)\n",
    "\n",
    "            # nan_idx = y[y.isna().any(axis=1)].index\n",
    "            # x = x.drop(index=nan_idx)\n",
    "            # y = y.drop(index=nan_idx)\n",
    "\n",
    "            # 0-1 scaling\n",
    "            for i in range(3, len(x.columns)):\n",
    "                data_col = x[x.columns[i]]\n",
    "                data_col = (data_col - data_col.min())/(data_col.max() - data_col.min())\n",
    "                x[x.columns[i]] = data_col\n",
    "\n",
    "            model = LinearRegression()\n",
    "\n",
    "            model.fit(x, y)\n",
    "            # print(model.intercept_) \n",
    "            # print(model.coef_)\n",
    "            print(f\"R2: {model.score(x, y)}\\n\")\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "        for metric in single_metrics:\n",
    "            print(f\"METRICS: {metric}\")\n",
    "            x, y = train.Train_POPANE.get_popane_data(study, metric, [phase], verbose=False, label_type=label_type, threshold=threshold)\n",
    "            x = x.drop([\"phaseId\"], axis=1)\n",
    "\n",
    "            # 0-1 scaling\n",
    "            for i in range(3, len(x.columns)):\n",
    "                data_col = x[x.columns[i]]\n",
    "                data_col = (data_col - data_col.min())/(data_col.max() - data_col.min())\n",
    "                x[x.columns[i]] = data_col\n",
    "\n",
    "            model = LinearRegression()\n",
    "            model.fit(x, y)\n",
    "            # print(model.intercept_) \n",
    "            # print(model.coef_)\n",
    "            print(f\"R2: {model.score(x, y)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study1 ------------------------------------------------------------\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['hf_rr', 'lf_rr']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd', 'hf_rr', 'lf_rr', 'mean_SCL', 'SCR_rate']\n",
      "Int64Index([138, 139, 140], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['hf_rr', 'lf_rr']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd', 'hf_rr', 'lf_rr', 'mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['hf_rr', 'lf_rr']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd', 'hf_rr', 'lf_rr', 'mean_SCL', 'SCR_rate']\n",
      "Int64Index([138, 139], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['hf_rr', 'lf_rr']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd', 'hf_rr', 'lf_rr', 'mean_SCL', 'SCR_rate']\n",
      "Int64Index([41, 42], dtype='int64')\n",
      "Study2 ------------------------------------------------------------\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['hf_rr', 'lf_rr']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd', 'hf_rr', 'lf_rr', 'mean_SCL', 'SCR_rate']\n",
      "Int64Index([175, 176, 177, 178, 179, 180, 181, 182, 183, 184], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['hf_rr', 'lf_rr']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd', 'hf_rr', 'lf_rr', 'mean_SCL', 'SCR_rate']\n",
      "Int64Index([64], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['hf_rr', 'lf_rr']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd', 'hf_rr', 'lf_rr', 'mean_SCL', 'SCR_rate']\n",
      "Int64Index([88, 89, 90], dtype='int64')\n",
      "Study3 ------------------------------------------------------------\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['hf_rr', 'lf_rr']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd', 'hf_rr', 'lf_rr', 'mean_SCL', 'SCR_rate']\n",
      "Int64Index([139, 140], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['hf_rr', 'lf_rr']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd', 'hf_rr', 'lf_rr', 'mean_SCL', 'SCR_rate']\n",
      "Int64Index([139, 140], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['hf_rr', 'lf_rr']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd', 'hf_rr', 'lf_rr', 'mean_SCL', 'SCR_rate']\n",
      "Int64Index([139, 140], dtype='int64')\n",
      "Study4 ------------------------------------------------------------\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['hf_rr', 'lf_rr']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd', 'hf_rr', 'lf_rr', 'mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['hf_rr', 'lf_rr']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd', 'hf_rr', 'lf_rr', 'mean_SCL', 'SCR_rate']\n",
      "Int64Index([40, 41, 42], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['hf_rr', 'lf_rr']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd', 'hf_rr', 'lf_rr', 'mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "Study5 ------------------------------------------------------------\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['hf_rr', 'lf_rr']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd', 'hf_rr', 'lf_rr', 'mean_SCL', 'SCR_rate']\n",
      "Int64Index([69, 70], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['hf_rr', 'lf_rr']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd', 'hf_rr', 'lf_rr', 'mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['hf_rr', 'lf_rr']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd', 'hf_rr', 'lf_rr', 'mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['hf_rr', 'lf_rr']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd', 'hf_rr', 'lf_rr', 'mean_SCL', 'SCR_rate']\n",
      "Int64Index([62], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['hf_rr', 'lf_rr']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd', 'hf_rr', 'lf_rr', 'mean_SCL', 'SCR_rate']\n",
      "Int64Index([62], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['hf_rr', 'lf_rr']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd', 'hf_rr', 'lf_rr', 'mean_SCL', 'SCR_rate']\n",
      "Int64Index([62], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['hf_rr', 'lf_rr']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd', 'hf_rr', 'lf_rr', 'mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['hf_rr', 'lf_rr']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd', 'hf_rr', 'lf_rr', 'mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['hf_rr', 'lf_rr']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n",
      "METRICS: ['bpm', 'ibi', 'sdnn', 'rmssd', 'hf_rr', 'lf_rr', 'mean_SCL', 'SCR_rate']\n",
      "Int64Index([], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "metrics = [ # all\n",
    "    train.Metrics.BPM, \n",
    "    train.Metrics.IBI, \n",
    "    train.Metrics.SDNN, \n",
    "    train.Metrics.RMSSD, \n",
    "    train.Metrics.HF_RR,\n",
    "    train.Metrics.LF_RR,\n",
    "    train.Metrics.MEAN_SCL, \n",
    "    train.Metrics.SCR_RATE\n",
    "]\n",
    "\n",
    "popane_phases = {\n",
    "    \"Study1\": dr_p.Study1.ALL,\n",
    "    \"Study2\": dr_p.Study2.ALL,\n",
    "    \"Study3\": dr_p.Study3.ALL,\n",
    "    \"Study4\": dr_p.Study4.ALL,\n",
    "    \"Study5\": dr_p.Study5.ALL,\n",
    "    # \"Study6\": dr_p.Study6.ALL,\n",
    "    # \"Study7\": dr_p.Study7.ALL\n",
    "}\n",
    "\n",
    "label_type = \"affect\"\n",
    "\n",
    "for study in popane_phases.keys():\n",
    "    print(f\"{study} \" + \"-\"*60)\n",
    "    phases = popane_phases[study]\n",
    "    for phase in phases:\n",
    "        for metrics in metrics_list:\n",
    "            print(f\"METRICS: {metrics}\")\n",
    "            x, y = train.Train_POPANE.get_popane_data(study, metrics, [phase], verbose=False, label_type=label_type, threshold=threshold)\n",
    "            print(x[x.isna().any(axis=1)].index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
