{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we classify each phase as relatively low or high anxiety for each subject? ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zhoux\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# IMPORTING MODULES\n",
    "import glob\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "cvx_path = os.path.abspath(os.path.join('..', '..', 'cvxEDA', 'src'))\n",
    "module_path = os.path.abspath(os.path.join('..', '..', 'src'))\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy.signal as ss\n",
    "import shap\n",
    "import sys\n",
    "sys.path.append(module_path)\n",
    "\n",
    "import tools.data_reader_apd as dr\n",
    "import tools.display_tools as dt\n",
    "import tools.preprocessing as preprocessing\n",
    "import train\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy.fft import fft, fftfreq, fftshift\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, \\\n",
    "    mean_absolute_error, mean_squared_error, log_loss\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RepeatedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import cvxopt.solvers\n",
    "cvxopt.solvers.options['show_progress'] = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", \n",
    "    category=RuntimeWarning\n",
    ")\n",
    "\n",
    "temp_a, _ = train.Train_APD.get_apd_data_ranking([train.Metrics.BPM], phases=dr.Phases.PHASES_LIST, normalize=False)\n",
    "idx = temp_a[temp_a[\"bpm\"] > 200].index \n",
    "invalid_apd_subjects = set(temp_a[\"subject\"].iloc[idx].tolist())\n",
    "idx = temp_a[temp_a[\"bpm\"] < 35].index \n",
    "invalid_apd_subjects.update(set(temp_a[\"subject\"].iloc[idx].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"LGB\": LGBMClassifier(),\n",
    "    \"RF\": RandomForestClassifier(random_state=16),\n",
    "    \"XGB\": XGBClassifier(random_state=16),\n",
    "    # \"random\": None\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "    \"LGB\": [{\n",
    "        \"objective\": [\"binary\"],\n",
    "        \"num_leaves\": [10, 30, 50, 70],\n",
    "        \"metric\": [\"mean_absolute_error\", \"mean_squared_error\", \"binary_logloss\"]\n",
    "    }],\n",
    "    \"RF\": [{\n",
    "        \"n_estimators\": [10, 50, 100],\n",
    "        \"max_features\": [\"sqrt\"],\n",
    "        \"min_samples_split\": [3, 5, 7]\n",
    "    }],\n",
    "    \"XGB\": [{\n",
    "        \"use_label_encoder\": [False],\n",
    "        \"objective\": [\"binary:logistic\"],\n",
    "        \"eval_metric\": [\"error\", mean_absolute_error, mean_squared_error, log_loss]\n",
    "    }],\n",
    "    # \"random\": None\n",
    "}\n",
    "\n",
    "metrics = [\n",
    "    train.Metrics.BPM, \n",
    "    train.Metrics.RMSSD, \n",
    "    train.Metrics.HF_RR, \n",
    "    train.Metrics.LF_RR, \n",
    "    train.Metrics.SDNN, \n",
    "    train.Metrics.MEAN_SCL, \n",
    "    train.Metrics.SCR_RATE, \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model LGB, Actual: [0 1], [109  85], Predictions: [0 1], [103  91]\n",
      "Model RF, Actual: [0 1], [109  85], Predictions: [0 1], [ 83 111]\n",
      "Model XGB, Actual: [0 1], [109  85], Predictions: [0 1], [116  78]\n",
      "\n",
      "[('sdnn', 788), ('rmssd', 780), ('bpm', 731), ('lf_rr', 654), ('hf_rr', 629)]\n",
      "\n",
      "\n",
      "[('rmssd', 0.2341555623428681), ('sdnn', 0.22415488484028406), ('hf_rr', 0.20066685312665905), ('bpm', 0.18269204451750204), ('lf_rr', 0.15833065517268674)]\n",
      "\n",
      "\n",
      "[('bpm', 0.2270864), ('lf_rr', 0.2149767), ('rmssd', 0.20971696), ('hf_rr', 0.17802972), ('sdnn', 0.17019023)]\n",
      "\n",
      "Model LGB, Actual: [0 1], [84 93], Predictions: [0 1], [122  55]\n",
      "Model RF, Actual: [0 1], [84 93], Predictions: [0 1], [133  44]\n",
      "Model XGB, Actual: [0 1], [84 93], Predictions: [0 1], [135  42]\n",
      "\n",
      "[('rmssd', 230), ('hf_rr', 213), ('bpm', 211), ('lf_rr', 131), ('sdnn', 115)]\n",
      "\n",
      "\n",
      "[('bpm', 0.2357522485368522), ('sdnn', 0.22487866020025343), ('rmssd', 0.20036756562970098), ('hf_rr', 0.17060969621861366), ('lf_rr', 0.16839182941457978)]\n",
      "\n",
      "\n",
      "[('rmssd', 0.23181815), ('sdnn', 0.22525091), ('bpm', 0.203727), ('lf_rr', 0.17310645), ('hf_rr', 0.16609743)]\n",
      "\n",
      "Model LGB, Actual: [0 1], [109 108], Predictions: [0 1], [111 106]\n",
      "Model RF, Actual: [0 1], [109 108], Predictions: [0 1], [128  89]\n",
      "Model XGB, Actual: [0 1], [109 108], Predictions: [0 1], [133  84]\n",
      "\n",
      "[('lf_rr', 799), ('rmssd', 701), ('hf_rr', 665), ('bpm', 651), ('sdnn', 640)]\n",
      "\n",
      "\n",
      "[('rmssd', 0.24674941120991875), ('bpm', 0.22906709408898962), ('hf_rr', 0.20440535811697685), ('sdnn', 0.16032961372153642), ('lf_rr', 0.1594485228625785)]\n",
      "\n",
      "\n",
      "[('rmssd', 0.23320815), ('bpm', 0.20597392), ('lf_rr', 0.19300771), ('hf_rr', 0.19078797), ('sdnn', 0.17702226)]\n",
      "\n",
      "Model LGB, Actual: [0 1], [126  94], Predictions: [0 1], [142  78]\n",
      "Model RF, Actual: [0 1], [126  94], Predictions: [0 1], [139  81]\n",
      "Model XGB, Actual: [0 1], [126  94], Predictions: [0 1], [121  99]\n",
      "\n",
      "[('lf_rr', 215), ('hf_rr', 185), ('rmssd', 178), ('bpm', 173), ('sdnn', 149)]\n",
      "\n",
      "\n",
      "[('bpm', 0.24815191547230658), ('hf_rr', 0.2217355647112091), ('rmssd', 0.20816624306634987), ('sdnn', 0.17360349834543884), ('lf_rr', 0.14834277840469562)]\n",
      "\n",
      "\n",
      "[('lf_rr', 0.23360829), ('sdnn', 0.21076871), ('bpm', 0.19111313), ('rmssd', 0.18711776), ('hf_rr', 0.17739213)]\n",
      "\n",
      "Model LGB, Actual: [0 1], [163  64], Predictions: [0 1], [114 113]\n",
      "Model RF, Actual: [0 1], [163  64], Predictions: [0 1], [117 110]\n",
      "Model XGB, Actual: [0 1], [163  64], Predictions: [0 1], [107 120]\n",
      "\n",
      "[('bpm', 732), ('hf_rr', 728), ('rmssd', 717), ('sdnn', 687), ('lf_rr', 578)]\n",
      "\n",
      "\n",
      "[('bpm', 0.23196268682087642), ('lf_rr', 0.21834629808940673), ('rmssd', 0.19800952280031317), ('hf_rr', 0.1861744097967335), ('sdnn', 0.16550708249267024)]\n",
      "\n",
      "\n",
      "[('hf_rr', 0.24485712), ('bpm', 0.21810542), ('rmssd', 0.20205604), ('lf_rr', 0.19432394), ('sdnn', 0.14065744)]\n",
      "\n",
      "Model evaluation metrics for LGB:\n",
      "\tAccuracy: 0.4845360824742268\n",
      "\tPrecision: 0.4175824175824176\n",
      "\tRecall: 0.4470588235294118\n",
      "\tF1-score: 0.4318181818181818\n",
      "\tAUC score: 0.48041014570966\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.5254237288135594\n",
      "\tPrecision: 0.5818181818181818\n",
      "\tRecall: 0.34408602150537637\n",
      "\tF1-score: 0.43243243243243246\n",
      "\tAUC score: 0.5351382488479263\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.631336405529954\n",
      "\tPrecision: 0.6320754716981132\n",
      "\tRecall: 0.6203703703703703\n",
      "\tF1-score: 0.6261682242990654\n",
      "\tAUC score: 0.6312861026163777\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.6545454545454545\n",
      "\tPrecision: 0.6153846153846154\n",
      "\tRecall: 0.5106382978723404\n",
      "\tF1-score: 0.558139534883721\n",
      "\tAUC score: 0.6362715298885511\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.5903083700440529\n",
      "\tPrecision: 0.37168141592920356\n",
      "\tRecall: 0.65625\n",
      "\tF1-score: 0.47457627118644063\n",
      "\tAUC score: 0.6103335889570553\n",
      "----------------------------------------\n",
      "Mean acc: 0.5772300082814495\n",
      "Mean F1-score: 0.5046269289239682\n",
      "Mean AUC score: 0.578687923203914\n",
      "\n",
      "\n",
      "Model evaluation metrics for RF:\n",
      "\tAccuracy: 0.5463917525773195\n",
      "\tPrecision: 0.4864864864864865\n",
      "\tRecall: 0.6352941176470588\n",
      "\tF1-score: 0.5510204081632654\n",
      "\tAUC score: 0.5561791689152725\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.5988700564971752\n",
      "\tPrecision: 0.75\n",
      "\tRecall: 0.3548387096774194\n",
      "\tF1-score: 0.48175182481751816\n",
      "\tAUC score: 0.6119431643625193\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.6359447004608295\n",
      "\tPrecision: 0.6629213483146067\n",
      "\tRecall: 0.5462962962962963\n",
      "\tF1-score: 0.598984771573604\n",
      "\tAUC score: 0.6355334692490656\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.6409090909090909\n",
      "\tPrecision: 0.5925925925925926\n",
      "\tRecall: 0.5106382978723404\n",
      "\tF1-score: 0.5485714285714286\n",
      "\tAUC score: 0.6243667679837892\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.6740088105726872\n",
      "\tPrecision: 0.45454545454545453\n",
      "\tRecall: 0.78125\n",
      "\tF1-score: 0.5747126436781609\n",
      "\tAUC score: 0.7065759202453987\n",
      "----------------------------------------\n",
      "Mean acc: 0.6192248822034204\n",
      "Mean F1-score: 0.5510082153607954\n",
      "Mean AUC score: 0.6269196981512091\n",
      "\n",
      "\n",
      "Model evaluation metrics for XGB:\n",
      "\tAccuracy: 0.5515463917525774\n",
      "\tPrecision: 0.48717948717948717\n",
      "\tRecall: 0.4470588235294118\n",
      "\tF1-score: 0.46625766871165647\n",
      "\tAUC score: 0.5400431732325958\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.5649717514124294\n",
      "\tPrecision: 0.6904761904761905\n",
      "\tRecall: 0.3118279569892473\n",
      "\tF1-score: 0.42962962962962964\n",
      "\tAUC score: 0.5785330261136712\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.576036866359447\n",
      "\tPrecision: 0.5952380952380952\n",
      "\tRecall: 0.46296296296296297\n",
      "\tF1-score: 0.5208333333333334\n",
      "\tAUC score: 0.5755181787291879\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.6136363636363636\n",
      "\tPrecision: 0.5454545454545454\n",
      "\tRecall: 0.574468085106383\n",
      "\tF1-score: 0.5595854922279793\n",
      "\tAUC score: 0.6086626139817629\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.4977973568281938\n",
      "\tPrecision: 0.2916666666666667\n",
      "\tRecall: 0.546875\n",
      "\tF1-score: 0.3804347826086956\n",
      "\tAUC score: 0.5127013036809815\n",
      "----------------------------------------\n",
      "Mean acc: 0.5607977459978023\n",
      "Mean F1-score: 0.47134818130225886\n",
      "Mean AUC score: 0.5630916591476398\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K-FOLD CROSS-VALIDATION FOR HYPERPARAMETER SELECTION\n",
    "importlib.reload(train)\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "\n",
    "\n",
    "model_phases = [\n",
    "    \"Baseline_Rest\", \n",
    "    \"BugBox_Relax\", \"BugBox_Anticipate\", \"BugBox_Exposure\", \"BugBox_Break\",\n",
    "    \"Speech_Relax\", \"Speech_Anticipate\", \"Speech_Exposure\", \"Speech_Break\"\n",
    "]\n",
    "\n",
    "threshold = \"fixed\"\n",
    "\n",
    "anxiety_label_type = None\n",
    "x, y = train.Train_APD.get_apd_data_ranking(\n",
    "    metrics, model_phases, verbose=False, anxiety_label_type=anxiety_label_type, \n",
    "    threshold=threshold, normalize=True, combine_phases=False\n",
    ")\n",
    "x = x.drop([\"phaseId\"], axis=1)\n",
    "inds = pd.isnull(x).any(axis=1).to_numpy().nonzero()[0]\n",
    "x = x.drop(labels=inds, axis=0).reset_index(drop=True)\n",
    "y = y.drop(labels=inds, axis=0).reset_index(drop=True)\n",
    "\n",
    "# drop subjects with noisy data\n",
    "x = x[~x[\"subject\"].isin(invalid_apd_subjects)].reset_index(drop=True)\n",
    "y = y[~y[\"subject\"].isin(invalid_apd_subjects)].reset_index(drop=True)\n",
    "\n",
    "if anxiety_label_type is not None:\n",
    "    x.drop(labels=[\"anxietyGroup\"], axis=1)\n",
    "    \n",
    "acc_results = {\n",
    "    \"LGB\": [],\n",
    "    \"RF\": [],\n",
    "    \"XGB\": [],\n",
    "    # \"random\": []\n",
    "}\n",
    "reports = {\n",
    "    \"LGB\": [],\n",
    "    \"RF\": [],\n",
    "    \"XGB\": [],\n",
    "    # \"random\": []\n",
    "}\n",
    "best_models = {}\n",
    "\n",
    "num_iters = 5\n",
    "get_importance = True\n",
    "for _ in range(num_iters):\n",
    "    # HYPERPARAMETER TUNING\n",
    "    model_data = train.grid_search_cv(\n",
    "        models, parameters, x, y, by_subject=True, save_metrics=True, is_resample=True,\n",
    "        get_importance=get_importance, drop_subject=True, test_size=0.2, folds=5\n",
    "    )\n",
    "\n",
    "    for model_name in models.keys():\n",
    "        best_models[model_name] = model_data[model_name][\"best_model\"]\n",
    "\n",
    "    # FEATURE SELECTION\n",
    "    x_train, y_train = model_data[\"train\"]\n",
    "    features = train.feature_selection(best_models, model_data[\"cv\"], x_train, y_train, n_features=5)\n",
    "\n",
    "    # TEST USING OPTIMIZED MODELS AND FEATAURES\n",
    "    x_test, y_test = model_data[\"test\"]\n",
    "    out = train.train_test_model(best_models, features, x_train, y_train, x_test, y_test)\n",
    "\n",
    "    for model_name in acc_results:\n",
    "        acc_results[model_name].append(out[model_name][\"performance\"][0])\n",
    "        reports[model_name].append(out[model_name][\"performance\"][1])\n",
    "        if get_importance:\n",
    "            try:\n",
    "                print(\"\")\n",
    "                feature_imp = list(zip(metrics + [\"lf_hf_ratio\"], out[model_name][\"performance\"][2]))\n",
    "                feature_imp = sorted(feature_imp, key=lambda x: x[1], reverse=True)\n",
    "                print(feature_imp)\n",
    "            except Exception as e:\n",
    "                print(out[model_name][\"performance\"][2])\n",
    "            print(\"\")\n",
    "\n",
    "for model_name in acc_results.keys():\n",
    "    print(f\"Model evaluation metrics for {model_name}:\")\n",
    "    for i in range(len(reports[model_name])):\n",
    "        report = reports[model_name][i]\n",
    "        acc = acc_results[model_name][i]\n",
    "        p = report[\"precision\"]\n",
    "        r = report[\"recall\"]\n",
    "        f1 = report[\"f1\"]\n",
    "        auc = report[\"auc\"]\n",
    "        print(f\"\\tAccuracy: {acc}\\n\\tPrecision: {p}\\n\\tRecall: {r}\\n\\tF1-score: {f1}\\n\\tAUC score: {auc}\\n\" + \"-\"*40)\n",
    "    print(f\"Mean acc: {np.mean([acc_results[model_name][i] for i in range(len(reports[model_name]))])}\")\n",
    "    print(f\"Mean F1-score: {np.mean([reports[model_name][i]['f1'] for i in range(len(reports[model_name]))])}\")\n",
    "    print(f\"Mean AUC score: {np.mean([reports[model_name][i]['auc'] for i in range(len(reports[model_name]))])}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD TRAIN AND TEST DATA -- train on some phases and test on others\n",
    "importlib.reload(train)\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "\n",
    "# metrics = train.Metrics.ALL\n",
    "# metrics = train.Metrics.ECG \\\n",
    "    # + train.Metrics.EDA \\\n",
    "    # + train.Metrics.ANKLE + train.Metrics.WRIST\n",
    "\n",
    "metrics = [\n",
    "    train.Metrics.BPM, \n",
    "    train.Metrics.RMSSD, \n",
    "    # train.Metrics.HF_RR, \n",
    "    # train.Metrics.LF_RR, \n",
    "    train.Metrics.IBI, \n",
    "    train.Metrics.SDNN, \n",
    "    train.Metrics.MEAN_SCL, \n",
    "    train.Metrics.SCR_RATE, \n",
    "]\n",
    "\n",
    "phases_a = [\n",
    "    \"Baseline_Rest\", \n",
    "    \"BugBox_Relax\", \n",
    "    \"BugBox_Anticipate\", \n",
    "    # \"BugBox_Exposure\", \n",
    "    # \"BugBox_Break\",\n",
    "    \"Speech_Relax\", \n",
    "    \"Speech_Anticipate\", \n",
    "    # \"Speech_Exposure\", \n",
    "    # \"Speech_Break\"\n",
    "]\n",
    "\n",
    "phases_b = [\n",
    "    # \"Baseline_Rest\", \n",
    "    # \"BugBox_Relax\", \n",
    "    # \"BugBox_Anticipate\", \n",
    "    \"BugBox_Exposure\", \n",
    "    # \"BugBox_Break\",\n",
    "    # \"Speech_Relax\", \n",
    "    # \"Speech_Anticipate\", \n",
    "    \"Speech_Exposure\", \n",
    "    # \"Speech_Break\"\n",
    "]\n",
    "\n",
    "models = {\n",
    "    \"SVM\": SVC(C=10, gamma=1),  # C=10, gamma=1\n",
    "    # \"KNN\": KNeighborsClassifier(n_neighbors=7),\n",
    "    # \"DT\": DecisionTreeClassifier(),\n",
    "    \"LogReg\": LogisticRegression(max_iter=1000),\n",
    "    # \"Bayes\": GaussianNB(),\n",
    "    \"XGB\": XGBClassifier(use_label_encoder=False, objective=\"binary:logistic\", eval_metric=\"logloss\")\n",
    "}\n",
    "\n",
    "anxiety_label_type = \"Anxiety\"\n",
    "# anxiety_label_type = None\n",
    "test_size = 1.0\n",
    "\n",
    "x_a, y_a = train.Train_APD.get_apd_data_ranking(metrics, phases_a, verbose=False, anxiety_label_type=anxiety_label_type)\n",
    "x_b, y_b = train.Train_APD.get_apd_data_ranking(metrics, phases_b, verbose=False, anxiety_label_type=anxiety_label_type)\n",
    "x_a = x_a.drop([\"phaseId\"], axis=1)\n",
    "x_b = x_b.drop([\"phaseId\"], axis=1)\n",
    "\n",
    "# drop subjects with noisy data\n",
    "\n",
    "x_a = x_a[~x_a[\"subject\"].isin(invalid_apd_subjects)]\n",
    "y_a = y_a[~y_a[\"subject\"].isin(invalid_apd_subjects)]\n",
    "x_b = x_b[~x_b[\"subject\"].isin(invalid_apd_subjects)]\n",
    "y_b = y_b[~y_b[\"subject\"].isin(invalid_apd_subjects)]\n",
    "\n",
    "print(f\"y_a:\\n{y_a.loc[:, 'label'].value_counts()}\")\n",
    "print(f\"y_b:\\n{y_b.loc[:, 'label'].value_counts()}\")\n",
    "\n",
    "# x = x[x['subject'] != 8.0]\n",
    "# y = y[y['subject'] != 8.0]\n",
    "\n",
    "if anxiety_label_type is not None:\n",
    "    x_a.drop(labels=[\"anxietyGroup\"], axis=1)\n",
    "    x_b.drop(labels=[\"anxietyGroup\"], axis=1)\n",
    "\n",
    "# 0-1 scaling\n",
    "for i in range(3, len(x_a.columns)):\n",
    "    data_col = x_a[x_a.columns[i]]\n",
    "    data_col = (data_col - data_col.min())/(data_col.max() - data_col.min())\n",
    "    x_a[x_a.columns[i]] = data_col\n",
    "for i in range(3, len(x_b.columns)):\n",
    "    data_col = x_b[x_b.columns[i]]\n",
    "    data_col = (data_col - data_col.min())/(data_col.max() - data_col.min())\n",
    "    x_b[x_b.columns[i]] = data_col\n",
    "    \n",
    "# make sure subjects from different datasets aren't labeled with the same index\n",
    "x_b[\"subject\"] = x_b[\"subject\"] + 500\n",
    "\n",
    "acc_results = {\n",
    "    \"SVM\": [],\n",
    "    \"LogReg\": [],\n",
    "    \"XGB\": []\n",
    "}\n",
    "reports = {\n",
    "    \"SVM\": [],\n",
    "    \"LogReg\": [],\n",
    "    \"XGB\": []\n",
    "}\n",
    "num_iters = 10\n",
    "for _ in range(num_iters):\n",
    "    out = train.Train_Multi_Dataset.train_across_datasets(models, x_a, y_a, x_b, y_b, by_subject=False, save_metrics=True, test_size=test_size)\n",
    "    for model_name in acc_results:\n",
    "        acc_results[model_name].append(out[model_name][0])\n",
    "        reports[model_name].append(out[model_name][1])\n",
    "\n",
    "for model_name in acc_results.keys():\n",
    "    acc = np.mean(acc_results[model_name])\n",
    "    print(f\"{model_name} accuracy over {num_iters} rounds: {acc}\")\n",
    "    if acc > 0.4:\n",
    "        print(f\"Model evaluation metrics for {model_name}:\")\n",
    "        p = np.mean([report[\"precision\"] for report in reports[model_name]])\n",
    "        r = np.mean([report[\"recall\"] for report in reports[model_name]])\n",
    "        f1 = np.mean([report[\"f1\"] for report in reports[model_name]])\n",
    "        auc = np.mean([report[\"auc\"] for report in reports[model_name]])\n",
    "        report = reports[model_name]\n",
    "        print(f\"Precision: {p}\\nRecall: {r}\\nF1-score: {f1}\\nAUC score: {auc}\")\n",
    "    print(\"\")\n",
    "print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5015c0e83de7be3f940d9818fce2964bddf05ca60741c8dac88cf8d83f44e00e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
