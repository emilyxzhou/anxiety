{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we classify each phase as relatively low or high anxiety for each subject? ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zhoux\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# IMPORTING MODULES\n",
    "import glob\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "cvx_path = os.path.abspath(os.path.join('..', '..', 'cvxEDA', 'src'))\n",
    "module_path = os.path.abspath(os.path.join('..', '..', 'src'))\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy.signal as ss\n",
    "import shap\n",
    "import sys\n",
    "sys.path.append(module_path)\n",
    "\n",
    "import tools.data_reader_apd as dr\n",
    "import tools.display_tools as dt\n",
    "import tools.preprocessing as preprocessing\n",
    "import train\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy.fft import fft, fftfreq, fftshift\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, \\\n",
    "    mean_absolute_error, mean_squared_error, log_loss\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RepeatedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import cvxopt.solvers\n",
    "cvxopt.solvers.options['show_progress'] = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", \n",
    "    category=RuntimeWarning\n",
    ")\n",
    "\n",
    "temp_a, _ = train.Train_APD.get_apd_data_ranking([train.Metrics.BPM], phases=dr.Phases.PHASES_LIST, normalize=False)\n",
    "idx = temp_a[temp_a[\"bpm\"] > 200].index \n",
    "invalid_apd_subjects = set(temp_a[\"subject\"].iloc[idx].tolist())\n",
    "idx = temp_a[temp_a[\"bpm\"] < 35].index \n",
    "invalid_apd_subjects.update(set(temp_a[\"subject\"].iloc[idx].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(train)\n",
    "\n",
    "models = {\n",
    "    \"LGB\": LGBMClassifier(),\n",
    "    \"RF\": RandomForestClassifier(random_state=16),\n",
    "    \"XGB\": XGBClassifier(random_state=16),\n",
    "    # \"random\": None\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "    \"LGB\": [{\n",
    "        \"objective\": [\"binary\"],\n",
    "        \"num_leaves\": [10, 20, 30, 40, 50, 70, 80, 200],\n",
    "        \"max_depth\": [3, 4, 5, 6, 7],\n",
    "        \"metric\": [\"mean_absolute_error\", \"mean_squared_error\", \"binary_logloss\"]\n",
    "    }],\n",
    "    \"RF\": [{\n",
    "        \"n_estimators\": [10, 20, 30, 50, 70, 100],\n",
    "        \"max_features\": [\"sqrt\", \"0.4\"],\n",
    "        \"min_samples_split\": [3, 4, 5, 6, 7]\n",
    "    }],\n",
    "    \"XGB\": [{\n",
    "        \"use_label_encoder\": [False],\n",
    "        \"objective\": [\"binary:logistic\"],\n",
    "        \"eval_metric\": [\"error\", \"mean_absolute_error\", \"mean_squared_error\", \"log_loss\"]\n",
    "    }],\n",
    "    # \"random\": None\n",
    "}\n",
    "\n",
    "metrics = [\n",
    "    train.Metrics.BPM, \n",
    "    train.Metrics.RMSSD, \n",
    "    train.Metrics.HF_RR, \n",
    "    train.Metrics.LF_RR, \n",
    "    train.Metrics.SDNN, \n",
    "    train.Metrics.MEAN_SCL, \n",
    "    train.Metrics.SCR_RATE, \n",
    "]\n",
    "# ] + train.Metrics.STATISTICAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more of the test scores are non-finite: [0.60277976 0.6041207  0.61632223 0.62432926 0.61664142 0.61942874\n",
      " 0.56912175 0.60517601 0.61306251 0.62143093 0.6326698  0.63176902\n",
      " 0.51888695 0.57815733 0.59757099 0.61197012 0.61757299 0.62700877\n",
      " 0.57817657 0.5958038  0.59603263 0.60447012 0.60685386 0.61004312\n",
      " 0.59562917 0.6134173  0.58582674 0.59995139 0.61952991 0.62455345\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "One or more of the test scores are non-finite: [0.61692306        nan        nan        nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGB: {'max_depth': 4, 'metric': 'mean_absolute_error', 'num_leaves': 20, 'objective': 'binary'}\n",
      "RF: {'max_features': 'sqrt', 'min_samples_split': 4, 'n_estimators': 70}\n",
      "XGB: {'eval_metric': 'error', 'objective': 'binary:logistic', 'use_label_encoder': False}\n",
      "Model LGB, Actual: [0 1], [111 114], Predictions: [0 1], [135  90]\n",
      "Model RF, Actual: [0 1], [111 114], Predictions: [0 1], [125 100]\n",
      "Model XGB, Actual: [0 1], [111 114], Predictions: [0 1], [149  76]\n",
      "\n",
      "[('hf_rr', 224), ('lf_rr', 210), ('rmssd', 206), ('bpm', 174)]\n",
      "\n",
      "\n",
      "[('rmssd', 0.2936771117626445), ('bpm', 0.2563499253585739), ('lf_rr', 0.22949072083150343), ('hf_rr', 0.22048224204727823)]\n",
      "\n",
      "\n",
      "[('bpm', 0.2851473), ('hf_rr', 0.25624493), ('rmssd', 0.23518357), ('lf_rr', 0.2234242)]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more of the test scores are non-finite: [0.58179426 0.62316955 0.63225722 0.64131767 0.62997349 0.62659064\n",
      " 0.63005903 0.63692618 0.61947536 0.63219056 0.63069866 0.62358633\n",
      " 0.61909236 0.65961206 0.64415398 0.65374199 0.63689823 0.63847481\n",
      " 0.61893158 0.6434586  0.64112968 0.64134317 0.63249119 0.62494946\n",
      " 0.60369778 0.61937785 0.61367839 0.61671009 0.60844298 0.6185491\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "One or more of the test scores are non-finite: [0.61513538        nan        nan        nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGB: {'max_depth': 7, 'metric': 'mean_absolute_error', 'num_leaves': 30, 'objective': 'binary'}\n",
      "RF: {'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 20}\n",
      "XGB: {'eval_metric': 'error', 'objective': 'binary:logistic', 'use_label_encoder': False}\n",
      "Model LGB, Actual: [0 1], [112 111], Predictions: [0 1], [135  88]\n",
      "Model RF, Actual: [0 1], [112 111], Predictions: [0 1], [137  86]\n",
      "Model XGB, Actual: [0 1], [112 111], Predictions: [0 1], [157  66]\n",
      "\n",
      "[('hf_rr', 439), ('bpm', 419), ('lf_rr', 389), ('rmssd', 351)]\n",
      "\n",
      "\n",
      "[('lf_rr', 0.28321863529819524), ('hf_rr', 0.25057990308619515), ('rmssd', 0.24395123482049402), ('bpm', 0.22225022679511555)]\n",
      "\n",
      "\n",
      "[('lf_rr', 0.2817231), ('bpm', 0.25734845), ('rmssd', 0.25047836), ('hf_rr', 0.21045013)]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more of the test scores are non-finite: [0.56419407 0.61347433 0.64339366 0.66913608 0.68120504 0.68892669\n",
      " 0.62429638 0.6471312  0.64710893 0.66639592 0.67732438 0.68277948\n",
      " 0.61639242 0.67329632 0.6666831  0.67640363 0.68520365 0.69029976\n",
      " 0.60850798 0.67127059 0.67461003 0.68281799 0.70002366 0.69745454\n",
      " 0.62429477 0.64446725 0.66909729 0.67884986 0.68831212 0.68616797\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "One or more of the test scores are non-finite: [0.64473149        nan        nan        nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGB: {'max_depth': 5, 'metric': 'mean_absolute_error', 'num_leaves': 10, 'objective': 'binary'}\n",
      "RF: {'max_features': 'sqrt', 'min_samples_split': 6, 'n_estimators': 70}\n",
      "XGB: {'eval_metric': 'error', 'objective': 'binary:logistic', 'use_label_encoder': False}\n",
      "Model LGB, Actual: [0 1], [94 85], Predictions: [0 1], [127  52]\n",
      "Model RF, Actual: [0 1], [94 85], Predictions: [0 1], [114  65]\n",
      "Model XGB, Actual: [0 1], [94 85], Predictions: [0 1], [102  77]\n",
      "\n",
      "[('bpm', 229), ('rmssd', 227), ('hf_rr', 215), ('lf_rr', 175)]\n",
      "\n",
      "\n",
      "[('rmssd', 0.2703471534978716), ('bpm', 0.2574493906956561), ('lf_rr', 0.24237960334735975), ('hf_rr', 0.22982385245911266)]\n",
      "\n",
      "\n",
      "[('rmssd', 0.28142604), ('hf_rr', 0.276341), ('bpm', 0.25282317), ('lf_rr', 0.18940987)]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more of the test scores are non-finite: [0.61521918 0.61066554 0.59741198 0.61031523 0.61106045 0.6333598\n",
      " 0.60840856 0.5989574  0.59705889 0.5987344  0.59584727 0.60171367\n",
      " 0.58994249 0.60472064 0.5936025  0.59803454 0.59978473 0.6132946\n",
      " 0.58855205 0.57552664 0.58232287 0.60040318 0.60054893 0.61597262\n",
      " 0.58126009 0.58694982 0.58090855 0.58772438 0.58590301 0.60024731\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "One or more of the test scores are non-finite: [0.61900672        nan        nan        nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGB: {'max_depth': 6, 'metric': 'mean_absolute_error', 'num_leaves': 30, 'objective': 'binary'}\n",
      "RF: {'max_features': 'sqrt', 'min_samples_split': 3, 'n_estimators': 100}\n",
      "XGB: {'eval_metric': 'error', 'objective': 'binary:logistic', 'use_label_encoder': False}\n",
      "Model LGB, Actual: [0 1], [118  84], Predictions: [0 1], [162  40]\n",
      "Model RF, Actual: [0 1], [118  84], Predictions: [0 1], [154  48]\n",
      "Model XGB, Actual: [0 1], [118  84], Predictions: [0 1], [138  64]\n",
      "\n",
      "[('bpm', 399), ('rmssd', 353), ('hf_rr', 298), ('lf_rr', 258)]\n",
      "\n",
      "\n",
      "[('bpm', 0.3330015464940695), ('lf_rr', 0.2373363729514384), ('hf_rr', 0.21835855609539684), ('rmssd', 0.2113035244590953)]\n",
      "\n",
      "\n",
      "[('hf_rr', 0.29039967), ('lf_rr', 0.27446422), ('bpm', 0.23537219), ('rmssd', 0.19976388)]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more of the test scores are non-finite: [0.56022199 0.52965957 0.54875502 0.53522081 0.54976785 0.55778556\n",
      " 0.57192522 0.52172082 0.53701083 0.54596861 0.55028025 0.53418145\n",
      " 0.59737716 0.56096987 0.5667471  0.53776063 0.53935471 0.52904269\n",
      " 0.54414713 0.52933184 0.52865169 0.52247666 0.52280417 0.52005149\n",
      " 0.53017648 0.51001612 0.51847586 0.53067633 0.546904   0.53935308\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "One or more of the test scores are non-finite: [0.57249953        nan        nan        nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGB: {'max_depth': 7, 'metric': 'mean_absolute_error', 'num_leaves': 20, 'objective': 'binary'}\n",
      "RF: {'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 10}\n",
      "XGB: {'eval_metric': 'error', 'objective': 'binary:logistic', 'use_label_encoder': False}\n",
      "Model LGB, Actual: [0 1], [140  61], Predictions: [0 1], [133  68]\n",
      "Model RF, Actual: [0 1], [140  61], Predictions: [0 1], [127  74]\n",
      "Model XGB, Actual: [0 1], [140  61], Predictions: [0 1], [121  80]\n",
      "\n",
      "[('bpm', 375), ('hf_rr', 354), ('rmssd', 341), ('lf_rr', 321)]\n",
      "\n",
      "\n",
      "[('hf_rr', 0.29005088399191736), ('bpm', 0.2533397945560006), ('lf_rr', 0.2379164917049505), ('rmssd', 0.21869282974713156)]\n",
      "\n",
      "\n",
      "[('rmssd', 0.262846), ('bpm', 0.259759), ('lf_rr', 0.25734034), ('hf_rr', 0.22005466)]\n",
      "\n",
      "Model evaluation metrics for LGB:\n",
      "\tAccuracy: 0.49333333333333335\n",
      "\tPrecision: 0.5\n",
      "\tRecall: 0.39473684210526316\n",
      "\tF1-score: 0.4411764705882353\n",
      "\tAUC score: 0.49466571834992884\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.5201793721973094\n",
      "\tPrecision: 0.5227272727272727\n",
      "\tRecall: 0.4144144144144144\n",
      "\tF1-score: 0.4623115577889447\n",
      "\tAUC score: 0.5197072072072072\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.5921787709497207\n",
      "\tPrecision: 0.6153846153846154\n",
      "\tRecall: 0.3764705882352941\n",
      "\tF1-score: 0.46715328467153283\n",
      "\tAUC score: 0.5818523153942428\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.5643564356435643\n",
      "\tPrecision: 0.45\n",
      "\tRecall: 0.21428571428571427\n",
      "\tF1-score: 0.29032258064516125\n",
      "\tAUC score: 0.5139225181598063\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.6666666666666666\n",
      "\tPrecision: 0.45588235294117646\n",
      "\tRecall: 0.5081967213114754\n",
      "\tF1-score: 0.4806201550387597\n",
      "\tAUC score: 0.6219555035128805\n",
      "----------------------------------------\n",
      "Mean acc: 0.5673429157581189\n",
      "Mean F1-score: 0.42831680974652675\n",
      "Mean AUC score: 0.5464206525248131\n",
      "\n",
      "\n",
      "Model evaluation metrics for RF:\n",
      "\tAccuracy: 0.47555555555555556\n",
      "\tPrecision: 0.48\n",
      "\tRecall: 0.42105263157894735\n",
      "\tF1-score: 0.44859813084112143\n",
      "\tAUC score: 0.47629208155523944\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.600896860986547\n",
      "\tPrecision: 0.627906976744186\n",
      "\tRecall: 0.4864864864864865\n",
      "\tF1-score: 0.548223350253807\n",
      "\tAUC score: 0.6003861003861003\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.553072625698324\n",
      "\tPrecision: 0.5384615384615384\n",
      "\tRecall: 0.4117647058823529\n",
      "\tF1-score: 0.4666666666666667\n",
      "\tAUC score: 0.5463078848560701\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.5742574257425742\n",
      "\tPrecision: 0.4791666666666667\n",
      "\tRecall: 0.27380952380952384\n",
      "\tF1-score: 0.3484848484848485\n",
      "\tAUC score: 0.5309725585149313\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.6169154228855721\n",
      "\tPrecision: 0.3918918918918919\n",
      "\tRecall: 0.47540983606557374\n",
      "\tF1-score: 0.42962962962962964\n",
      "\tAUC score: 0.5769906323185011\n",
      "----------------------------------------\n",
      "Mean acc: 0.5641395781737145\n",
      "Mean F1-score: 0.4483205251752146\n",
      "Mean AUC score: 0.5461898515261685\n",
      "\n",
      "\n",
      "Model evaluation metrics for XGB:\n",
      "\tAccuracy: 0.5822222222222222\n",
      "\tPrecision: 0.631578947368421\n",
      "\tRecall: 0.42105263157894735\n",
      "\tF1-score: 0.5052631578947367\n",
      "\tAUC score: 0.5844001896633476\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.6636771300448431\n",
      "\tPrecision: 0.7727272727272727\n",
      "\tRecall: 0.4594594594594595\n",
      "\tF1-score: 0.576271186440678\n",
      "\tAUC score: 0.662765444015444\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.5754189944134078\n",
      "\tPrecision: 0.5584415584415584\n",
      "\tRecall: 0.5058823529411764\n",
      "\tF1-score: 0.5308641975308641\n",
      "\tAUC score: 0.572090112640801\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.44554455445544555\n",
      "\tPrecision: 0.28125\n",
      "\tRecall: 0.21428571428571427\n",
      "\tF1-score: 0.2432432432432432\n",
      "\tAUC score: 0.4122276029055689\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.6268656716417911\n",
      "\tPrecision: 0.4125\n",
      "\tRecall: 0.5409836065573771\n",
      "\tF1-score: 0.46808510638297873\n",
      "\tAUC score: 0.6026346604215458\n",
      "----------------------------------------\n",
      "Mean acc: 0.578745714555542\n",
      "Mean F1-score: 0.46474537829850016\n",
      "Mean AUC score: 0.5668236019293416\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K-FOLD CROSS-VALIDATION FOR HYPERPARAMETER SELECTION\n",
    "importlib.reload(train)\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "\n",
    "\n",
    "model_phases = [\n",
    "    \"Baseline_Rest\", \n",
    "    \"BugBox_Relax\", \"BugBox_Anticipate\", \"BugBox_Exposure\", \"BugBox_Break\",\n",
    "    \"Speech_Relax\", \"Speech_Anticipate\", \"Speech_Exposure\", \"Speech_Break\"\n",
    "]\n",
    "\n",
    "threshold = \"fixed\"\n",
    "\n",
    "anxiety_label_type = None\n",
    "x, y = train.Train_APD.get_apd_data_ranking(\n",
    "    metrics, model_phases, verbose=False, anxiety_label_type=anxiety_label_type, \n",
    "    threshold=threshold, normalize=True, combine_phases=False\n",
    ")\n",
    "x = x.drop([\"phaseId\"], axis=1)\n",
    "inds = pd.isnull(x).any(axis=1).to_numpy().nonzero()[0]\n",
    "x = x.drop(labels=inds, axis=0).reset_index(drop=True)\n",
    "y = y.drop(labels=inds, axis=0).reset_index(drop=True)\n",
    "\n",
    "# drop subjects with noisy data\n",
    "x = x[~x[\"subject\"].isin(invalid_apd_subjects)].reset_index(drop=True)\n",
    "y = y[~y[\"subject\"].isin(invalid_apd_subjects)].reset_index(drop=True)\n",
    "\n",
    "if anxiety_label_type is not None:\n",
    "    x.drop(labels=[\"anxietyGroup\"], axis=1)\n",
    "    \n",
    "acc_results = {\n",
    "    \"LGB\": [],\n",
    "    \"RF\": [],\n",
    "    \"XGB\": [],\n",
    "    # \"random\": []\n",
    "}\n",
    "reports = {\n",
    "    \"LGB\": [],\n",
    "    \"RF\": [],\n",
    "    \"XGB\": [],\n",
    "    # \"random\": []\n",
    "}\n",
    "best_models = {}\n",
    "\n",
    "num_iters = 5\n",
    "get_importance = True\n",
    "for _ in range(num_iters):\n",
    "    # HYPERPARAMETER TUNING\n",
    "    model_data = train.grid_search_cv(\n",
    "        models, parameters, x, y, by_subject=True, save_metrics=True, is_resample=True,\n",
    "        get_importance=get_importance, drop_subject=True, test_size=0.2, folds=5\n",
    "    )\n",
    "\n",
    "    for model_name in models.keys():\n",
    "        best_models[model_name] = model_data[model_name][\"best_model\"]\n",
    "        print(f\"{model_name}: {model_data[model_name]['best_params']}\")\n",
    "\n",
    "    # # FEATURE SELECTION\n",
    "    x_train, y_train = model_data[\"train\"]\n",
    "    # features = {name: metrics for name in models.keys()}\n",
    "    features = train.feature_selection(best_models, model_data[\"cv\"], x_train, y_train, n_features=4)\n",
    "\n",
    "    # TEST USING OPTIMIZED MODELS AND FEATAURES\n",
    "    x_test, y_test = model_data[\"test\"]\n",
    "    out = train.train_test_model(best_models, features, x_train, y_train, x_test, y_test)\n",
    "\n",
    "    for model_name in acc_results:\n",
    "        acc_results[model_name].append(out[model_name][\"performance\"][0])\n",
    "        reports[model_name].append(out[model_name][\"performance\"][1])\n",
    "        if get_importance:\n",
    "            try:\n",
    "                print(\"\")\n",
    "                feature_imp = list(zip(metrics + [\"lf_hf_ratio\"], out[model_name][\"performance\"][2]))\n",
    "                feature_imp = sorted(feature_imp, key=lambda x: x[1], reverse=True)\n",
    "                print(feature_imp)\n",
    "            except Exception as e:\n",
    "                print(out[model_name][\"performance\"][2])\n",
    "            print(\"\")\n",
    "\n",
    "for model_name in acc_results.keys():\n",
    "    print(f\"Model evaluation metrics for {model_name}:\")\n",
    "    for i in range(len(reports[model_name])):\n",
    "        report = reports[model_name][i]\n",
    "        acc = acc_results[model_name][i]\n",
    "        p = report[\"precision\"]\n",
    "        r = report[\"recall\"]\n",
    "        f1 = report[\"f1\"]\n",
    "        auc = report[\"auc\"]\n",
    "        print(f\"\\tAccuracy: {acc}\\n\\tPrecision: {p}\\n\\tRecall: {r}\\n\\tF1-score: {f1}\\n\\tAUC score: {auc}\\n\" + \"-\"*40)\n",
    "    print(f\"Mean acc: {np.mean([acc_results[model_name][i] for i in range(len(reports[model_name]))])}\")\n",
    "    print(f\"Mean F1-score: {np.mean([reports[model_name][i]['f1'] for i in range(len(reports[model_name]))])}\")\n",
    "    print(f\"Mean AUC score: {np.mean([reports[model_name][i]['auc'] for i in range(len(reports[model_name]))])}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD TRAIN AND TEST DATA -- train on some phases and test on others\n",
    "importlib.reload(train)\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "\n",
    "# metrics = train.Metrics.ALL\n",
    "# metrics = train.Metrics.ECG \\\n",
    "    # + train.Metrics.EDA \\\n",
    "    # + train.Metrics.ANKLE + train.Metrics.WRIST\n",
    "\n",
    "metrics = [\n",
    "    train.Metrics.BPM, \n",
    "    train.Metrics.RMSSD, \n",
    "    # train.Metrics.HF_RR, \n",
    "    # train.Metrics.LF_RR, \n",
    "    train.Metrics.IBI, \n",
    "    train.Metrics.SDNN, \n",
    "    train.Metrics.MEAN_SCL, \n",
    "    train.Metrics.SCR_RATE, \n",
    "]\n",
    "\n",
    "phases_a = [\n",
    "    \"Baseline_Rest\", \n",
    "    \"BugBox_Relax\", \n",
    "    \"BugBox_Anticipate\", \n",
    "    # \"BugBox_Exposure\", \n",
    "    # \"BugBox_Break\",\n",
    "    \"Speech_Relax\", \n",
    "    \"Speech_Anticipate\", \n",
    "    # \"Speech_Exposure\", \n",
    "    # \"Speech_Break\"\n",
    "]\n",
    "\n",
    "phases_b = [\n",
    "    # \"Baseline_Rest\", \n",
    "    # \"BugBox_Relax\", \n",
    "    # \"BugBox_Anticipate\", \n",
    "    \"BugBox_Exposure\", \n",
    "    # \"BugBox_Break\",\n",
    "    # \"Speech_Relax\", \n",
    "    # \"Speech_Anticipate\", \n",
    "    \"Speech_Exposure\", \n",
    "    # \"Speech_Break\"\n",
    "]\n",
    "\n",
    "models = {\n",
    "    \"SVM\": SVC(C=10, gamma=1),  # C=10, gamma=1\n",
    "    # \"KNN\": KNeighborsClassifier(n_neighbors=7),\n",
    "    # \"DT\": DecisionTreeClassifier(),\n",
    "    \"LogReg\": LogisticRegression(max_iter=1000),\n",
    "    # \"Bayes\": GaussianNB(),\n",
    "    \"XGB\": XGBClassifier(use_label_encoder=False, objective=\"binary:logistic\", eval_metric=\"logloss\")\n",
    "}\n",
    "\n",
    "anxiety_label_type = \"Anxiety\"\n",
    "# anxiety_label_type = None\n",
    "test_size = 1.0\n",
    "\n",
    "x_a, y_a = train.Train_APD.get_apd_data_ranking(metrics, phases_a, verbose=False, anxiety_label_type=anxiety_label_type)\n",
    "x_b, y_b = train.Train_APD.get_apd_data_ranking(metrics, phases_b, verbose=False, anxiety_label_type=anxiety_label_type)\n",
    "x_a = x_a.drop([\"phaseId\"], axis=1)\n",
    "x_b = x_b.drop([\"phaseId\"], axis=1)\n",
    "\n",
    "# drop subjects with noisy data\n",
    "\n",
    "x_a = x_a[~x_a[\"subject\"].isin(invalid_apd_subjects)]\n",
    "y_a = y_a[~y_a[\"subject\"].isin(invalid_apd_subjects)]\n",
    "x_b = x_b[~x_b[\"subject\"].isin(invalid_apd_subjects)]\n",
    "y_b = y_b[~y_b[\"subject\"].isin(invalid_apd_subjects)]\n",
    "\n",
    "print(f\"y_a:\\n{y_a.loc[:, 'label'].value_counts()}\")\n",
    "print(f\"y_b:\\n{y_b.loc[:, 'label'].value_counts()}\")\n",
    "\n",
    "# x = x[x['subject'] != 8.0]\n",
    "# y = y[y['subject'] != 8.0]\n",
    "\n",
    "if anxiety_label_type is not None:\n",
    "    x_a.drop(labels=[\"anxietyGroup\"], axis=1)\n",
    "    x_b.drop(labels=[\"anxietyGroup\"], axis=1)\n",
    "\n",
    "# 0-1 scaling\n",
    "for i in range(3, len(x_a.columns)):\n",
    "    data_col = x_a[x_a.columns[i]]\n",
    "    data_col = (data_col - data_col.min())/(data_col.max() - data_col.min())\n",
    "    x_a[x_a.columns[i]] = data_col\n",
    "for i in range(3, len(x_b.columns)):\n",
    "    data_col = x_b[x_b.columns[i]]\n",
    "    data_col = (data_col - data_col.min())/(data_col.max() - data_col.min())\n",
    "    x_b[x_b.columns[i]] = data_col\n",
    "    \n",
    "# make sure subjects from different datasets aren't labeled with the same index\n",
    "x_b[\"subject\"] = x_b[\"subject\"] + 500\n",
    "\n",
    "acc_results = {\n",
    "    \"SVM\": [],\n",
    "    \"LogReg\": [],\n",
    "    \"XGB\": []\n",
    "}\n",
    "reports = {\n",
    "    \"SVM\": [],\n",
    "    \"LogReg\": [],\n",
    "    \"XGB\": []\n",
    "}\n",
    "num_iters = 10\n",
    "for _ in range(num_iters):\n",
    "    out = train.Train_Multi_Dataset.train_across_datasets(models, x_a, y_a, x_b, y_b, by_subject=False, save_metrics=True, test_size=test_size)\n",
    "    for model_name in acc_results:\n",
    "        acc_results[model_name].append(out[model_name][0])\n",
    "        reports[model_name].append(out[model_name][1])\n",
    "\n",
    "for model_name in acc_results.keys():\n",
    "    acc = np.mean(acc_results[model_name])\n",
    "    print(f\"{model_name} accuracy over {num_iters} rounds: {acc}\")\n",
    "    if acc > 0.4:\n",
    "        print(f\"Model evaluation metrics for {model_name}:\")\n",
    "        p = np.mean([report[\"precision\"] for report in reports[model_name]])\n",
    "        r = np.mean([report[\"recall\"] for report in reports[model_name]])\n",
    "        f1 = np.mean([report[\"f1\"] for report in reports[model_name]])\n",
    "        auc = np.mean([report[\"auc\"] for report in reports[model_name]])\n",
    "        report = reports[model_name]\n",
    "        print(f\"Precision: {p}\\nRecall: {r}\\nF1-score: {f1}\\nAUC score: {auc}\")\n",
    "    print(\"\")\n",
    "print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5015c0e83de7be3f940d9818fce2964bddf05ca60741c8dac88cf8d83f44e00e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
