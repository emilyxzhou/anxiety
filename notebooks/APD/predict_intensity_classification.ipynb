{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we classify each phase as relatively low or high anxiety for each subject? ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING MODULES\n",
    "import glob\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "cvx_path = os.path.abspath(os.path.join('..', '..', 'cvxEDA', 'src'))\n",
    "module_path = os.path.abspath(os.path.join('..', '..', 'src'))\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy.signal as ss\n",
    "import shap\n",
    "import sys\n",
    "sys.path.append(module_path)\n",
    "\n",
    "import tools.data_reader_apd as dr\n",
    "import tools.display_tools as dt\n",
    "import tools.preprocessing as preprocessing\n",
    "import train\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy.fft import fft, fftfreq, fftshift\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, \\\n",
    "    mean_absolute_error, mean_squared_error, log_loss\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RepeatedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import cvxopt.solvers\n",
    "cvxopt.solvers.options['show_progress'] = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", \n",
    "    category=RuntimeWarning\n",
    ")\n",
    "\n",
    "temp_a, _ = train.Train_APD.get_apd_data_ranking([train.Metrics.BPM], phases=dr.Phases.PHASES_LIST, normalize=False)\n",
    "idx = temp_a[temp_a[\"bpm\"] > 200].index \n",
    "invalid_apd_subjects = set(temp_a[\"subject\"].iloc[idx].tolist())\n",
    "idx = temp_a[temp_a[\"bpm\"] < 35].index \n",
    "invalid_apd_subjects.update(set(temp_a[\"subject\"].iloc[idx].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(train)\n",
    "\n",
    "models = {\n",
    "    \"SVM\": SVC(),\n",
    "    \"LGB\": LGBMClassifier(),\n",
    "    \"RF\": RandomForestClassifier(random_state=16),\n",
    "    \"XGB\": XGBClassifier(random_state=16),\n",
    "    # \"random\": None\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "    \"SVM\": [{\n",
    "        \"kernel\": [\"rbf\", \"poly\", \"sigmoid\"],\n",
    "        \"C\": [0.1, 1, 10, 100],\n",
    "        \"gamma\": [1, 0.1, 0.01, 0.001, \"scale\", \"auto\"],\n",
    "    }],\n",
    "    \"LGB\": [{\n",
    "        \"objective\": [\"binary\"],\n",
    "        \"num_leaves\": [10, 20, 30, 40, 50],\n",
    "        \"max_depth\": [3, 4, 5, 6, 7],\n",
    "        \"metric\": [\"mean_absolute_error\", \"mean_squared_error\", \"binary_logloss\"]\n",
    "    }],\n",
    "    \"RF\": [{\n",
    "        \"n_estimators\": [10, 20, 30, 40, 50],\n",
    "        \"max_features\": [\"sqrt\", \"0.4\"],\n",
    "        \"min_samples_split\": [3, 4, 5, 6, 7],\n",
    "        \"random_state\": [16]\n",
    "    }],\n",
    "    \"XGB\": [{\n",
    "        \"objective\": [\"binary:logistic\"],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.3, 0.5],\n",
    "        \"max_depth\": [4, 5, 6, 7],\n",
    "        \"n_estimators\": [10, 20, 30, 40, 50],\n",
    "        \"eval_metric\": [\"error\"],\n",
    "        \"use_label_encoder\": [False],\n",
    "        \"random_state\": [16]\n",
    "    }],\n",
    "    # \"random\": None\n",
    "}\n",
    "\n",
    "metrics = [\n",
    "    train.Metrics.BPM, \n",
    "    train.Metrics.RMSSD, \n",
    "    train.Metrics.HF_RR, \n",
    "    train.Metrics.LF_RR, \n",
    "    train.Metrics.SDNN, \n",
    "    train.Metrics.MEAN_SCL, \n",
    "    train.Metrics.SCR_RATE, \n",
    "# ]\n",
    "] + train.Metrics.STATISTICAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search for SVM ...\n",
      "Grid search for LGB ...\n",
      "Grid search for RF ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more of the test scores are non-finite: [0.62561187 0.63304422 0.62665    0.6347437  0.63474028 0.61534931\n",
      " 0.63112093 0.63723654 0.62662994 0.63457461 0.61718166 0.6216823\n",
      " 0.62571921 0.62176901 0.62754308 0.59891376 0.62537858 0.62892599\n",
      " 0.62827158 0.6339188  0.59819141 0.61827247 0.62974246 0.63525012\n",
      " 0.63689941        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search for XGB ...\n",
      "SVM: {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "LGB: {'max_depth': 4, 'metric': 'mean_absolute_error', 'num_leaves': 20, 'objective': 'binary'}\n",
      "RF: {'max_features': 'sqrt', 'min_samples_split': 4, 'n_estimators': 30, 'random_state': 16}\n",
      "XGB: {'eval_metric': 'error', 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 10, 'objective': 'binary:logistic', 'random_state': 16, 'use_label_encoder': False}\n",
      "Feature selection for SVM ...\n",
      "Feature selection for LGB ...\n",
      "Feature selection for RF ...\n",
      "Feature selection for XGB ...\n",
      "Training SVM ...\n",
      "Model SVM, Actual: [0 1], [49 18], Predictions: [0 1], [64  3]\n",
      "coef_ only available for SVC with linear kernel\n",
      "Training LGB ...\n",
      "Model LGB, Actual: [0 1], [49 18], Predictions: [0 1], [52 15]\n",
      "Training RF ...\n",
      "Model RF, Actual: [0 1], [49 18], Predictions: [0 1], [43 24]\n",
      "Training XGB ...\n",
      "Model XGB, Actual: [0 1], [49 18], Predictions: [0 1], [55 12]\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "[('hf_rr', 176), ('rmssd', 145), ('sdnn', 140), ('bpm', 128), ('lf_rr', 120)]\n",
      "\n",
      "\n",
      "[('lf_rr', 0.23613240733781268), ('bpm', 0.20198804809204432), ('sdnn', 0.19966930043900524), ('rmssd', 0.18299273640970998), ('hf_rr', 0.1792175077214279)]\n",
      "\n",
      "\n",
      "[('sdnn', 0.455077), ('rmssd', 0.18296248), ('lf_rr', 0.17422174), ('hf_rr', 0.12303862), ('bpm', 0.06470022)]\n",
      "\n",
      "Grid search for SVM ...\n",
      "Grid search for LGB ...\n",
      "Grid search for RF ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more of the test scores are non-finite: [0.57255201 0.59406025 0.60945273 0.61327355 0.62014908 0.56460943\n",
      " 0.58172214 0.58391804 0.5924106  0.60019586 0.57358257 0.5853035\n",
      " 0.58747729 0.59524329 0.60415909 0.56188191 0.58865565 0.58932781\n",
      " 0.60498549 0.59938961 0.56303651 0.5896984  0.587295   0.58956401\n",
      " 0.59270737        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search for XGB ...\n",
      "SVM: {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "LGB: {'max_depth': 3, 'metric': 'mean_absolute_error', 'num_leaves': 10, 'objective': 'binary'}\n",
      "RF: {'max_features': 'sqrt', 'min_samples_split': 3, 'n_estimators': 50, 'random_state': 16}\n",
      "XGB: {'eval_metric': 'error', 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50, 'objective': 'binary:logistic', 'random_state': 16, 'use_label_encoder': False}\n",
      "Feature selection for SVM ...\n",
      "Feature selection for LGB ...\n",
      "Feature selection for RF ...\n",
      "Feature selection for XGB ...\n",
      "Training SVM ...\n",
      "Model SVM, Actual: [0 1], [34 38], Predictions: [0 1], [45 27]\n",
      "coef_ only available for SVC with linear kernel\n",
      "Training LGB ...\n",
      "Model LGB, Actual: [0 1], [34 38], Predictions: [0 1], [54 18]\n",
      "Training RF ...\n",
      "Model RF, Actual: [0 1], [34 38], Predictions: [0 1], [52 20]\n",
      "Training XGB ...\n",
      "Model XGB, Actual: [0 1], [34 38], Predictions: [0 1], [54 18]\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "[('bpm', 116), ('lf_rr', 102), ('rmssd', 101), ('sdnn', 85), ('hf_rr', 64)]\n",
      "\n",
      "\n",
      "[('rmssd', 0.27051762356333603), ('bpm', 0.19211888653475678), ('lf_rr', 0.18974933392025395), ('hf_rr', 0.18750234289459136), ('sdnn', 0.16011181308706188)]\n",
      "\n",
      "\n",
      "[('lf_rr', 0.21957827), ('bpm', 0.20762926), ('rmssd', 0.2045404), ('hf_rr', 0.18784241), ('sdnn', 0.18040958)]\n",
      "\n",
      "Grid search for SVM ...\n",
      "Grid search for LGB ...\n",
      "Grid search for RF ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more of the test scores are non-finite: [0.58596971 0.59013722 0.60379446 0.61526452 0.61306062 0.57630877\n",
      " 0.57458006 0.58162518 0.59327881 0.6003925  0.57808218 0.58306627\n",
      " 0.59267392 0.60158148 0.60827214 0.57188451 0.57968174 0.58789628\n",
      " 0.59999639 0.61505834 0.57915945 0.57758835 0.59657561 0.60031752\n",
      " 0.59872115        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search for XGB ...\n",
      "SVM: {'C': 100, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "LGB: {'max_depth': 3, 'metric': 'mean_absolute_error', 'num_leaves': 10, 'objective': 'binary'}\n",
      "RF: {'max_features': 'sqrt', 'min_samples_split': 3, 'n_estimators': 40, 'random_state': 16}\n",
      "XGB: {'eval_metric': 'error', 'learning_rate': 0.3, 'max_depth': 7, 'n_estimators': 20, 'objective': 'binary:logistic', 'random_state': 16, 'use_label_encoder': False}\n",
      "Feature selection for SVM ...\n",
      "Feature selection for LGB ...\n",
      "Feature selection for RF ...\n",
      "Feature selection for XGB ...\n",
      "Training SVM ...\n",
      "Model SVM, Actual: [0 1], [35 29], Predictions: [0 1], [42 22]\n",
      "coef_ only available for SVC with linear kernel\n",
      "Training LGB ...\n",
      "Model LGB, Actual: [0 1], [35 29], Predictions: [0 1], [54 10]\n",
      "Training RF ...\n",
      "Model RF, Actual: [0 1], [35 29], Predictions: [0 1], [42 22]\n",
      "Training XGB ...\n",
      "Model XGB, Actual: [0 1], [35 29], Predictions: [0 1], [42 22]\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "[('bpm', 109), ('rmssd', 102), ('hf_rr', 98), ('lf_rr', 97), ('sdnn', 89)]\n",
      "\n",
      "\n",
      "[('lf_rr', 0.25162886955702735), ('rmssd', 0.20163251482226374), ('bpm', 0.1914739655736523), ('hf_rr', 0.18972453863777564), ('sdnn', 0.16554011140928107)]\n",
      "\n",
      "\n",
      "[('rmssd', 0.25098878), ('hf_rr', 0.22191943), ('bpm', 0.18804814), ('sdnn', 0.17385367), ('lf_rr', 0.16518994)]\n",
      "\n",
      "Grid search for SVM ...\n",
      "Grid search for LGB ...\n",
      "Grid search for RF ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more of the test scores are non-finite: [0.60804599 0.63250084 0.62325002 0.62697019 0.6342079  0.60280522\n",
      " 0.61535998 0.6058982  0.60943757 0.62011681 0.60674247 0.6160868\n",
      " 0.60643341 0.6122525  0.61422253 0.59839296 0.59678334 0.59781117\n",
      " 0.6158534  0.61207408 0.59373143 0.59816984 0.5976544  0.61442716\n",
      " 0.6151537         nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search for XGB ...\n",
      "SVM: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "LGB: {'max_depth': 7, 'metric': 'mean_absolute_error', 'num_leaves': 20, 'objective': 'binary'}\n",
      "RF: {'max_features': 'sqrt', 'min_samples_split': 3, 'n_estimators': 50, 'random_state': 16}\n",
      "XGB: {'eval_metric': 'error', 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 30, 'objective': 'binary:logistic', 'random_state': 16, 'use_label_encoder': False}\n",
      "Feature selection for SVM ...\n",
      "Feature selection for LGB ...\n",
      "Feature selection for RF ...\n",
      "Feature selection for XGB ...\n",
      "Training SVM ...\n",
      "Model SVM, Actual: [0 1], [47 26], Predictions: [0 1], [66  7]\n",
      "coef_ only available for SVC with linear kernel\n",
      "Training LGB ...\n",
      "Model LGB, Actual: [0 1], [47 26], Predictions: [0 1], [45 28]\n",
      "Training RF ...\n",
      "Model RF, Actual: [0 1], [47 26], Predictions: [0 1], [53 20]\n",
      "Training XGB ...\n",
      "Model XGB, Actual: [0 1], [47 26], Predictions: [0 1], [60 13]\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "[('sdnn', 291), ('bpm', 289), ('rmssd', 249), ('lf_rr', 219), ('hf_rr', 217)]\n",
      "\n",
      "\n",
      "[('hf_rr', 0.22681230795378932), ('rmssd', 0.21752844590260376), ('sdnn', 0.19643371104243007), ('lf_rr', 0.17991351778589834), ('bpm', 0.1793120173152785)]\n",
      "\n",
      "\n",
      "[('lf_rr', 0.3743387), ('rmssd', 0.18039541), ('sdnn', 0.16970298), ('bpm', 0.14658085), ('hf_rr', 0.12898207)]\n",
      "\n",
      "Grid search for SVM ...\n",
      "Grid search for LGB ...\n",
      "Grid search for RF ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more of the test scores are non-finite: [0.55390518 0.5616905  0.56391917 0.56245124 0.56683486 0.56487223\n",
      " 0.57841484 0.57895434 0.59010834 0.58373894 0.6003178  0.5947913\n",
      " 0.59020297 0.58705326 0.5794595  0.5780285  0.5649273  0.56269289\n",
      " 0.56167165 0.56856418 0.56768336 0.5731735  0.55803907 0.56142606\n",
      " 0.56781279        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search for XGB ...\n",
      "SVM: {'C': 100, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "LGB: {'max_depth': 4, 'metric': 'mean_absolute_error', 'num_leaves': 20, 'objective': 'binary'}\n",
      "RF: {'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 10, 'random_state': 16}\n",
      "XGB: {'eval_metric': 'error', 'learning_rate': 0.3, 'max_depth': 4, 'n_estimators': 50, 'objective': 'binary:logistic', 'random_state': 16, 'use_label_encoder': False}\n",
      "Feature selection for SVM ...\n",
      "Feature selection for LGB ...\n",
      "Feature selection for RF ...\n",
      "Feature selection for XGB ...\n",
      "Training SVM ...\n",
      "Model SVM, Actual: [0 1], [45 22], Predictions: [0 1], [34 33]\n",
      "coef_ only available for SVC with linear kernel\n",
      "Training LGB ...\n",
      "Model LGB, Actual: [0 1], [45 22], Predictions: [0 1], [55 12]\n",
      "Training RF ...\n",
      "Model RF, Actual: [0 1], [45 22], Predictions: [0 1], [49 18]\n",
      "Training XGB ...\n",
      "Model XGB, Actual: [0 1], [45 22], Predictions: [0 1], [58  9]\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "[('lf_rr', 127), ('bpm', 122), ('sdnn', 121), ('hf_rr', 105), ('rmssd', 102)]\n",
      "\n",
      "\n",
      "[('hf_rr', 0.23302464894550584), ('rmssd', 0.21193736021818982), ('sdnn', 0.19899350611860245), ('lf_rr', 0.18241615864911695), ('bpm', 0.17362832606858494)]\n",
      "\n",
      "\n",
      "[('rmssd', 0.22236715), ('bpm', 0.20833243), ('hf_rr', 0.20624119), ('lf_rr', 0.19679232), ('sdnn', 0.16626696)]\n",
      "\n",
      "Model evaluation metrics for SVM:\n",
      "\tAccuracy: 0.7164179104477612\n",
      "\tPrecision: 0.3333333333333333\n",
      "\tRecall: 0.05555555555555555\n",
      "\tF1-score: 0.09523809523809525\n",
      "\tAUC score: 0.5073696145124716\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.5416666666666666\n",
      "\tPrecision: 0.5925925925925926\n",
      "\tRecall: 0.42105263157894735\n",
      "\tF1-score: 0.49230769230769234\n",
      "\tAUC score: 0.5487616099071208\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.515625\n",
      "\tPrecision: 0.45454545454545453\n",
      "\tRecall: 0.3448275862068966\n",
      "\tF1-score: 0.39215686274509803\n",
      "\tAUC score: 0.5009852216748769\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.6027397260273972\n",
      "\tPrecision: 0.2857142857142857\n",
      "\tRecall: 0.07692307692307693\n",
      "\tF1-score: 0.12121212121212123\n",
      "\tAUC score: 0.4852700490998363\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.5373134328358209\n",
      "\tPrecision: 0.36363636363636365\n",
      "\tRecall: 0.5454545454545454\n",
      "\tF1-score: 0.43636363636363634\n",
      "\tAUC score: 0.5393939393939393\n",
      "----------------------------------------\n",
      "Mean acc: 0.5827525471955293\n",
      "Mean F1-score: 0.30745568157332864\n",
      "Mean AUC score: 0.5163560869176489\n",
      "\n",
      "\n",
      "Model evaluation metrics for LGB:\n",
      "\tAccuracy: 0.5671641791044776\n",
      "\tPrecision: 0.13333333333333333\n",
      "\tRecall: 0.1111111111111111\n",
      "\tF1-score: 0.1212121212121212\n",
      "\tAUC score: 0.4229024943310657\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.4722222222222222\n",
      "\tPrecision: 0.5\n",
      "\tRecall: 0.23684210526315788\n",
      "\tF1-score: 0.32142857142857145\n",
      "\tAUC score: 0.4860681114551084\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.640625\n",
      "\tPrecision: 0.8\n",
      "\tRecall: 0.27586206896551724\n",
      "\tF1-score: 0.4102564102564103\n",
      "\tAUC score: 0.6093596059113301\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.589041095890411\n",
      "\tPrecision: 0.42857142857142855\n",
      "\tRecall: 0.46153846153846156\n",
      "\tF1-score: 0.4444444444444445\n",
      "\tAUC score: 0.560556464811784\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.6417910447761194\n",
      "\tPrecision: 0.4166666666666667\n",
      "\tRecall: 0.22727272727272727\n",
      "\tF1-score: 0.29411764705882354\n",
      "\tAUC score: 0.5358585858585858\n",
      "----------------------------------------\n",
      "Mean acc: 0.582168708398646\n",
      "Mean F1-score: 0.31829183888007423\n",
      "Mean AUC score: 0.5229490524735748\n",
      "\n",
      "\n",
      "Model evaluation metrics for RF:\n",
      "\tAccuracy: 0.5522388059701493\n",
      "\tPrecision: 0.25\n",
      "\tRecall: 0.3333333333333333\n",
      "\tF1-score: 0.28571428571428575\n",
      "\tAUC score: 0.4829931972789116\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.5\n",
      "\tPrecision: 0.55\n",
      "\tRecall: 0.2894736842105263\n",
      "\tF1-score: 0.37931034482758624\n",
      "\tAUC score: 0.5123839009287926\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.609375\n",
      "\tPrecision: 0.5909090909090909\n",
      "\tRecall: 0.4482758620689655\n",
      "\tF1-score: 0.5098039215686274\n",
      "\tAUC score: 0.5955665024630543\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.5616438356164384\n",
      "\tPrecision: 0.35\n",
      "\tRecall: 0.2692307692307692\n",
      "\tF1-score: 0.3043478260869565\n",
      "\tAUC score: 0.496317512274959\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.582089552238806\n",
      "\tPrecision: 0.3333333333333333\n",
      "\tRecall: 0.2727272727272727\n",
      "\tF1-score: 0.3\n",
      "\tAUC score: 0.503030303030303\n",
      "----------------------------------------\n",
      "Mean acc: 0.5610694387650788\n",
      "Mean F1-score: 0.3558352756394912\n",
      "Mean AUC score: 0.5180582831952041\n",
      "\n",
      "\n",
      "Model evaluation metrics for XGB:\n",
      "\tAccuracy: 0.6417910447761194\n",
      "\tPrecision: 0.25\n",
      "\tRecall: 0.16666666666666666\n",
      "\tF1-score: 0.2\n",
      "\tAUC score: 0.49149659863945583\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.5277777777777778\n",
      "\tPrecision: 0.6111111111111112\n",
      "\tRecall: 0.2894736842105263\n",
      "\tF1-score: 0.3928571428571429\n",
      "\tAUC score: 0.541795665634675\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.609375\n",
      "\tPrecision: 0.5909090909090909\n",
      "\tRecall: 0.4482758620689655\n",
      "\tF1-score: 0.5098039215686274\n",
      "\tAUC score: 0.5955665024630543\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.6575342465753424\n",
      "\tPrecision: 0.5384615384615384\n",
      "\tRecall: 0.2692307692307692\n",
      "\tF1-score: 0.3589743589743589\n",
      "\tAUC score: 0.570785597381342\n",
      "----------------------------------------\n",
      "\tAccuracy: 0.6567164179104478\n",
      "\tPrecision: 0.4444444444444444\n",
      "\tRecall: 0.18181818181818182\n",
      "\tF1-score: 0.2580645161290322\n",
      "\tAUC score: 0.5353535353535354\n",
      "----------------------------------------\n",
      "Mean acc: 0.6186388974079374\n",
      "Mean F1-score: 0.34393998790583236\n",
      "Mean AUC score: 0.5469995798944126\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K-FOLD CROSS-VALIDATION FOR HYPERPARAMETER SELECTION\n",
    "importlib.reload(train)\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "\n",
    "\n",
    "random.seed(74)\n",
    "\n",
    "model_phases = [\n",
    "    \"Baseline_Rest\", \n",
    "    \"BugBox_Relax\", \"BugBox_Anticipate\", \"BugBox_Exposure\", \"BugBox_Break\",\n",
    "    \"Speech_Relax\", \"Speech_Anticipate\", \"Speech_Exposure\", \"Speech_Break\"\n",
    "]\n",
    "\n",
    "threshold = \"fixed\"\n",
    "\n",
    "anxiety_label_type = None\n",
    "x, y = train.Train_APD.get_apd_data_ranking(\n",
    "    metrics, model_phases, verbose=False, anxiety_label_type=anxiety_label_type, \n",
    "    threshold=threshold, normalize=True, combine_phases=False, standardize=False\n",
    ")\n",
    "x = x.drop([\"phaseId\"], axis=1)\n",
    "inds = pd.isnull(x).any(axis=1).to_numpy().nonzero()[0]\n",
    "x = x.drop(labels=inds, axis=0).reset_index(drop=True)\n",
    "y = y.drop(labels=inds, axis=0).reset_index(drop=True)\n",
    "\n",
    "# drop subjects with noisy data\n",
    "# x = x[~x[\"subject\"].isin(invalid_apd_subjects)].reset_index(drop=True)\n",
    "# y = y[~y[\"subject\"].isin(invalid_apd_subjects)].reset_index(drop=True)\n",
    "\n",
    "if anxiety_label_type is not None:\n",
    "    x.drop(labels=[\"anxietyGroup\"], axis=1)\n",
    "    \n",
    "acc_results = {\n",
    "    \"SVM\": [],\n",
    "    \"LGB\": [],\n",
    "    \"RF\": [],\n",
    "    \"XGB\": [],\n",
    "    # \"random\": []\n",
    "}\n",
    "reports = {\n",
    "    \"SVM\": [],\n",
    "    \"LGB\": [],\n",
    "    \"RF\": [],\n",
    "    \"XGB\": [],\n",
    "    # \"random\": []\n",
    "}\n",
    "best_models = {}\n",
    "\n",
    "num_iters = 5\n",
    "get_importance = True\n",
    "for _ in range(num_iters):\n",
    "    # HYPERPARAMETER TUNING\n",
    "    model_data = train.grid_search_cv(\n",
    "        models, parameters, x, y, by_subject=True, save_metrics=True, is_resample=True,\n",
    "        get_importance=get_importance, drop_subject=True, test_size=0.1, folds=5\n",
    "    )\n",
    "\n",
    "    for model_name in models.keys():\n",
    "        best_models[model_name] = model_data[model_name][\"best_model\"]\n",
    "        print(f\"{model_name}: {model_data[model_name]['best_params']}\")\n",
    "\n",
    "    # # FEATURE SELECTION\n",
    "    x_train, y_train = model_data[\"train\"]\n",
    "    # features = {name: metrics for name in models.keys()}\n",
    "    features = train.feature_selection(best_models, model_data[\"cv\"], x_train, y_train, n_features=5)\n",
    "\n",
    "    # TEST USING OPTIMIZED MODELS AND FEATAURES\n",
    "    x_test, y_test = model_data[\"test\"]\n",
    "    out = train.train_test_model(best_models, features, x_train, y_train, x_test, y_test)\n",
    "\n",
    "    for model_name in acc_results:\n",
    "        acc_results[model_name].append(out[model_name][\"performance\"][0])\n",
    "        reports[model_name].append(out[model_name][\"performance\"][1])\n",
    "        if get_importance:\n",
    "            try:\n",
    "                print(\"\")\n",
    "                feature_imp = list(zip(metrics + [\"lf_hf_ratio\"], out[model_name][\"performance\"][2]))\n",
    "                feature_imp = sorted(feature_imp, key=lambda x: x[1], reverse=True)\n",
    "                print(feature_imp)\n",
    "            except Exception as e:\n",
    "                print(out[model_name][\"performance\"][2])\n",
    "            print(\"\")\n",
    "\n",
    "for model_name in acc_results.keys():\n",
    "    print(f\"Model evaluation metrics for {model_name}:\")\n",
    "    for i in range(len(reports[model_name])):\n",
    "        report = reports[model_name][i]\n",
    "        acc = acc_results[model_name][i]\n",
    "        p = report[\"precision\"]\n",
    "        r = report[\"recall\"]\n",
    "        f1 = report[\"f1\"]\n",
    "        auc = report[\"auc\"]\n",
    "        print(f\"\\tAccuracy: {acc}\\n\\tPrecision: {p}\\n\\tRecall: {r}\\n\\tF1-score: {f1}\\n\\tAUC score: {auc}\\n\" + \"-\"*40)\n",
    "    print(f\"Mean acc: {np.mean([acc_results[model_name][i] for i in range(len(reports[model_name]))])}\")\n",
    "    print(f\"Mean F1-score: {np.mean([reports[model_name][i]['f1'] for i in range(len(reports[model_name]))])}\")\n",
    "    print(f\"Mean AUC score: {np.mean([reports[model_name][i]['auc'] for i in range(len(reports[model_name]))])}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4574468085106383"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ENSEMBLE\n",
    "importlib.reload(train)\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedGroupKFold, GroupShuffleSplit\n",
    "\n",
    "test_size = 0.15\n",
    "folds = 5\n",
    "\n",
    "cv, x_train, y_train, x_test, y_test = train.kfold_train_test_split(x, y, test_size, is_resample=False, folds=folds)\n",
    "\n",
    "estimators = [(name, best_models[name]) for name in best_models.keys()]\n",
    "ensemble = VotingClassifier(estimators, voting=\"hard\")\n",
    "ensemble.fit(x_train, y_train.loc[:, \"label\"])\n",
    "ensemble.score(x_test, y_test.loc[:, \"label\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5015c0e83de7be3f940d9818fce2964bddf05ca60741c8dac88cf8d83f44e00e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
