{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we classify each phase as relatively low or high anxiety for each subject? ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING MODULES\n",
    "import glob\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "cvx_path = os.path.abspath(os.path.join('..', '..', 'cvxEDA', 'src'))\n",
    "module_path = os.path.abspath(os.path.join('..', '..', 'src'))\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy.signal as ss\n",
    "import shap\n",
    "import sys\n",
    "sys.path.append(module_path)\n",
    "\n",
    "import tools.data_reader_apd as dr\n",
    "import tools.display_tools as dt\n",
    "import tools.preprocessing as preprocessing\n",
    "import train\n",
    "\n",
    "from scipy.fft import fft, fftfreq, fftshift\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RepeatedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import cvxopt.solvers\n",
    "cvxopt.solvers.options['show_progress'] = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", \n",
    "    category=RuntimeWarning\n",
    ")\n",
    "\n",
    "temp_a, _ = train.Train_APD.get_apd_data_ranking([train.Metrics.BPM], phases=dr.Phases.PHASES_LIST, normalize=False)\n",
    "idx = temp_a[temp_a[\"bpm\"] > 200].index \n",
    "invalid_apd_subjects = set(temp_a[\"subject\"].iloc[idx].tolist())\n",
    "idx = temp_a[temp_a[\"bpm\"] < 35].index \n",
    "invalid_apd_subjects.update(set(temp_a[\"subject\"].iloc[idx].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    # \"SVM\": SVC(C=10, gamma=1),  # C=10, gamma=1\n",
    "    # \"KNN\": KNeighborsClassifier(n_neighbors=7),\n",
    "    # \"DT\": DecisionTreeClassifier(),\n",
    "    \"LogReg\": LogisticRegression(max_iter=1000, solver=\"liblinear\"),\n",
    "    # \"Bayes\": GaussianNB(),\n",
    "    \"RF\": RandomForestClassifier(n_estimators=50, max_features=3),\n",
    "    \"XGB\": XGBClassifier(use_label_encoder=False, objective=\"binary:logistic\", eval_metric=\"error\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.0, 18.0, 6.0, 66.0, 80.0, 89.0, 47.0, 42.0, 92.0], [31.0, 87.0, 82.0, 33.0, 51.0, 69.0, 49.0, 55.0, 78.0], [79.0, 83.0, 48.0, 14.0, 85.0, 43.0, 25.0, 71.0, 26.0], [27.0, 91.0, 46.0, 34.0, 35.0, 84.0, 93.0, 72.0, 22.0], [12.0, 77.0, 32.0, 39.0, 10.0, 45.0, 29.0, 88.0, 54.0]]\n",
      "Ratio of positive to negative labels (0.3064516129032258) is under 0.333, oversampling positive class.\n",
      "Ratio of positive to negative labels (0.3117408906882591) is under 0.333, oversampling positive class.\n",
      "Ratio of positive to negative labels (0.2908366533864542) is under 0.333, oversampling positive class.\n",
      "Ratio of positive to negative labels (0.25096525096525096) is under 0.333, oversampling positive class.\n",
      "Ratio of positive to negative labels (0.27058823529411763) is under 0.333, oversampling positive class.\n",
      "Ratio of positive to negative labels (0.208955223880597) is under 0.333, oversampling positive class.\n",
      "Ratio of positive to negative labels (0.19117647058823528) is under 0.333, oversampling positive class.\n",
      "Ratio of positive to negative labels (0.265625) is under 0.333, oversampling positive class.\n",
      "y_train | y_test:\n",
      "{0: 248, 1: 82} | {0: 67, 1: 22}\n",
      "y_train | y_test:\n",
      "{0: 247, 1: 82} | {0: 68, 1: 22}\n",
      "y_train | y_test:\n",
      "{0: 251, 1: 83} | {0: 64, 1: 21}\n",
      "y_train | y_test:\n",
      "{0: 259, 1: 86} | {0: 56, 1: 25}\n",
      "y_train | y_test:\n",
      "{0: 255, 1: 84} | {0: 60, 1: 21}\n",
      "Fold #0\n",
      "Model LogReg, Predictions: [0 1], [88  1]\n",
      "{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.4925373134328358}\n",
      "Fold #1\n",
      "Model LogReg, Predictions: [0 1], [87  3]\n",
      "{'precision': 0.6666666666666666, 'recall': 0.09090909090909091, 'f1': 0.16, 'auc': 0.5381016042780749}\n",
      "Fold #2\n",
      "Model LogReg, Predictions: [0], [85]\n",
      "{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.5}\n",
      "Fold #3\n",
      "Model LogReg, Predictions: [0 1], [79  2]\n",
      "{'precision': 1.0, 'recall': 0.08, 'f1': 0.14814814814814814, 'auc': 0.54}\n",
      "Fold #4\n",
      "Model LogReg, Predictions: [0 1], [79  2]\n",
      "{'precision': 1.0, 'recall': 0.09523809523809523, 'f1': 0.17391304347826084, 'auc': 0.5476190476190477}\n",
      "Fold #0\n",
      "Model RF, Predictions: [0 1], [79 10]\n",
      "{'precision': 0.4, 'recall': 0.18181818181818182, 'f1': 0.25000000000000006, 'auc': 0.5461329715061058}\n",
      "Fold #1\n",
      "Model RF, Predictions: [0 1], [79 11]\n",
      "{'precision': 0.18181818181818182, 'recall': 0.09090909090909091, 'f1': 0.12121212121212123, 'auc': 0.4792780748663102}\n",
      "Fold #2\n",
      "Model RF, Predictions: [0 1], [81  4]\n",
      "{'precision': 0.25, 'recall': 0.047619047619047616, 'f1': 0.08, 'auc': 0.5003720238095238}\n",
      "Fold #3\n",
      "Model RF, Predictions: [0 1], [77  4]\n",
      "{'precision': 0.75, 'recall': 0.12, 'f1': 0.20689655172413793, 'auc': 0.5510714285714287}\n",
      "Fold #4\n",
      "Model RF, Predictions: [0 1], [74  7]\n",
      "{'precision': 0.42857142857142855, 'recall': 0.14285714285714285, 'f1': 0.21428571428571427, 'auc': 0.5380952380952381}\n",
      "Fold #0\n",
      "Model XGB, Predictions: [0 1], [64 25]\n",
      "{'precision': 0.36, 'recall': 0.4090909090909091, 'f1': 0.3829787234042554, 'auc': 0.5851424694708277}\n",
      "Fold #1\n",
      "Model XGB, Predictions: [0 1], [53 37]\n",
      "{'precision': 0.21621621621621623, 'recall': 0.36363636363636365, 'f1': 0.27118644067796616, 'auc': 0.4685828877005348}\n",
      "Fold #2\n",
      "Model XGB, Predictions: [0 1], [66 19]\n",
      "{'precision': 0.2631578947368421, 'recall': 0.23809523809523808, 'f1': 0.25, 'auc': 0.5096726190476191}\n",
      "Fold #3\n",
      "Model XGB, Predictions: [0 1], [62 19]\n",
      "{'precision': 0.6842105263157895, 'recall': 0.52, 'f1': 0.5909090909090909, 'auc': 0.7064285714285714}\n",
      "Fold #4\n",
      "Model XGB, Predictions: [0 1], [65 16]\n",
      "{'precision': 0.4375, 'recall': 0.3333333333333333, 'f1': 0.37837837837837834, 'auc': 0.5916666666666667}\n",
      "\n",
      "[('lf_hf_ratio', 1.242040876071885), ('lf_rr', 1.2112294418508411), ('mean_SCL', 1.0562169608315033), ('hf_rr', 0.993913398954941), ('sdnn', 0.5760487929559809), ('rmssd', 0.12330366970549947), ('SCR_rate', -0.2450307597177074), ('bpm', -0.5524268790877629)]\n",
      "[('lf_hf_ratio', 1.500838577079157), ('lf_rr', 1.3291569691405614), ('mean_SCL', 1.0335104122468484), ('hf_rr', 0.8016051117519499), ('sdnn', 0.04186950511555499), ('rmssd', -0.0019153899885549974), ('bpm', -0.20956642404307085), ('SCR_rate', -0.4664465626054199)]\n",
      "[('lf_hf_ratio', 1.7067658061533482), ('lf_rr', 1.1991627432859535), ('hf_rr', 0.8105637969041589), ('mean_SCL', 0.7949465433060813), ('sdnn', 0.15189237136952094), ('SCR_rate', -0.12673892976317935), ('rmssd', -0.15620228151225524), ('bpm', -0.3957858700727985)]\n",
      "[('lf_rr', 1.3368537697442393), ('lf_hf_ratio', 1.1437652358386001), ('hf_rr', 0.8444068035308613), ('mean_SCL', 0.7003464364199755), ('sdnn', 0.05474173935130349), ('SCR_rate', -0.07268269789591249), ('rmssd', -0.18027347976678174), ('bpm', -0.26061944711162627)]\n",
      "[('lf_rr', 1.2783841104617424), ('mean_SCL', 1.2529025745294586), ('lf_hf_ratio', 1.252826413847689), ('hf_rr', 0.6019388807295306), ('sdnn', 0.22749921016224067), ('rmssd', 0.08230734229805639), ('SCR_rate', -0.724209020072417), ('bpm', -0.7424986387781702)]\n",
      "\n",
      "\n",
      "[('mean_SCL', 0.15307695563231102), ('lf_hf_ratio', 0.14741645101088474), ('hf_rr', 0.13418249449184372), ('bpm', 0.12452986694485205), ('sdnn', 0.11961004324001762), ('SCR_rate', 0.1129035204438963), ('lf_rr', 0.11163249092286398), ('rmssd', 0.09664817731333056)]\n",
      "[('mean_SCL', 0.16662376979393692), ('bpm', 0.15004683422887924), ('lf_rr', 0.13661156373051103), ('hf_rr', 0.13301982043254737), ('lf_hf_ratio', 0.1283094968536981), ('SCR_rate', 0.11252140381369882), ('rmssd', 0.08950907137161722), ('sdnn', 0.08335803977511139)]\n",
      "[('mean_SCL', 0.14517655418775022), ('hf_rr', 0.1392638370710655), ('SCR_rate', 0.13783336213661715), ('bpm', 0.13754809139229998), ('lf_hf_ratio', 0.12403800420020873), ('rmssd', 0.11399585384539353), ('lf_rr', 0.10375976484818783), ('sdnn', 0.0983845323184772)]\n",
      "[('lf_rr', 0.1447314730163138), ('mean_SCL', 0.14132814474206465), ('bpm', 0.13358711828067216), ('SCR_rate', 0.12779375921661862), ('hf_rr', 0.12009416103815715), ('rmssd', 0.11722241621329685), ('lf_hf_ratio', 0.11243006058640911), ('sdnn', 0.10281286690646774)]\n",
      "[('mean_SCL', 0.19498790586965944), ('bpm', 0.17602186312675383), ('lf_rr', 0.12667162311695804), ('lf_hf_ratio', 0.11780791921493307), ('SCR_rate', 0.1157076402900575), ('hf_rr', 0.10618338235625718), ('rmssd', 0.08335166644221538), ('sdnn', 0.07926799958316551)]\n",
      "\n",
      "\n",
      "[('mean_SCL', 0.16491945), ('rmssd', 0.14377758), ('SCR_rate', 0.124883056), ('hf_rr', 0.12276907), ('bpm', 0.11950504), ('lf_rr', 0.119345844), ('sdnn', 0.10686603), ('lf_hf_ratio', 0.09793398)]\n",
      "[('mean_SCL', 0.22514097), ('bpm', 0.1347611), ('lf_hf_ratio', 0.1257978), ('sdnn', 0.11997182), ('lf_rr', 0.11542896), ('hf_rr', 0.10160304), ('SCR_rate', 0.09823085), ('rmssd', 0.07906546)]\n",
      "[('lf_hf_ratio', 0.16218401), ('mean_SCL', 0.16028458), ('hf_rr', 0.13247874), ('lf_rr', 0.12721306), ('sdnn', 0.11633891), ('bpm', 0.10208437), ('SCR_rate', 0.10110887), ('rmssd', 0.098307505)]\n",
      "[('mean_SCL', 0.17616555), ('lf_rr', 0.17521341), ('hf_rr', 0.1213445), ('bpm', 0.12003883), ('sdnn', 0.11935995), ('SCR_rate', 0.10637442), ('lf_hf_ratio', 0.09849971), ('rmssd', 0.083003655)]\n",
      "[('mean_SCL', 0.18791357), ('hf_rr', 0.14780211), ('lf_hf_ratio', 0.14726928), ('bpm', 0.11580927), ('lf_rr', 0.11562353), ('sdnn', 0.109174006), ('rmssd', 0.09961889), ('SCR_rate', 0.07678932)]\n",
      "\n",
      "LogReg accuracy over 1 rounds: 0.7485324716653203\n",
      "Model evaluation metrics for LogReg:\n",
      "\tPrecision: 0.5333333333333333\n",
      "\tRecall: 0.053229437229437224\n",
      "\tF1-score: 0.09641223832528181\n",
      "\tAUC score: 0.5236515930659916\n",
      "\n",
      "RF accuracy over 1 rounds: 0.7163942131159581\n",
      "Model evaluation metrics for RF:\n",
      "\tPrecision: 0.4020779220779221\n",
      "\tRecall: 0.11664069264069263\n",
      "\tF1-score: 0.1744788774443947\n",
      "\tAUC score: 0.5229899473697213\n",
      "\n",
      "XGB accuracy over 1 rounds: 0.6674531019232496\n",
      "Model evaluation metrics for XGB:\n",
      "\tPrecision: 0.39221692745376957\n",
      "\tRecall: 0.37283116883116885\n",
      "\tF1-score: 0.3746905266739381\n",
      "\tAUC score: 0.572298642862844\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LOAD TRAIN AND TEST DATA\n",
    "importlib.reload(train)\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "\n",
    "\n",
    "metrics = [\n",
    "    train.Metrics.BPM, \n",
    "    train.Metrics.RMSSD, \n",
    "    train.Metrics.HF_RR, \n",
    "    train.Metrics.LF_RR, \n",
    "    # train.Metrics.IBI, \n",
    "    train.Metrics.SDNN, \n",
    "    train.Metrics.MEAN_SCL, \n",
    "    train.Metrics.SCR_RATE, \n",
    "]\n",
    "\n",
    "model_phases = [\n",
    "    \"Baseline_Rest\", \n",
    "    \"BugBox_Relax\", \"BugBox_Anticipate\", \"BugBox_Exposure\", \"BugBox_Break\",\n",
    "    \"Speech_Relax\", \"Speech_Anticipate\", \"Speech_Exposure\", \"Speech_Break\"\n",
    "]\n",
    "\n",
    "threshold = \"fixed\"\n",
    "\n",
    "anxiety_label_type = None\n",
    "x, y = train.Train_APD.get_apd_data_ranking(metrics, model_phases, verbose=False, anxiety_label_type=anxiety_label_type, threshold=threshold, normalize=True)\n",
    "x = x.drop([\"phaseId\"], axis=1)\n",
    "\n",
    "# drop subjects with noisy data\n",
    "x = x[~x[\"subject\"].isin(invalid_apd_subjects)].reset_index(drop=True)\n",
    "y = y[~y[\"subject\"].isin(invalid_apd_subjects)].reset_index(drop=True)\n",
    "\n",
    "if anxiety_label_type is not None:\n",
    "    x.drop(labels=[\"anxietyGroup\"], axis=1)\n",
    "    \n",
    "acc_results = {\n",
    "    # \"SVM\": [],\n",
    "    \"LogReg\": [],\n",
    "    \"RF\": [],\n",
    "    \"XGB\": []\n",
    "}\n",
    "reports = {\n",
    "    # \"SVM\": [],\n",
    "    \"LogReg\": [],\n",
    "    \"RF\": [],\n",
    "    \"XGB\": []\n",
    "}\n",
    "num_iters = 1\n",
    "get_importance = True\n",
    "for _ in range(num_iters):\n",
    "    out = train.train_predict(models, x, y, by_subject=True, save_metrics=True, is_resample=True, get_importance=get_importance, drop_subject=True, test_size=0.2, folds=5)\n",
    "    for model_name in acc_results:\n",
    "        for i in range(len(out[model_name])):\n",
    "            acc_results[model_name].append(out[model_name][i][0])\n",
    "            reports[model_name].append(out[model_name][i][1])\n",
    "        if get_importance:\n",
    "            try:\n",
    "                print(\"\")\n",
    "                # shap.plots.bar(out[model_name][0][2])\n",
    "                for i in range(len(out[model_name])):\n",
    "                    feature_imp = list(zip(metrics + [\"lf_hf_ratio\"], out[model_name][i][2]))\n",
    "                    feature_imp = sorted(feature_imp, key=lambda x: x[1], reverse=True)\n",
    "                    print(feature_imp)\n",
    "            except Exception as e:\n",
    "                print(out[model_name][0][2])\n",
    "            print(\"\")\n",
    "\n",
    "for model_name in acc_results.keys():\n",
    "    acc = np.mean(acc_results[model_name])\n",
    "    print(f\"{model_name} accuracy over {num_iters} rounds: {acc}\")\n",
    "    if acc > 0.5:\n",
    "        print(f\"Model evaluation metrics for {model_name}:\")\n",
    "        p = np.mean([report[\"precision\"] for report in reports[model_name]])\n",
    "        r = np.mean([report[\"recall\"] for report in reports[model_name]])\n",
    "        f1 = np.mean([report[\"f1\"] for report in reports[model_name]])\n",
    "        auc = np.mean([report[\"auc\"] for report in reports[model_name]])\n",
    "        report = reports[model_name]\n",
    "        print(f\"\\tPrecision: {p}\\n\\tRecall: {r}\\n\\tF1-score: {f1}\\n\\tAUC score: {auc}\")\n",
    "    print(\"\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD TRAIN AND TEST DATA -- train on some phases and test on others\n",
    "importlib.reload(train)\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "\n",
    "# metrics = train.Metrics.ALL\n",
    "# metrics = train.Metrics.ECG \\\n",
    "    # + train.Metrics.EDA \\\n",
    "    # + train.Metrics.ANKLE + train.Metrics.WRIST\n",
    "\n",
    "metrics = [\n",
    "    train.Metrics.BPM, \n",
    "    train.Metrics.RMSSD, \n",
    "    # train.Metrics.HF_RR, \n",
    "    # train.Metrics.LF_RR, \n",
    "    train.Metrics.IBI, \n",
    "    train.Metrics.SDNN, \n",
    "    train.Metrics.MEAN_SCL, \n",
    "    train.Metrics.SCR_RATE, \n",
    "]\n",
    "\n",
    "phases_a = [\n",
    "    \"Baseline_Rest\", \n",
    "    \"BugBox_Relax\", \n",
    "    \"BugBox_Anticipate\", \n",
    "    # \"BugBox_Exposure\", \n",
    "    # \"BugBox_Break\",\n",
    "    \"Speech_Relax\", \n",
    "    \"Speech_Anticipate\", \n",
    "    # \"Speech_Exposure\", \n",
    "    # \"Speech_Break\"\n",
    "]\n",
    "\n",
    "phases_b = [\n",
    "    # \"Baseline_Rest\", \n",
    "    # \"BugBox_Relax\", \n",
    "    # \"BugBox_Anticipate\", \n",
    "    \"BugBox_Exposure\", \n",
    "    # \"BugBox_Break\",\n",
    "    # \"Speech_Relax\", \n",
    "    # \"Speech_Anticipate\", \n",
    "    \"Speech_Exposure\", \n",
    "    # \"Speech_Break\"\n",
    "]\n",
    "\n",
    "models = {\n",
    "    \"SVM\": SVC(C=10, gamma=1),  # C=10, gamma=1\n",
    "    # \"KNN\": KNeighborsClassifier(n_neighbors=7),\n",
    "    # \"DT\": DecisionTreeClassifier(),\n",
    "    \"LogReg\": LogisticRegression(max_iter=1000),\n",
    "    # \"Bayes\": GaussianNB(),\n",
    "    \"XGB\": XGBClassifier(use_label_encoder=False, objective=\"binary:logistic\", eval_metric=\"logloss\")\n",
    "}\n",
    "\n",
    "anxiety_label_type = \"Anxiety\"\n",
    "# anxiety_label_type = None\n",
    "test_size = 1.0\n",
    "\n",
    "x_a, y_a = train.Train_APD.get_apd_data_ranking(metrics, phases_a, verbose=False, anxiety_label_type=anxiety_label_type)\n",
    "x_b, y_b = train.Train_APD.get_apd_data_ranking(metrics, phases_b, verbose=False, anxiety_label_type=anxiety_label_type)\n",
    "x_a = x_a.drop([\"phaseId\"], axis=1)\n",
    "x_b = x_b.drop([\"phaseId\"], axis=1)\n",
    "\n",
    "# drop subjects with noisy data\n",
    "\n",
    "x_a = x_a[~x_a[\"subject\"].isin(invalid_apd_subjects)]\n",
    "y_a = y_a[~y_a[\"subject\"].isin(invalid_apd_subjects)]\n",
    "x_b = x_b[~x_b[\"subject\"].isin(invalid_apd_subjects)]\n",
    "y_b = y_b[~y_b[\"subject\"].isin(invalid_apd_subjects)]\n",
    "\n",
    "print(f\"y_a:\\n{y_a.loc[:, 'label'].value_counts()}\")\n",
    "print(f\"y_b:\\n{y_b.loc[:, 'label'].value_counts()}\")\n",
    "\n",
    "# x = x[x['subject'] != 8.0]\n",
    "# y = y[y['subject'] != 8.0]\n",
    "\n",
    "if anxiety_label_type is not None:\n",
    "    x_a.drop(labels=[\"anxietyGroup\"], axis=1)\n",
    "    x_b.drop(labels=[\"anxietyGroup\"], axis=1)\n",
    "\n",
    "# 0-1 scaling\n",
    "for i in range(3, len(x_a.columns)):\n",
    "    data_col = x_a[x_a.columns[i]]\n",
    "    data_col = (data_col - data_col.min())/(data_col.max() - data_col.min())\n",
    "    x_a[x_a.columns[i]] = data_col\n",
    "for i in range(3, len(x_b.columns)):\n",
    "    data_col = x_b[x_b.columns[i]]\n",
    "    data_col = (data_col - data_col.min())/(data_col.max() - data_col.min())\n",
    "    x_b[x_b.columns[i]] = data_col\n",
    "    \n",
    "# make sure subjects from different datasets aren't labeled with the same index\n",
    "x_b[\"subject\"] = x_b[\"subject\"] + 500\n",
    "\n",
    "acc_results = {\n",
    "    \"SVM\": [],\n",
    "    \"LogReg\": [],\n",
    "    \"XGB\": []\n",
    "}\n",
    "reports = {\n",
    "    \"SVM\": [],\n",
    "    \"LogReg\": [],\n",
    "    \"XGB\": []\n",
    "}\n",
    "num_iters = 10\n",
    "for _ in range(num_iters):\n",
    "    out = train.Train_Multi_Dataset.train_across_datasets(models, x_a, y_a, x_b, y_b, by_subject=False, save_metrics=True, test_size=test_size)\n",
    "    for model_name in acc_results:\n",
    "        acc_results[model_name].append(out[model_name][0])\n",
    "        reports[model_name].append(out[model_name][1])\n",
    "\n",
    "for model_name in acc_results.keys():\n",
    "    acc = np.mean(acc_results[model_name])\n",
    "    print(f\"{model_name} accuracy over {num_iters} rounds: {acc}\")\n",
    "    if acc > 0.4:\n",
    "        print(f\"Model evaluation metrics for {model_name}:\")\n",
    "        p = np.mean([report[\"precision\"] for report in reports[model_name]])\n",
    "        r = np.mean([report[\"recall\"] for report in reports[model_name]])\n",
    "        f1 = np.mean([report[\"f1\"] for report in reports[model_name]])\n",
    "        auc = np.mean([report[\"auc\"] for report in reports[model_name]])\n",
    "        report = reports[model_name]\n",
    "        print(f\"Precision: {p}\\nRecall: {r}\\nF1-score: {f1}\\nAUC score: {auc}\")\n",
    "    print(\"\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-FOLD CROSS-VALIDATION\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "metrics = [\n",
    "    train.Metrics.BPM, \n",
    "    train.Metrics.RMSSD, \n",
    "    train.Metrics.HF_RR, \n",
    "    train.Metrics.LF_RR, \n",
    "    train.Metrics.IBI, \n",
    "    train.Metrics.SDNN, \n",
    "    train.Metrics.MEAN_SCL, \n",
    "    train.Metrics.SCR_RATE, \n",
    "]\n",
    "\n",
    "model_phases = [\n",
    "    [\n",
    "        \"Baseline_Rest\", \n",
    "        \"BugBox_Relax\", \"BugBox_Anticipate\", \"BugBox_Exposure\", \"BugBox_Break\",\n",
    "        \"Speech_Relax\", \"Speech_Anticipate\", \"Speech_Exposure\", \"Speech_Break\"\n",
    "    ],\n",
    "]\n",
    "\n",
    "models = {\n",
    "    \"SVM\": SVC(C=10, gamma=1),  # C=10, gamma=1\n",
    "    # \"KNN\": KNeighborsClassifier(n_neighbors=7),\n",
    "    # \"DT\": DecisionTreeClassifier(),\n",
    "    \"LogReg\": LogisticRegression(max_iter=1000),\n",
    "    # \"Bayes\": GaussianNB(),\n",
    "    \"XGB\": XGBClassifier(use_label_encoder=False, objective=\"binary:logistic\", eval_metric=\"logloss\")\n",
    "}\n",
    "\n",
    "for phases in model_phases:\n",
    "    print(f\"PHASES: {phases} \" + \"-\"*30)\n",
    "    # anxiety_label_type = \"Anxiety\"\n",
    "    anxiety_label_type = None\n",
    "    x, y = train.Train_APD.get_apd_data_ranking(metrics, phases, verbose=False, anxiety_label_type=anxiety_label_type)\n",
    "    x = x.drop([\"phaseId\"], axis=1)\n",
    "    # drop subjects with noisy data\n",
    "    x = x[~x[\"subject\"].isin(invalid_apd_subjects)]\n",
    "    y = y[~y[\"subject\"].isin(invalid_apd_subjects)]\n",
    "    # x = x[x['subject'] != 8.0]\n",
    "    # y = y[y['subject'] != 8.0]\n",
    "\n",
    "    if anxiety_label_type is not None:\n",
    "        x.drop(labels=[\"anxietyGroup\"], axis=1)\n",
    "        \n",
    "    print(y.loc[:, \"label\"].value_counts())\n",
    "\n",
    "    # 0-1 scaling\n",
    "    for i in range(3, len(x.columns)):\n",
    "        data_col = x[x.columns[i]]\n",
    "        data_col = (data_col - data_col.min())/(data_col.max() - data_col.min())\n",
    "        x[x.columns[i]] = data_col\n",
    "\n",
    "    acc_results = {\n",
    "        \"SVM\": [],\n",
    "        \"LogReg\": [],\n",
    "        \"XGB\": []\n",
    "    }\n",
    "    reports = {\n",
    "        \"SVM\": [],\n",
    "        \"LogReg\": [],\n",
    "        \"XGB\": []\n",
    "    }\n",
    "\n",
    "    # num_iters = 10\n",
    "    num_iters = 1\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        for model_name in acc_results:\n",
    "            model = models[model_name]\n",
    "            # scores = cross_validate(model, x, y, scoring=[\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"], cv=5, n_jobs=-1)\n",
    "            scores = cross_validate(model, x, y, scoring=[\"accuracy\"], cv=5, n_jobs=-1)\n",
    "            print(scores)\n",
    "            reports[model_name].append(scores)\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5015c0e83de7be3f940d9818fce2964bddf05ca60741c8dac88cf8d83f44e00e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
