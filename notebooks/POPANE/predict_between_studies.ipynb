{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zhoux\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# IMPORTING MODULES\n",
    "import glob\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "cvx_path = os.path.abspath(os.path.join('..', '..', 'cvxEDA', 'src'))\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy.signal as ss\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..', '..', 'src'))\n",
    "sys.path.append(module_path)\n",
    "\n",
    "import tools.data_reader_popane as dr_p\n",
    "import tools.display_tools as dt\n",
    "import tools.preprocessing as preprocessing\n",
    "import train\n",
    "\n",
    "from scipy.fft import fft, fftfreq, fftshift\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import cvxopt.solvers\n",
    "cvxopt.solvers.options['show_progress'] = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", \n",
    "    category=RuntimeWarning\n",
    ")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POPANE Study1 --------------------------------------------------\n",
      "POPANE Study2 --------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_label_encoder` is deprecated in 1.7.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    487\n",
      "0    463\n",
      "Name: label, dtype: int64\n",
      "SVM accuracy over 10 rounds: 0.4233233957707476\n",
      "LogReg accuracy over 10 rounds: 0.5229530019443079\n",
      "Model evaluation metrics for LogReg:\n",
      "Precision: 0.6085044849479586\n",
      "Recall: 0.2925168199010015\n",
      "F1-score: 0.34940516882349737\n",
      "AUC score: 0.5355713684485056\n",
      "XGB accuracy over 10 rounds: 0.48549038618522733\n",
      "\n",
      "\n",
      "POPANE Study1 --------------------------------------------------\n",
      "POPANE Study3 --------------------------------------------------\n",
      "1    435\n",
      "0    396\n",
      "Name: label, dtype: int64\n",
      "Only one value in predictions: 1\n",
      "SVM accuracy over 10 rounds: 0.46419714225789593\n",
      "LogReg accuracy over 10 rounds: 0.4954261422590057\n",
      "XGB accuracy over 10 rounds: 0.48725249713970553\n",
      "\n",
      "\n",
      "POPANE Study1 --------------------------------------------------\n",
      "POPANE Study5 --------------------------------------------------\n",
      "1    529\n",
      "0    474\n",
      "Name: label, dtype: int64\n",
      "SVM accuracy over 10 rounds: 0.45377052466604706\n",
      "LogReg accuracy over 10 rounds: 0.5193237111147558\n",
      "Model evaluation metrics for LogReg:\n",
      "Precision: 0.5380984953443375\n",
      "Recall: 0.7830709256167163\n",
      "F1-score: 0.6197342295911524\n",
      "AUC score: 0.504008144843438\n",
      "XGB accuracy over 10 rounds: 0.5270228527691214\n",
      "Model evaluation metrics for XGB:\n",
      "Precision: 0.5562060860426488\n",
      "Recall: 0.5657134196811934\n",
      "F1-score: 0.5580012848419583\n",
      "AUC score: 0.5253752726525598\n",
      "\n",
      "\n",
      "POPANE Study2 --------------------------------------------------\n",
      "POPANE Study1 --------------------------------------------------\n",
      "1    487\n",
      "0    463\n",
      "Name: label, dtype: int64\n",
      "SVM accuracy over 10 rounds: 0.44125378023207995\n",
      "LogReg accuracy over 10 rounds: 0.5268317235687174\n",
      "Model evaluation metrics for LogReg:\n",
      "Precision: 0.5479034975571329\n",
      "Recall: 0.6442293186617313\n",
      "F1-score: 0.556921670557162\n",
      "AUC score: 0.5276923968398455\n",
      "XGB accuracy over 10 rounds: 0.4936650774586033\n",
      "\n",
      "\n",
      "POPANE Study2 --------------------------------------------------\n",
      "POPANE Study3 --------------------------------------------------\n",
      "1    492\n",
      "0    461\n",
      "Name: label, dtype: int64\n",
      "SVM accuracy over 10 rounds: 0.4491071626836877\n",
      "LogReg accuracy over 10 rounds: 0.5009008263703899\n",
      "Model evaluation metrics for LogReg:\n",
      "Precision: 0.5182338469825953\n",
      "Recall: 0.7788628303409703\n",
      "F1-score: 0.6067669153033453\n",
      "AUC score: 0.49086864502103167\n",
      "XGB accuracy over 10 rounds: 0.47151954813843355\n",
      "\n",
      "\n",
      "POPANE Study2 --------------------------------------------------\n",
      "POPANE Study5 --------------------------------------------------\n",
      "1    586\n",
      "0    539\n",
      "Name: label, dtype: int64\n",
      "SVM accuracy over 10 rounds: 0.4288042388788657\n",
      "LogReg accuracy over 10 rounds: 0.5146105552821971\n",
      "Model evaluation metrics for LogReg:\n",
      "Precision: 0.5358941405304076\n",
      "Recall: 0.7436702199329037\n",
      "F1-score: 0.6106239892711185\n",
      "AUC score: 0.5003025246196867\n",
      "XGB accuracy over 10 rounds: 0.498184899677437\n",
      "\n",
      "\n",
      "POPANE Study3 --------------------------------------------------\n",
      "POPANE Study1 --------------------------------------------------\n",
      "1    435\n",
      "0    396\n",
      "Name: label, dtype: int64\n",
      "SVM accuracy over 10 rounds: 0.43560789395198424\n",
      "LogReg accuracy over 10 rounds: 0.46843864155965376\n",
      "XGB accuracy over 10 rounds: 0.49968669916784325\n",
      "\n",
      "\n",
      "POPANE Study3 --------------------------------------------------\n",
      "POPANE Study2 --------------------------------------------------\n",
      "1    492\n",
      "0    461\n",
      "Name: label, dtype: int64\n",
      "Only one value in predictions: 0\n",
      "SVM accuracy over 10 rounds: 0.42364218798358955\n",
      "LogReg accuracy over 10 rounds: 0.4858790376568526\n",
      "XGB accuracy over 10 rounds: 0.49092102118867353\n",
      "\n",
      "\n",
      "POPANE Study3 --------------------------------------------------\n",
      "POPANE Study5 --------------------------------------------------\n",
      "1    534\n",
      "0    472\n",
      "Name: label, dtype: int64\n",
      "Only one value in predictions: 1\n",
      "Only one value in predictions: 1\n",
      "Only one value in predictions: 1\n",
      "Only one value in predictions: 1\n",
      "SVM accuracy over 10 rounds: 0.4424762149039697\n",
      "LogReg accuracy over 10 rounds: 0.5103375182384392\n",
      "Model evaluation metrics for LogReg:\n",
      "Precision: 0.5174109061919718\n",
      "Recall: 0.8220929855601268\n",
      "F1-score: 0.6069248902089013\n",
      "AUC score: 0.49629236495925166\n",
      "XGB accuracy over 10 rounds: 0.5011727078891257\n",
      "Model evaluation metrics for XGB:\n",
      "Precision: 0.5270829836518922\n",
      "Recall: 0.5602292411823514\n",
      "F1-score: 0.5392087508874982\n",
      "AUC score: 0.499372592788707\n",
      "\n",
      "\n",
      "POPANE Study5 --------------------------------------------------\n",
      "POPANE Study1 --------------------------------------------------\n",
      "1    529\n",
      "0    474\n",
      "Name: label, dtype: int64\n",
      "SVM accuracy over 10 rounds: 0.4384235507621711\n",
      "LogReg accuracy over 10 rounds: 0.49783861744090424\n",
      "XGB accuracy over 10 rounds: 0.5155832858931046\n",
      "Model evaluation metrics for XGB:\n",
      "Precision: 0.5387841463308994\n",
      "Recall: 0.533447452171503\n",
      "F1-score: 0.5312242376460505\n",
      "AUC score: 0.5168170290048729\n",
      "\n",
      "\n",
      "POPANE Study5 --------------------------------------------------\n",
      "POPANE Study2 --------------------------------------------------\n",
      "1    586\n",
      "0    539\n",
      "Name: label, dtype: int64\n",
      "SVM accuracy over 10 rounds: 0.4456026568920953\n",
      "LogReg accuracy over 10 rounds: 0.49997211808664843\n",
      "XGB accuracy over 10 rounds: 0.4980856062218767\n",
      "\n",
      "\n",
      "POPANE Study5 --------------------------------------------------\n",
      "POPANE Study3 --------------------------------------------------\n",
      "1    534\n",
      "0    472\n",
      "Name: label, dtype: int64\n",
      "Only one value in predictions: 1\n",
      "Only one value in predictions: 1\n",
      "SVM accuracy over 10 rounds: 0.46998614228864277\n",
      "LogReg accuracy over 10 rounds: 0.5066722236645743\n",
      "Model evaluation metrics for LogReg:\n",
      "Precision: 0.5145768582753006\n",
      "Recall: 0.936907894654882\n",
      "F1-score: 0.6631527546204525\n",
      "AUC score: 0.4893892682820665\n",
      "XGB accuracy over 10 rounds: 0.5009192087079855\n",
      "Model evaluation metrics for XGB:\n",
      "Precision: 0.5215372555448815\n",
      "Recall: 0.5694208636109629\n",
      "F1-score: 0.539548364991566\n",
      "AUC score: 0.5006386375746378\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAIN ON APD AND TEST ON POPANE\n",
    "importlib.reload(train)\n",
    "importlib.reload(dr_p)\n",
    "importlib.reload(dt)\n",
    "\n",
    "\n",
    "metrics = [\n",
    "    train.Metrics.BPM, \n",
    "    train.Metrics.RMSSD, \n",
    "    train.Metrics.HF_RR, \n",
    "    train.Metrics.LF_RR, \n",
    "    train.Metrics.IBI, \n",
    "    train.Metrics.SDNN, \n",
    "    train.Metrics.MEAN_SCL, \n",
    "    train.Metrics.SCR_RATE\n",
    "]\n",
    "\n",
    "studies_popane = [\n",
    "    \"Study1\",\n",
    "    \"Study2\",\n",
    "    \"Study3\",\n",
    "    # \"Study4\",\n",
    "    \"Study5\",\n",
    "    # \"Study6\",\n",
    "    # \"Study7\"\n",
    "]\n",
    "\n",
    "model_phases_popane = [\n",
    "    dr_p.Study1.ALL,\n",
    "    dr_p.Study2.ALL,\n",
    "    dr_p.Study3.ALL,\n",
    "    # dr_p.Study4.ALL,\n",
    "    dr_p.Study5.ALL\n",
    "    # dr_p.Study6.ALL\n",
    "    # dr_p.Study7.ALL\n",
    "]\n",
    "\n",
    "popane_label_type = \"affect\"\n",
    "\n",
    "models = {\n",
    "    \"SVM\": SVC(C=10, gamma=1),  # C=10, gamma=1\n",
    "    \"LogReg\": LogisticRegression(max_iter=1000),\n",
    "    \"XGB\": XGBClassifier(use_label_encoder=False, objective=\"binary:logistic\", eval_metric=\"logloss\")\n",
    "}\n",
    "\n",
    "threshold = \"dynamic\"\n",
    "test_size = 0.8\n",
    "\n",
    "for i in range(len(studies_popane)):\n",
    "    for j in range(len(studies_popane)):\n",
    "        if j == i:\n",
    "            continue\n",
    "        print(f\"POPANE {studies_popane[i]} \" + \"-\"*50)\n",
    "        print(f\"POPANE {studies_popane[j]} \" + \"-\"*50)\n",
    "        x_a, y_a = train.Train_POPANE.get_popane_data(studies_popane[i], metrics, model_phases_popane[i], verbose=False, label_type=popane_label_type, threshold=threshold)\n",
    "        x_b, y_b = train.Train_POPANE.get_popane_data(studies_popane[j], metrics, model_phases_popane[j], verbose=False, label_type=popane_label_type, threshold=threshold)\n",
    "        \n",
    "        inds = pd.isnull(x_a).any(1).to_numpy().nonzero()[0]\n",
    "        x_a = x_a.drop(inds, axis=0)\n",
    "        y_a = y_a.drop(inds, axis=0)\n",
    "        \n",
    "        inds = pd.isnull(x_b).any(1).to_numpy().nonzero()[0]\n",
    "        x_b = x_b.drop(inds, axis=0)\n",
    "        y_b = y_b.drop(inds, axis=0)\n",
    "\n",
    "        x_a = x_a.drop([\"phaseId\"], axis=1)\n",
    "        x_b = x_b.drop([\"phaseId\"], axis=1)\n",
    "\n",
    "        # make sure subjects from different datasets aren't labeled with the same index\n",
    "        x_b[\"subject\"] = x_b[\"subject\"] + 500\n",
    "\n",
    "        if y_a.isnull().values.any():\n",
    "            print(\"y_a contains NaN\")\n",
    "\n",
    "        if y_b.isnull().values.any():\n",
    "            print(\"y_b contains NaN\")\n",
    "\n",
    "        # 0-1 scaling\n",
    "        for c in range(3, len(x_a.columns)):\n",
    "            data_col = x_a[x_a.columns[c]]\n",
    "            data_col = (data_col - data_col.min())/(data_col.max() - data_col.min())\n",
    "            x_a[x_a.columns[c]] = data_col\n",
    "        # 0-1 scaling\n",
    "        for c in range(3, len(x_b.columns)):\n",
    "            data_col = x_b[x_b.columns[c]]\n",
    "            data_col = (data_col - data_col.min())/(data_col.max() - data_col.min())\n",
    "            x_b[x_b.columns[c]] = data_col\n",
    "\n",
    "        print(y_a.loc[:, \"label\"].value_counts() + y_b.loc[:, \"label\"].value_counts())\n",
    "\n",
    "        acc_results = {\n",
    "            \"SVM\": [], \n",
    "            # \"KNN\": [],\n",
    "            # \"DT\": [],\n",
    "            \"LogReg\": [],\n",
    "            # \"Bayes\": [],\n",
    "            \"XGB\": []\n",
    "        }\n",
    "        reports = {\n",
    "            \"SVM\": [], \n",
    "            # \"KNN\": [],\n",
    "            # \"DT\": [],\n",
    "            \"LogReg\": [],\n",
    "            # \"Bayes\": [],\n",
    "            \"XGB\": [],\n",
    "        }\n",
    "        num_iters = 10\n",
    "        for _ in range(num_iters):\n",
    "            out = train.Train_Multi_Dataset.train_across_datasets(models, x_a, y_a, x_b, y_b, by_subject=False, save_metrics=True, test_size=test_size)\n",
    "            for model_name in acc_results:\n",
    "                acc_results[model_name].append(out[model_name][0])\n",
    "                reports[model_name].append(out[model_name][1])\n",
    "\n",
    "        for model_name in acc_results.keys():\n",
    "            acc = np.mean(acc_results[model_name])\n",
    "            print(f\"{model_name} accuracy over {num_iters} rounds: {acc}\")\n",
    "            if acc > 0.5:\n",
    "                print(f\"Model evaluation metrics for {model_name}:\")\n",
    "                p = np.mean([report[\"precision\"] for report in reports[model_name]])\n",
    "                r = np.mean([report[\"recall\"] for report in reports[model_name]])\n",
    "                f1 = np.mean([report[\"f1\"] for report in reports[model_name]])\n",
    "                idx = np.argmax([report[\"f1\"] for report in reports[model_name]])\n",
    "                auc = np.mean([report[\"auc\"] for report in reports[model_name]])\n",
    "                report = reports[model_name]\n",
    "                print(f\"Precision: {p}\\nRecall: {r}\\nF1-score: {f1}\\nAUC score: {auc}\")\n",
    "                plot_y = reports[model_name][idx][\"actual vs pred\"]\n",
    "                _, y_test_counts = np.unique(plot_y[0], return_counts=True)\n",
    "                _, y_pred_counts = np.unique(plot_y[1], return_counts=True)\n",
    "\n",
    "                # br1 = [0, 0.5]\n",
    "                # br2 = [1, 1.5]\n",
    "                \n",
    "                # x = [0, 1]\n",
    "                # x_axis = np.arange(len(x))\n",
    "                # plt.bar(x_axis-0.1, y_test_counts, 0.2, label=\"Actual\")\n",
    "                # plt.bar(x_axis+0.1, y_pred_counts, 0.2, label=\"Predicted\")\n",
    "                # plt.xticks(x_axis, x)\n",
    "                # plt.legend()\n",
    "                # plt.show()\n",
    "\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_label_encoder` is deprecated in 1.7.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POPANE Study2 --------------------------------------------------\n",
      "POPANE Study1 --------------------------------------------------\n",
      "1    487\n",
      "0    463\n",
      "Name: label, dtype: int64\n",
      "SVM accuracy over 10 rounds: 0.4356078843952993\n",
      "LogReg accuracy over 10 rounds: 0.5177962283865363\n",
      "Model evaluation metrics for LogReg:\n",
      "Precision: 0.5589064396606184\n",
      "Recall: 0.537396548488492\n",
      "F1-score: 0.4856201554967071\n",
      "AUC score: 0.5232449895588376\n",
      "XGB accuracy over 10 rounds: 0.5002841828627835\n",
      "Model evaluation metrics for XGB:\n",
      "Precision: 0.5262219312346593\n",
      "Recall: 0.5290731344653568\n",
      "F1-score: 0.5250630329201862\n",
      "AUC score: 0.4998491278290936\n",
      "\n",
      "\n",
      "POPANE Study3 --------------------------------------------------\n",
      "POPANE Study1 --------------------------------------------------\n",
      "1    435\n",
      "0    396\n",
      "Name: label, dtype: int64\n",
      "Only one value in predictions: 1\n",
      "SVM accuracy over 10 rounds: 0.44456576799684805\n",
      "LogReg accuracy over 10 rounds: 0.4699836776045478\n",
      "XGB accuracy over 10 rounds: 0.5208232490947637\n",
      "Model evaluation metrics for XGB:\n",
      "Precision: 0.5481531372613653\n",
      "Recall: 0.5058847320216273\n",
      "F1-score: 0.5214008045962142\n",
      "AUC score: 0.5230415040488736\n",
      "\n",
      "\n",
      "POPANE Study5 --------------------------------------------------\n",
      "POPANE Study1 --------------------------------------------------\n",
      "1    529\n",
      "0    474\n",
      "Name: label, dtype: int64\n",
      "SVM accuracy over 10 rounds: 0.4385361550510353\n",
      "LogReg accuracy over 10 rounds: 0.49214256329930983\n",
      "XGB accuracy over 10 rounds: 0.5298598321198456\n",
      "Model evaluation metrics for XGB:\n",
      "Precision: 0.547168342646658\n",
      "Recall: 0.5906995815809104\n",
      "F1-score: 0.5664211425375107\n",
      "AUC score: 0.527844982192367\n",
      "\n",
      "\n",
      "POPANE Study1 --------------------------------------------------\n",
      "POPANE Study2 --------------------------------------------------\n",
      "1    487\n",
      "0    463\n",
      "Name: label, dtype: int64\n",
      "SVM accuracy over 10 rounds: 0.4289666751521716\n",
      "LogReg accuracy over 10 rounds: 0.5295859258417004\n",
      "Model evaluation metrics for LogReg:\n",
      "Precision: 0.5966053454264653\n",
      "Recall: 0.4159574983506739\n",
      "F1-score: 0.42212494610730805\n",
      "AUC score: 0.5395253277131482\n",
      "XGB accuracy over 10 rounds: 0.48943768345606153\n",
      "\n",
      "\n",
      "POPANE Study3 --------------------------------------------------\n",
      "POPANE Study2 --------------------------------------------------\n",
      "1    492\n",
      "0    461\n",
      "Name: label, dtype: int64\n",
      "SVM accuracy over 10 rounds: 0.43577229523814925\n",
      "LogReg accuracy over 10 rounds: 0.501054954518224\n",
      "Model evaluation metrics for LogReg:\n",
      "Precision: 0.5499819318258254\n",
      "Recall: 0.26239736155678484\n",
      "F1-score: 0.2960137938690016\n",
      "AUC score: 0.5113957056797106\n",
      "XGB accuracy over 10 rounds: 0.49147507404249957\n",
      "\n",
      "\n",
      "POPANE Study5 --------------------------------------------------\n",
      "POPANE Study2 --------------------------------------------------\n",
      "1    586\n",
      "0    539\n",
      "Name: label, dtype: int64\n",
      "SVM accuracy over 10 rounds: 0.42637165580108977\n",
      "LogReg accuracy over 10 rounds: 0.5000294251590053\n",
      "Model evaluation metrics for LogReg:\n",
      "Precision: 0.5523772488435899\n",
      "Recall: 0.5404877657395126\n",
      "F1-score: 0.4411924716290046\n",
      "AUC score: 0.5098737493900489\n",
      "XGB accuracy over 10 rounds: 0.49615873103397573\n",
      "\n",
      "\n",
      "POPANE Study1 --------------------------------------------------\n",
      "POPANE Study3 --------------------------------------------------\n",
      "1    435\n",
      "0    396\n",
      "Name: label, dtype: int64\n",
      "Only one value in predictions: 1\n",
      "SVM accuracy over 10 rounds: 0.4549589653131467\n",
      "LogReg accuracy over 10 rounds: 0.5016745151957597\n",
      "Model evaluation metrics for LogReg:\n",
      "Precision: 0.5135072460973225\n",
      "Recall: 0.7632586081624001\n",
      "F1-score: 0.5847411316605348\n",
      "AUC score: 0.49331618338189587\n",
      "XGB accuracy over 10 rounds: 0.49741550622247416\n",
      "\n",
      "\n",
      "POPANE Study2 --------------------------------------------------\n",
      "POPANE Study3 --------------------------------------------------\n",
      "1    492\n",
      "0    461\n",
      "Name: label, dtype: int64\n",
      "SVM accuracy over 10 rounds: 0.45752141475545727\n",
      "LogReg accuracy over 10 rounds: 0.4824113475177305\n",
      "XGB accuracy over 10 rounds: 0.4557234963617942\n",
      "\n",
      "\n",
      "POPANE Study5 --------------------------------------------------\n",
      "POPANE Study3 --------------------------------------------------\n",
      "1    534\n",
      "0    472\n",
      "Name: label, dtype: int64\n",
      "Only one value in predictions: 1\n",
      "SVM accuracy over 10 rounds: 0.45421625972404645\n",
      "LogReg accuracy over 10 rounds: 0.5054390121717502\n",
      "Model evaluation metrics for LogReg:\n",
      "Precision: 0.5351484977159873\n",
      "Recall: 0.7199819075015229\n",
      "F1-score: 0.5922006049270646\n",
      "AUC score: 0.4929884070244622\n",
      "XGB accuracy over 10 rounds: 0.48334326246364834\n",
      "\n",
      "\n",
      "POPANE Study1 --------------------------------------------------\n",
      "POPANE Study5 --------------------------------------------------\n",
      "1    529\n",
      "0    474\n",
      "Name: label, dtype: int64\n",
      "SVM accuracy over 10 rounds: 0.4463396388023254\n",
      "LogReg accuracy over 10 rounds: 0.5112022558084799\n",
      "Model evaluation metrics for LogReg:\n",
      "Precision: 0.5257463996942265\n",
      "Recall: 0.8495317549480068\n",
      "F1-score: 0.6324967307994276\n",
      "AUC score: 0.492947266178716\n",
      "XGB accuracy over 10 rounds: 0.5321042069676556\n",
      "Model evaluation metrics for XGB:\n",
      "Precision: 0.5566957131424662\n",
      "Recall: 0.5818393291479044\n",
      "F1-score: 0.5674234556418818\n",
      "AUC score: 0.5295136006223368\n",
      "\n",
      "\n",
      "POPANE Study2 --------------------------------------------------\n",
      "POPANE Study5 --------------------------------------------------\n",
      "1    586\n",
      "0    539\n",
      "Name: label, dtype: int64\n",
      "SVM accuracy over 10 rounds: 0.44720842634307234\n",
      "LogReg accuracy over 10 rounds: 0.513952748144555\n",
      "Model evaluation metrics for LogReg:\n",
      "Precision: 0.5274513781684238\n",
      "Recall: 0.8491160090402137\n",
      "F1-score: 0.6500721944712939\n",
      "AUC score: 0.4908482839616256\n",
      "XGB accuracy over 10 rounds: 0.49902641728618236\n",
      "\n",
      "\n",
      "POPANE Study3 --------------------------------------------------\n",
      "POPANE Study5 --------------------------------------------------\n",
      "1    534\n",
      "0    472\n",
      "Name: label, dtype: int64\n",
      "Only one value in predictions: 1\n",
      "SVM accuracy over 10 rounds: 0.4428542050777195\n",
      "LogReg accuracy over 10 rounds: 0.5032146850088244\n",
      "Model evaluation metrics for LogReg:\n",
      "Precision: 0.4999838626099688\n",
      "Recall: 0.7867999221404782\n",
      "F1-score: 0.5857010696963888\n",
      "AUC score: 0.49237765997962957\n",
      "XGB accuracy over 10 rounds: 0.5119289811674614\n",
      "Model evaluation metrics for XGB:\n",
      "Precision: 0.5387850680324594\n",
      "Recall: 0.5761416482070894\n",
      "F1-score: 0.5536148899692349\n",
      "AUC score: 0.5096160237136385\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAIN ON APD AND TEST ON POPANE\n",
    "importlib.reload(train)\n",
    "importlib.reload(dr_p)\n",
    "importlib.reload(dt)\n",
    "\n",
    "\n",
    "metrics = [\n",
    "    train.Metrics.BPM, \n",
    "    train.Metrics.RMSSD, \n",
    "    train.Metrics.HF_RR, \n",
    "    train.Metrics.LF_RR, \n",
    "    train.Metrics.IBI, \n",
    "    train.Metrics.SDNN, \n",
    "    train.Metrics.MEAN_SCL, \n",
    "    train.Metrics.SCR_RATE\n",
    "]\n",
    "\n",
    "studies_popane = [\n",
    "    \"Study1\",\n",
    "    \"Study2\",\n",
    "    \"Study3\",\n",
    "    # \"Study4\",\n",
    "    \"Study5\",\n",
    "    # \"Study6\",\n",
    "    # \"Study7\"\n",
    "]\n",
    "\n",
    "model_phases_popane = [\n",
    "    dr_p.Study1.ALL,\n",
    "    dr_p.Study2.ALL,\n",
    "    dr_p.Study3.ALL,\n",
    "    # dr_p.Study4.ALL,\n",
    "    dr_p.Study5.ALL\n",
    "    # dr_p.Study6.ALL\n",
    "    # dr_p.Study7.ALL\n",
    "]\n",
    "\n",
    "popane_label_type = \"affect\"\n",
    "\n",
    "models = {\n",
    "    \"SVM\": SVC(C=10, gamma=1),  # C=10, gamma=1\n",
    "    \"LogReg\": LogisticRegression(max_iter=1000),\n",
    "    \"XGB\": XGBClassifier(use_label_encoder=False, objective=\"binary:logistic\", eval_metric=\"logloss\")\n",
    "}\n",
    "\n",
    "threshold = \"dynamic\"\n",
    "test_size = 0.8\n",
    "\n",
    "for j in range(len(studies_popane)):\n",
    "    for i in range(len(studies_popane)):\n",
    "        if i == j:\n",
    "            continue\n",
    "        print(f\"POPANE {studies_popane[i]} \" + \"-\"*50)\n",
    "        print(f\"POPANE {studies_popane[j]} \" + \"-\"*50)\n",
    "        x_a, y_a = train.Train_POPANE.get_popane_data(studies_popane[i], metrics, model_phases_popane[i], verbose=False, label_type=popane_label_type, threshold=threshold)\n",
    "        x_b, y_b = train.Train_POPANE.get_popane_data(studies_popane[j], metrics, model_phases_popane[j], verbose=False, label_type=popane_label_type, threshold=threshold)\n",
    "        \n",
    "        inds = pd.isnull(x_a).any(1).to_numpy().nonzero()[0]\n",
    "        x_a = x_a.drop(inds, axis=0)\n",
    "        y_a = y_a.drop(inds, axis=0)\n",
    "        \n",
    "        inds = pd.isnull(x_b).any(1).to_numpy().nonzero()[0]\n",
    "        x_b = x_b.drop(inds, axis=0)\n",
    "        y_b = y_b.drop(inds, axis=0)\n",
    "\n",
    "        x_a = x_a.drop([\"phaseId\"], axis=1)\n",
    "        x_b = x_b.drop([\"phaseId\"], axis=1)\n",
    "\n",
    "        # make sure subjects from different datasets aren't labeled with the same index\n",
    "        x_b[\"subject\"] = x_b[\"subject\"] + 500\n",
    "\n",
    "        if y_a.isnull().values.any():\n",
    "            print(\"y_a contains NaN\")\n",
    "\n",
    "        if y_b.isnull().values.any():\n",
    "            print(\"y_b contains NaN\")\n",
    "\n",
    "        # 0-1 scaling\n",
    "        for c in range(3, len(x_a.columns)):\n",
    "            data_col = x_a[x_a.columns[c]]\n",
    "            data_col = (data_col - data_col.min())/(data_col.max() - data_col.min())\n",
    "            x_a[x_a.columns[c]] = data_col\n",
    "        # 0-1 scaling\n",
    "        for c in range(3, len(x_b.columns)):\n",
    "            data_col = x_b[x_b.columns[c]]\n",
    "            data_col = (data_col - data_col.min())/(data_col.max() - data_col.min())\n",
    "            x_b[x_b.columns[c]] = data_col\n",
    "\n",
    "        print(y_a.loc[:, \"label\"].value_counts() + y_b.loc[:, \"label\"].value_counts())\n",
    "\n",
    "        acc_results = {\n",
    "            \"SVM\": [], \n",
    "            # \"KNN\": [],\n",
    "            # \"DT\": [],\n",
    "            \"LogReg\": [],\n",
    "            # \"Bayes\": [],\n",
    "            \"XGB\": []\n",
    "        }\n",
    "        reports = {\n",
    "            \"SVM\": [], \n",
    "            # \"KNN\": [],\n",
    "            # \"DT\": [],\n",
    "            \"LogReg\": [],\n",
    "            # \"Bayes\": [],\n",
    "            \"XGB\": [],\n",
    "        }\n",
    "        num_iters = 10\n",
    "        for _ in range(num_iters):\n",
    "            out = train.Train_Multi_Dataset.train_across_datasets(models, x_a, y_a, x_b, y_b, by_subject=False, save_metrics=True, test_size=test_size)\n",
    "            for model_name in acc_results:\n",
    "                acc_results[model_name].append(out[model_name][0])\n",
    "                reports[model_name].append(out[model_name][1])\n",
    "\n",
    "        for model_name in acc_results.keys():\n",
    "            acc = np.mean(acc_results[model_name])\n",
    "            print(f\"{model_name} accuracy over {num_iters} rounds: {acc}\")\n",
    "            if acc > 0.5:\n",
    "                print(f\"Model evaluation metrics for {model_name}:\")\n",
    "                p = np.mean([report[\"precision\"] for report in reports[model_name]])\n",
    "                r = np.mean([report[\"recall\"] for report in reports[model_name]])\n",
    "                f1 = np.mean([report[\"f1\"] for report in reports[model_name]])\n",
    "                idx = np.argmax([report[\"f1\"] for report in reports[model_name]])\n",
    "                auc = np.mean([report[\"auc\"] for report in reports[model_name]])\n",
    "                report = reports[model_name]\n",
    "                print(f\"Precision: {p}\\nRecall: {r}\\nF1-score: {f1}\\nAUC score: {auc}\")\n",
    "                plot_y = reports[model_name][idx][\"actual vs pred\"]\n",
    "                _, y_test_counts = np.unique(plot_y[0], return_counts=True)\n",
    "                _, y_pred_counts = np.unique(plot_y[1], return_counts=True)\n",
    "\n",
    "                # br1 = [0, 0.5]\n",
    "                # br2 = [1, 1.5]\n",
    "                \n",
    "                # x = [0, 1]\n",
    "                # x_axis = np.arange(len(x))\n",
    "                # plt.bar(x_axis-0.1, y_test_counts, 0.2, label=\"Actual\")\n",
    "                # plt.bar(x_axis+0.1, y_pred_counts, 0.2, label=\"Predicted\")\n",
    "                # plt.xticks(x_axis, x)\n",
    "                # plt.legend()\n",
    "                # plt.show()\n",
    "\n",
    "        print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
