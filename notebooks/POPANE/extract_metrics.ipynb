{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING MODULES\n",
    "import glob\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.signal as ss\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..', '..', 'src'))\n",
    "sys.path.append(module_path)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tools.data_reader_popane as dr\n",
    "import tools.display_tools as dt\n",
    "import tools.preprocessing as preprocessing\n",
    "\n",
    "from scipy.fft import fft, fftfreq, fftshift\n",
    "\n",
    "import cvxopt.solvers\n",
    "cvxopt.solvers.options['show_progress'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STUDY: 3\n",
      "PHASE: Baseline\n",
      "PHASE: Gratitude\n",
      "PHASE: Neutral9\n",
      "STUDY: 4\n",
      "PHASE: Baseline\n",
      "PHASE: Fear2\n",
      "PHASE: Neutral10\n",
      "STUDY: 5\n",
      "PHASE: Anger1\n",
      "PHASE: Anger2\n",
      "PHASE: Anger3\n",
      "PHASE: Neutral1\n",
      "PHASE: Neutral6\n",
      "PHASE: Neutral7\n",
      "PHASE: Amusement2\n",
      "PHASE: Amusement3\n",
      "PHASE: Amusement4\n"
     ]
    }
   ],
   "source": [
    "# FEATURE EXTRACTION WITH HEARTPY - BPM, RMSSD, IBI\n",
    "# WORKS\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "importlib.reload(preprocessing)\n",
    "\n",
    "import heartpy as hp\n",
    "\n",
    "convert_sr = False\n",
    "studies = {\n",
    "    # 1: dr.Study1,\n",
    "    3: dr.Study3, \n",
    "    4: dr.Study4, \n",
    "    5: dr.Study5\n",
    "}\n",
    "is_clean_ecg = True\n",
    "signal = dr.Signals.ECG\n",
    "measure = \"bpm\"\n",
    "# measure = \"rmssd\"\n",
    "# measure = \"ibi\"\n",
    "# measure = \"sdnn\"\n",
    "# measure = \"breathingrate\"\n",
    "fs = 1000.0\n",
    "f_dim = preprocessing.DATA_TYPE_DIMENSIONS[\"Heart\"]\n",
    "\n",
    "for study_num in studies.keys():\n",
    "    print(f\"STUDY: {study_num}\")\n",
    "    phases = studies[study_num].ALL\n",
    "    subjects = dr.get_subjects(study_num)\n",
    "    for phase in phases:\n",
    "        print(f\"PHASE: {phase}\")\n",
    "        df = []\n",
    "        for subject in subjects:\n",
    "            # print(f\"SUBJECT: {subject}\")\n",
    "            try:\n",
    "                data = dr.get_data_for_subject(study_num, subject, phase, signal).to_numpy()\n",
    "                # data = data.flatten()\n",
    "                working_data, measures = hp.process_segmentwise(data, fs, segment_width=55, segment_overlap=5/55)\n",
    "                value = measures[f\"{measure}\"]\n",
    "                value = np.insert(value, 0, subject)\n",
    "                df.append(value)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        df = pd.DataFrame(df)\n",
    "        file = os.path.join(dr.Paths.METRICS, f\"Study{study_num}\", f\"{measure}_{phase}.csv\")\n",
    "        with open(file, \"w+\") as f:\n",
    "            df.to_csv(f)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE EXTRACTION WITH HEARTPY - LF_RR, HF_RR\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "importlib.reload(preprocessing)\n",
    "\n",
    "convert_sr = False\n",
    "studies = {\n",
    "    1: dr.Study1,\n",
    "    3: dr.Study3, \n",
    "    4: dr.Study4, \n",
    "    5: dr.Study5\n",
    "}\n",
    "is_clean_ecg = True\n",
    "signal = dr.Signals.ECG\n",
    "fs = 1000.0\n",
    "f_dim = preprocessing.DATA_TYPE_DIMENSIONS[\"Heart\"]\n",
    "\n",
    "for study_num in studies.keys():\n",
    "    print(f\"STUDY: {study_num}\")\n",
    "    phases = studies[study_num].ALL\n",
    "    subjects = dr.get_subjects(study_num)\n",
    "    for phase in phases:\n",
    "        print(f\"PHASE: {phase}\")\n",
    "        metrics_dict = {\n",
    "            \"lf_rr\": [],\n",
    "            \"hf_rr\": [],\n",
    "        }\n",
    "        for subject in subjects:\n",
    "            # print(f\"SUBJECT: {subject}\")\n",
    "            try:\n",
    "                data = dr.get_data_for_subject(study_num, subject, phase, signal).to_numpy()\n",
    "                # data = data.flatten()\n",
    "                ecg_signal = preprocessing.clean_ecg(data)\n",
    "                lf_rr = preprocessing.get_lf_rr(ecg_signal, fs)\n",
    "                lf_rr = np.insert(lf_rr, 0, subject)\n",
    "                lf_rr = pd.DataFrame(lf_rr).dropna(axis=1)\n",
    "\n",
    "                hf_rr = preprocessing.get_lf_rr(ecg_signal, fs)\n",
    "                hf_rr = np.insert(hf_rr, 0, subject)\n",
    "                hf_rr = pd.DataFrame(hf_rr).dropna(axis=1)\n",
    "                \n",
    "                metrics_dict[\"lf_rr\"].append(lf_rr)\n",
    "                metrics_dict[\"hf_rr\"].append(hf_rr)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        for metric in list(metrics_dict.keys()):\n",
    "            df = pd.concat(metrics_dict[metric], axis=1)\n",
    "            df = df.transpose()\n",
    "            file = os.path.join(dr.Paths.METRICS, f\"Study{study_num}\", f\"{metric}_{phase}.csv\")\n",
    "            with open(file, \"w+\") as f:\n",
    "                df.to_csv(f)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STUDY: 1\n",
      "PHASE: Baseline\n",
      "SUBJECT: 1\n",
      "SUBJECT: 2\n",
      "SUBJECT: 3\n",
      "SUBJECT: 4\n",
      "SUBJECT: 5\n",
      "SUBJECT: 6\n",
      "SUBJECT: 7\n",
      "SUBJECT: 8\n",
      "SUBJECT: 9\n",
      "SUBJECT: 10\n",
      "SUBJECT: 11\n",
      "SUBJECT: 12\n",
      "SUBJECT: 13\n",
      "SUBJECT: 14\n",
      "SUBJECT: 15\n",
      "SUBJECT: 16\n",
      "SUBJECT: 17\n",
      "SUBJECT: 18\n",
      "SUBJECT: 19\n",
      "SUBJECT: 20\n",
      "SUBJECT: 21\n",
      "SUBJECT: 22\n",
      "SUBJECT: 23\n",
      "SUBJECT: 24\n",
      "SUBJECT: 25\n",
      "SUBJECT: 26\n",
      "SUBJECT: 27\n",
      "SUBJECT: 28\n",
      "SUBJECT: 29\n",
      "SUBJECT: 30\n",
      "SUBJECT: 31\n",
      "SUBJECT: 32\n",
      "SUBJECT: 33\n",
      "SUBJECT: 34\n",
      "SUBJECT: 35\n",
      "SUBJECT: 36\n",
      "SUBJECT: 37\n",
      "SUBJECT: 38\n",
      "SUBJECT: 39\n",
      "SUBJECT: 40\n",
      "SUBJECT: 41\n",
      "SUBJECT: 42\n",
      "SUBJECT: 43\n",
      "SUBJECT: 44\n",
      "SUBJECT: 45\n",
      "SUBJECT: 46\n",
      "SUBJECT: 47\n",
      "SUBJECT: 48\n",
      "SUBJECT: 49\n",
      "SUBJECT: 50\n",
      "SUBJECT: 51\n",
      "SUBJECT: 52\n",
      "SUBJECT: 53\n",
      "SUBJECT: 54\n",
      "SUBJECT: 55\n",
      "SUBJECT: 56\n",
      "SUBJECT: 57\n",
      "SUBJECT: 58\n",
      "SUBJECT: 59\n",
      "SUBJECT: 60\n",
      "SUBJECT: 61\n",
      "SUBJECT: 62\n",
      "SUBJECT: 63\n",
      "SUBJECT: 64\n",
      "SUBJECT: 65\n",
      "SUBJECT: 66\n",
      "SUBJECT: 67\n",
      "SUBJECT: 68\n",
      "SUBJECT: 69\n",
      "SUBJECT: 70\n",
      "SUBJECT: 71\n",
      "SUBJECT: 72\n",
      "SUBJECT: 73\n",
      "SUBJECT: 74\n",
      "SUBJECT: 75\n",
      "SUBJECT: 76\n",
      "SUBJECT: 77\n",
      "SUBJECT: 78\n",
      "SUBJECT: 79\n",
      "SUBJECT: 80\n",
      "SUBJECT: 81\n",
      "SUBJECT: 82\n",
      "SUBJECT: 83\n",
      "SUBJECT: 84\n",
      "SUBJECT: 85\n",
      "SUBJECT: 86\n",
      "SUBJECT: 87\n",
      "SUBJECT: 88\n",
      "SUBJECT: 89\n",
      "SUBJECT: 90\n",
      "SUBJECT: 91\n",
      "SUBJECT: 92\n",
      "SUBJECT: 93\n",
      "SUBJECT: 94\n",
      "SUBJECT: 95\n",
      "SUBJECT: 96\n",
      "SUBJECT: 97\n",
      "SUBJECT: 98\n",
      "SUBJECT: 99\n",
      "SUBJECT: 100\n",
      "SUBJECT: 101\n",
      "SUBJECT: 102\n",
      "SUBJECT: 103\n",
      "SUBJECT: 104\n",
      "SUBJECT: 105\n",
      "SUBJECT: 106\n",
      "SUBJECT: 107\n",
      "SUBJECT: 108\n",
      "SUBJECT: 109\n",
      "SUBJECT: 110\n",
      "SUBJECT: 111\n",
      "SUBJECT: 112\n",
      "SUBJECT: 113\n",
      "SUBJECT: 114\n",
      "SUBJECT: 115\n",
      "SUBJECT: 116\n",
      "SUBJECT: 117\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m data \u001b[39m=\u001b[39m samplerate\u001b[39m.\u001b[39mresample(data, ratio\u001b[39m=\u001b[39m\u001b[39m250.0\u001b[39m\u001b[39m/\u001b[39m\u001b[39m1000.0\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[39m# data = data.flatten()\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m mean_scl \u001b[39m=\u001b[39m preprocessing\u001b[39m.\u001b[39;49mget_mean_SCL(data, fs)\n\u001b[0;32m     35\u001b[0m mean_scl \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39minsert(mean_scl, \u001b[39m0\u001b[39m, subject)\n\u001b[0;32m     36\u001b[0m mean_scl \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(mean_scl)\u001b[39m.\u001b[39mdropna(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zhoux\\Desktop\\Projects\\anxiety\\src\\tools\\preprocessing.py:302\u001b[0m, in \u001b[0;36mget_mean_SCL\u001b[1;34m(eda_signal, fs)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_mean_SCL\u001b[39m(eda_signal, fs\u001b[39m=\u001b[39mFS_DICT[dr\u001b[39m.\u001b[39mDataTypes\u001b[39m.\u001b[39mEDA]):\n\u001b[1;32m--> 302\u001b[0m     _, scl \u001b[39m=\u001b[39m get_SC_metrics(eda_signal, fs)\n\u001b[0;32m    303\u001b[0m     \u001b[39mif\u001b[39;00m scl \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    304\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhoux\\Desktop\\Projects\\anxiety\\src\\tools\\preprocessing.py:295\u001b[0m, in \u001b[0;36mget_SC_metrics\u001b[1;34m(eda, fs)\u001b[0m\n\u001b[0;32m    290\u001b[0m eda \u001b[39m=\u001b[39m eda\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mdouble)\n\u001b[0;32m    291\u001b[0m \u001b[39m# sos = ss.butter(N=3, Wn=4.0, btype=\"lowpass\", fs=fs, output=\"sos\")\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[39m# filtered = ss.sosfilt(sos, eda_signal)\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[39m# sr = 200*(272+filtered)/(752-filtered)\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[39m# sc = 1/sr\u001b[39;00m\n\u001b[1;32m--> 295\u001b[0m [r, p, t, l, d, e, obj] \u001b[39m=\u001b[39m cvxEDA(eda, \u001b[39m1.\u001b[39;49m\u001b[39m/\u001b[39;49mfs, options\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mshow_progress\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mFalse\u001b[39;49;00m})\n\u001b[0;32m    296\u001b[0m r \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog10(r \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m    297\u001b[0m p \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog10(p \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zhoux\\Desktop\\Projects\\anxiety\\cvxEDA\\src\\cvxEDA.py:125\u001b[0m, in \u001b[0;36mcvxEDA\u001b[1;34m(y, delta, tau0, tau1, delta_knot, alpha, gamma, solver, options)\u001b[0m\n\u001b[0;32m    122\u001b[0m     H \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39msparse([[Mt\u001b[39m*\u001b[39mM, Ct\u001b[39m*\u001b[39mM, Bt\u001b[39m*\u001b[39mM], [Mt\u001b[39m*\u001b[39mC, Ct\u001b[39m*\u001b[39mC, Bt\u001b[39m*\u001b[39mC], \n\u001b[0;32m    123\u001b[0m                 [Mt\u001b[39m*\u001b[39mB, Ct\u001b[39m*\u001b[39mB, Bt\u001b[39m*\u001b[39mB\u001b[39m+\u001b[39mgamma\u001b[39m*\u001b[39mcv\u001b[39m.\u001b[39mspmatrix(\u001b[39m1.0\u001b[39m, \u001b[39mrange\u001b[39m(nB), \u001b[39mrange\u001b[39m(nB))]])\n\u001b[0;32m    124\u001b[0m     f \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mmatrix([(cv\u001b[39m.\u001b[39mmatrix(alpha, (\u001b[39m1\u001b[39m,n)) \u001b[39m*\u001b[39m A)\u001b[39m.\u001b[39mT \u001b[39m-\u001b[39m Mt\u001b[39m*\u001b[39my,  \u001b[39m-\u001b[39m(Ct\u001b[39m*\u001b[39my), \u001b[39m-\u001b[39m(Bt\u001b[39m*\u001b[39my)])\n\u001b[1;32m--> 125\u001b[0m     res \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39;49msolvers\u001b[39m.\u001b[39;49mqp(H, f, cv\u001b[39m.\u001b[39;49mspmatrix(\u001b[39m-\u001b[39;49mA\u001b[39m.\u001b[39;49mV, A\u001b[39m.\u001b[39;49mI, A\u001b[39m.\u001b[39;49mJ, (n,\u001b[39mlen\u001b[39;49m(f))),\n\u001b[0;32m    126\u001b[0m                         cv\u001b[39m.\u001b[39;49mmatrix(\u001b[39m0.\u001b[39;49m, (n,\u001b[39m1\u001b[39;49m)), solver\u001b[39m=\u001b[39;49msolver)\n\u001b[0;32m    127\u001b[0m     obj \u001b[39m=\u001b[39m res[\u001b[39m'\u001b[39m\u001b[39mprimal objective\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m.5\u001b[39m \u001b[39m*\u001b[39m (y\u001b[39m.\u001b[39mT \u001b[39m*\u001b[39m y)\n\u001b[0;32m    128\u001b[0m cv\u001b[39m.\u001b[39msolvers\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mclear()\n",
      "File \u001b[1;32mc:\\Users\\zhoux\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\cvxopt\\coneprog.py:4485\u001b[0m, in \u001b[0;36mqp\u001b[1;34m(P, q, G, h, A, b, solver, kktsolver, initvals, **kwargs)\u001b[0m\n\u001b[0;32m   4475\u001b[0m         pinfres, dinfres \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   4477\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m'\u001b[39m: status, \u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m: x, \u001b[39m'\u001b[39m\u001b[39ms\u001b[39m\u001b[39m'\u001b[39m: s, \u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m: y, \u001b[39m'\u001b[39m\u001b[39mz\u001b[39m\u001b[39m'\u001b[39m: z,\n\u001b[0;32m   4478\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mprimal objective\u001b[39m\u001b[39m'\u001b[39m: pcost, \u001b[39m'\u001b[39m\u001b[39mdual objective\u001b[39m\u001b[39m'\u001b[39m: dcost,\n\u001b[0;32m   4479\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mgap\u001b[39m\u001b[39m'\u001b[39m: gap, \u001b[39m'\u001b[39m\u001b[39mrelative gap\u001b[39m\u001b[39m'\u001b[39m: relgap,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4482\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mresidual as primal infeasibility certificate\u001b[39m\u001b[39m'\u001b[39m: pinfres,\n\u001b[0;32m   4483\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mresidual as dual infeasibility certificate\u001b[39m\u001b[39m'\u001b[39m: dinfres}\n\u001b[1;32m-> 4485\u001b[0m \u001b[39mreturn\u001b[39;00m coneqp(P, q, G, h, \u001b[39mNone\u001b[39;49;00m, A,  b, initvals, kktsolver \u001b[39m=\u001b[39;49m kktsolver, options \u001b[39m=\u001b[39;49m options)\n",
      "File \u001b[1;32mc:\\Users\\zhoux\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\cvxopt\\coneprog.py:2256\u001b[0m, in \u001b[0;36mconeqp\u001b[1;34m(P, q, G, h, dims, A, b, initvals, kktsolver, xnewcopy, xdot, xaxpy, xscal, ynewcopy, ydot, yaxpy, yscal, **kwargs)\u001b[0m\n\u001b[0;32m   2244\u001b[0m misc\u001b[39m.\u001b[39mssqr(lmbdasq, lmbda, dims)\n\u001b[0;32m   2247\u001b[0m \u001b[39m# f3(x, y, z) solves\u001b[39;00m\n\u001b[0;32m   2248\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m   2249\u001b[0m \u001b[39m#    [ P   A'  G'    ] [ ux        ]   [ bx ]\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2253\u001b[0m \u001b[39m# On entry, x, y, z containg bx, by, bz.\u001b[39;00m\n\u001b[0;32m   2254\u001b[0m \u001b[39m# On exit, they contain ux, uy, uz.\u001b[39;00m\n\u001b[1;32m-> 2256\u001b[0m \u001b[39mtry\u001b[39;00m: f3 \u001b[39m=\u001b[39m kktsolver(W)\n\u001b[0;32m   2257\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mArithmeticError\u001b[39;00m:\n\u001b[0;32m   2258\u001b[0m     \u001b[39mif\u001b[39;00m iters \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\zhoux\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\cvxopt\\coneprog.py:1981\u001b[0m, in \u001b[0;36mconeqp.<locals>.kktsolver\u001b[1;34m(W)\u001b[0m\n\u001b[0;32m   1980\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mkktsolver\u001b[39m(W):\n\u001b[1;32m-> 1981\u001b[0m     \u001b[39mreturn\u001b[39;00m factor(W, P)\n",
      "File \u001b[1;32mc:\\Users\\zhoux\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\cvxopt\\misc.py:1464\u001b[0m, in \u001b[0;36mkkt_chol2.<locals>.factor\u001b[1;34m(W, H, Df)\u001b[0m\n\u001b[0;32m   1461\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1462\u001b[0m         cholmod\u001b[39m.\u001b[39mnumeric(F[\u001b[39m'\u001b[39m\u001b[39mS\u001b[39m\u001b[39m'\u001b[39m], F[\u001b[39m'\u001b[39m\u001b[39mSf\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m-> 1464\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39;49m(F[\u001b[39m'\u001b[39;49m\u001b[39mS\u001b[39;49m\u001b[39m'\u001b[39;49m]) \u001b[39mis\u001b[39;00m matrix: \n\u001b[0;32m   1465\u001b[0m     \u001b[39m# Asct := L^{-1}*A'.  Factor K = Asct'*Asct.\u001b[39;00m\n\u001b[0;32m   1466\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(A) \u001b[39mis\u001b[39;00m matrix: \n\u001b[0;32m   1467\u001b[0m         Asct \u001b[39m=\u001b[39m A\u001b[39m.\u001b[39mT\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# FEATURE EXTRACTION - EDA\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "importlib.reload(preprocessing)\n",
    "\n",
    "import samplerate\n",
    "\n",
    "convert_sr = False\n",
    "studies = {\n",
    "    1: dr.Study1,\n",
    "    3: dr.Study3, \n",
    "    4: dr.Study4, \n",
    "    5: dr.Study5\n",
    "}\n",
    "signal = dr.Signals.EDA\n",
    "fs = 250.0\n",
    "\n",
    "for study_num in studies.keys():\n",
    "    print(f\"STUDY: {study_num}\")\n",
    "    phases = studies[study_num].ALL\n",
    "    subjects = dr.get_subjects(study_num)\n",
    "    for phase in phases:\n",
    "        print(f\"PHASE: {phase}\")\n",
    "        metrics_dict = {\n",
    "            \"mean_SCL\": [],\n",
    "            \"SCR_rate\": [],\n",
    "        }\n",
    "        for subject in subjects:\n",
    "            print(f\"SUBJECT: {subject}\")\n",
    "            try:\n",
    "                data = dr.get_data_for_subject(study_num, subject, phase, signal).to_numpy()\n",
    "                data = samplerate.resample(data, ratio=250.0/1000.0)\n",
    "                # data = data.flatten()\n",
    "                mean_scl = preprocessing.get_mean_SCL(data, fs)\n",
    "                mean_scl = np.insert(mean_scl, 0, subject)\n",
    "                mean_scl = pd.DataFrame(mean_scl).dropna(axis=1)\n",
    "\n",
    "                scr_rate = preprocessing.get_SCR_rate(data, fs)\n",
    "                scr_rate = np.insert(scr_rate, 0, subject)\n",
    "                scr_rate = pd.DataFrame(scr_rate).dropna(axis=1)\n",
    "\n",
    "                metrics_dict[\"mean_SCL\"].append(mean_scl)\n",
    "                metrics_dict[\"SCR_rate\"].append(scr_rate)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        for metric in list(metrics_dict.keys()):\n",
    "            df = pd.concat(metrics_dict[metric], axis=1)\n",
    "            df = df.transpose()\n",
    "            print(df.head())\n",
    "            file = os.path.join(dr.Paths.METRICS, f\"Study{study_num}\", f\"{metric}_{phase}.csv\")\n",
    "            with open(file, \"w+\") as f:\n",
    "                df.to_csv(f)\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aecf4e853c2a06e9a3d98203b0bfcb89edde136ff484aed399b3da44301ece48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
