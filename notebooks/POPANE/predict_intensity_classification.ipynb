{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we classify each phase as relatively low or high affect for each subject? ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zhoux\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# IMPORTING MODULES\n",
    "import glob\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "cvx_path = os.path.abspath(os.path.join('..', '..', 'cvxEDA', 'src'))\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy.signal as ss\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..', '..', 'src'))\n",
    "sys.path.append(module_path)\n",
    "\n",
    "import tools.data_reader_popane as dr\n",
    "import tools.display_tools as dt\n",
    "import tools.preprocessing as preprocessing\n",
    "import train\n",
    "\n",
    "from scipy.fft import fft, fftfreq, fftshift\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import cvxopt.solvers\n",
    "cvxopt.solvers.options['show_progress'] = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", \n",
    "    category=RuntimeWarning\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(train)\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "importlib.reload(preprocessing)\n",
    "\n",
    "\n",
    "metrics = [\n",
    "    train.Metrics.BPM, \n",
    "    train.Metrics.RMSSD, \n",
    "    train.Metrics.HF_RR, \n",
    "    train.Metrics.LF_RR, \n",
    "    train.Metrics.IBI, \n",
    "    train.Metrics.SDNN, \n",
    "    train.Metrics.MEAN_SCL, \n",
    "    train.Metrics.SCR_RATE\n",
    "]\n",
    "\n",
    "models = {\n",
    "    \"SVM\": SVC(C=10, gamma=1),  # C=10, gamma=1\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=7),\n",
    "    \"DT\": DecisionTreeClassifier(),\n",
    "    \"LogReg\": LogisticRegression(max_iter=1000),\n",
    "    \"Bayes\": GaussianNB(),\n",
    "    \"XGB\": XGBClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In a future version of pandas all arguments of DataFrame.any and Series.any will be keyword-only.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     subject       bpm     rmssd     hf_rr     lf_rr       ibi      sdnn  \\\n",
      "0        1.0  0.174082  0.064601  0.051278  0.051277  0.583253  0.179868   \n",
      "1        2.0  0.174234  0.111392  0.032959  0.033053  0.582878  0.248430   \n",
      "2        4.0  0.188964  0.115288  0.001913  0.001904  0.558699  0.297430   \n",
      "3        5.0  0.247023  0.053615  0.060713  0.060841  0.473109  0.099060   \n",
      "4        6.0  0.180540  0.040365  0.004760  0.004775  0.573500  0.121139   \n",
      "..       ...       ...       ...       ...       ...       ...       ...   \n",
      "368    122.0  0.208688  0.064977  0.000029  0.000029  0.530853  0.207775   \n",
      "369    125.0  0.219133  0.058071  0.060923  0.060943  0.517160  0.181523   \n",
      "370    132.0  0.240461  0.044381  0.004346  0.004358  0.482771  0.124340   \n",
      "371    139.0  0.316016  0.028821  0.000703  0.000704  0.389253  0.057646   \n",
      "372    140.0  0.117004  0.080071  0.005186  0.005246  0.692011  0.187638   \n",
      "\n",
      "     mean_SCL  SCR_rate  \n",
      "0    0.004679  0.094915  \n",
      "1    0.026238  0.233898  \n",
      "2    0.044695  0.222034  \n",
      "3    0.018550  0.306780  \n",
      "4    0.002089  0.144068  \n",
      "..        ...       ...  \n",
      "368  0.073310  0.195763  \n",
      "369  0.006121  0.100847  \n",
      "370  0.000000  0.023729  \n",
      "371  0.004346  0.225424  \n",
      "372  0.036944  0.329237  \n",
      "\n",
      "[229 rows x 9 columns]\n",
      "     subject  label\n",
      "0        1.0      0\n",
      "1        2.0      0\n",
      "2        4.0      0\n",
      "3        5.0      0\n",
      "4        6.0      0\n",
      "..       ...    ...\n",
      "368    122.0      1\n",
      "369    125.0      1\n",
      "370    132.0      1\n",
      "371    139.0      1\n",
      "372    140.0      1\n",
      "\n",
      "[229 rows x 2 columns]\n",
      "0    138\n",
      "1     91\n",
      "Name: label, dtype: int64\n",
      "\n",
      "SVM accuracy over 10 rounds: 0.31650021187562905\n",
      "\n",
      "KNN accuracy over 10 rounds: 0.495649796069707\n",
      "\n",
      "DT accuracy over 10 rounds: 0.5328190052439219\n",
      "\n",
      "LogReg accuracy over 10 rounds: 0.7201154722178081\n",
      "Model evaluation metrics for LogReg:\n",
      "Precision: 0.15\n",
      "Recall: 0.02222222222222222\n",
      "F1-score: 0.03818181818181818\n",
      "AUC score: 0.48447573561703994\n",
      "\n",
      "Bayes accuracy over 10 rounds: 0.38835425605169765\n",
      "\n",
      "XGB accuracy over 10 rounds: 0.5282877800730971\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# STUDY 1\n",
    "importlib.reload(train)\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "importlib.reload(preprocessing)\n",
    "\n",
    "study = \"Study1\"\n",
    "phases = dr.Study1.ALL\n",
    "label_type = \"affect\"\n",
    "\n",
    "x, y = train.Train_POPANE.get_popane_data(study, metrics, phases, verbose=False, label_type=label_type)\n",
    "inds = pd.isnull(x).any(1).to_numpy().nonzero()[0]\n",
    "x = x.drop(inds, axis=0)\n",
    "x = x.drop([\"phaseId\"], axis=1)\n",
    "y = y.drop(inds, axis=0)\n",
    "\n",
    "print(y[\"label\"].value_counts())\n",
    "print(\"\")\n",
    "\n",
    "# 0-1 scaling\n",
    "for i in range(2, len(x.columns)):\n",
    "    if x.columns[i] in metrics:\n",
    "        data_col = x[x.columns[i]]\n",
    "        data_col = (data_col - data_col.min())/(data_col.max() - data_col.min())\n",
    "        x[x.columns[i]] = data_col\n",
    "\n",
    "acc_results = {\n",
    "    \"SVM\": [], \"KNN\": [],\n",
    "    \"DT\": [],\n",
    "    \"LogReg\": [],\n",
    "    \"Bayes\": [],\n",
    "    \"XGB\": []\n",
    "}\n",
    "reports = {\n",
    "    \"SVM\": [], \"KNN\": [],\n",
    "    \"DT\": [],\n",
    "    \"LogReg\": [],\n",
    "    \"Bayes\": [],\n",
    "    \"XGB\": [],\n",
    "}\n",
    "num_iters = 10\n",
    "for _ in range(num_iters):\n",
    "    out = train.train_predict(models, x, y, by_subject=False, save_metrics=True, get_shap_values=False)\n",
    "    for model_name in acc_results:\n",
    "        acc_results[model_name].append(out[model_name][0])\n",
    "        reports[model_name].append(out[model_name][1])\n",
    "\n",
    "for model_name in acc_results.keys():\n",
    "    acc = np.mean(acc_results[model_name])\n",
    "    print(f\"{model_name} accuracy over {num_iters} rounds: {acc}\")\n",
    "    if acc > 0.65:\n",
    "        print(f\"Model evaluation metrics for {model_name}:\")\n",
    "        p = np.mean([report[\"precision\"] for report in reports[model_name]])\n",
    "        r = np.mean([report[\"recall\"] for report in reports[model_name]])\n",
    "        f1 = np.mean([report[\"f1\"] for report in reports[model_name]])\n",
    "        auc = np.mean([report[\"auc\"] for report in reports[model_name]])\n",
    "        report = reports[model_name]\n",
    "        print(f\"Precision: {p}\\nRecall: {r}\\nF1-score: {f1}\\nAUC score: {auc}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDY 5: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In a future version of pandas all arguments of DataFrame.any and Series.any will be keyword-only.\n",
      "In a future version of pandas all arguments of DataFrame.any and Series.any will be keyword-only.\n",
      "In a future version of pandas all arguments of DataFrame.any and Series.any will be keyword-only.\n",
      "In a future version of pandas all arguments of DataFrame.any and Series.any will be keyword-only.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    977\n",
      "0    419\n",
      "Name: label, dtype: int64\n",
      "\n",
      "SVM accuracy over 10 rounds: 0.593109988008194\n",
      "\n",
      "KNN accuracy over 10 rounds: 0.6344322162990433\n",
      "\n",
      "DT accuracy over 10 rounds: 0.5918014412948472\n",
      "\n",
      "LogReg accuracy over 10 rounds: 0.7042812504681562\n",
      "Model evaluation metrics for LogReg:\n",
      "Precision: 0.7047189281578164\n",
      "Recall: 0.9991525423728813\n",
      "F1-score: 0.8262562696952485\n",
      "AUC score: 0.49957627118644066\n",
      "\n",
      "Bayes accuracy over 10 rounds: 0.6837181486025026\n",
      "Model evaluation metrics for Bayes:\n",
      "Precision: 0.7059359170750736\n",
      "Recall: 0.9441821947821607\n",
      "F1-score: 0.8076005833447271\n",
      "AUC score: 0.5025610377748767\n",
      "\n",
      "XGB accuracy over 10 rounds: 0.6674458127456777\n",
      "Model evaluation metrics for XGB:\n",
      "Precision: 0.7267253588887849\n",
      "Recall: 0.847840502664539\n",
      "F1-score: 0.7820624935991197\n",
      "AUC score: 0.542742622304327\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# STUDY 1, 3, 4, 5\n",
    "importlib.reload(train)\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "importlib.reload(preprocessing)\n",
    "\n",
    "label_type = \"affect\"\n",
    "\n",
    "study = \"Study1\"\n",
    "phases = dr.Study1.ALL\n",
    "\n",
    "x1, y1 = train.Train_POPANE.get_popane_data(study, metrics, phases, verbose=False, label_type=label_type)\n",
    "inds = pd.isnull(x1).any(1).to_numpy().nonzero()[0]\n",
    "x1 = x1.drop(inds, axis=0)\n",
    "y1 = y1.drop(inds, axis=0)\n",
    "\n",
    "study = \"Study3\"\n",
    "phases = dr.Study3.ALL\n",
    "\n",
    "x3, y3 = train.Train_POPANE.get_popane_data(study, metrics, phases, verbose=False, label_type=label_type)\n",
    "inds = pd.isnull(x3).any(1).to_numpy().nonzero()[0]\n",
    "x3 = x3.drop(inds, axis=0)\n",
    "y3 = y3.drop(inds, axis=0)\n",
    "\n",
    "study = \"Study4\"\n",
    "phases = dr.Study4.ALL\n",
    "\n",
    "x4, y4 = train.Train_POPANE.get_popane_data(study, metrics, phases, verbose=False, label_type=label_type)\n",
    "inds = pd.isnull(x4).any(1).to_numpy().nonzero()[0]\n",
    "x4 = x4.drop(inds, axis=0)\n",
    "y4 = y4.drop(inds, axis=0)\n",
    "\n",
    "study = \"Study5\"\n",
    "phases = dr.Study5.ALL\n",
    "\n",
    "x5, y5 = train.Train_POPANE.get_popane_data(study, metrics, phases, verbose=False, label_type=label_type)\n",
    "inds = pd.isnull(x5).any(1).to_numpy().nonzero()[0]\n",
    "x5 = x5.drop(inds, axis=0)\n",
    "y5 = y5.drop(inds, axis=0)\n",
    "\n",
    "# print(x1.shape)\n",
    "# print(x3.shape)\n",
    "# print(x4.shape)\n",
    "# print(x5.shape)\n",
    "\n",
    "x = pd.concat([x1, x3, x4, x5])\n",
    "x = x.drop([\"phaseId\"], axis=1)\n",
    "y = pd.concat([y1, y3, y4, y5])\n",
    "\n",
    "# print(x.head())\n",
    "# print(x.shape)\n",
    "\n",
    "print(y[\"label\"].value_counts())\n",
    "print(\"\")\n",
    "\n",
    "# 0-1 scaling\n",
    "for i in range(2, len(x.columns)):\n",
    "    if x.columns[i] in metrics:\n",
    "        data_col = x[x.columns[i]]\n",
    "        data_col = (data_col - data_col.min())/(data_col.max() - data_col.min())\n",
    "        x[x.columns[i]] = data_col\n",
    "\n",
    "acc_results = {\n",
    "    \"SVM\": [], \"KNN\": [],\n",
    "    \"DT\": [],\n",
    "    \"LogReg\": [],\n",
    "    \"Bayes\": [],\n",
    "    \"XGB\": []\n",
    "}\n",
    "reports = {\n",
    "    \"SVM\": [], \"KNN\": [],\n",
    "    \"DT\": [],\n",
    "    \"LogReg\": [],\n",
    "    \"Bayes\": [],\n",
    "    \"XGB\": [],\n",
    "}\n",
    "num_iters = 10\n",
    "for _ in range(num_iters):\n",
    "    out = train.train_predict(models, x, y, by_subject=False, save_metrics=True, get_shap_values=False)\n",
    "    for model_name in acc_results:\n",
    "        acc_results[model_name].append(out[model_name][0])\n",
    "        reports[model_name].append(out[model_name][1])\n",
    "\n",
    "for model_name in acc_results.keys():\n",
    "    acc = np.mean(acc_results[model_name])\n",
    "    print(f\"{model_name} accuracy over {num_iters} rounds: {acc}\")\n",
    "    if acc > 0.65:\n",
    "        print(f\"Model evaluation metrics for {model_name}:\")\n",
    "        p = np.mean([report[\"precision\"] for report in reports[model_name]])\n",
    "        r = np.mean([report[\"recall\"] for report in reports[model_name]])\n",
    "        f1 = np.mean([report[\"f1\"] for report in reports[model_name]])\n",
    "        auc = np.mean([report[\"auc\"] for report in reports[model_name]])\n",
    "        report = reports[model_name]\n",
    "        print(f\"Precision: {p}\\nRecall: {r}\\nF1-score: {f1}\\nAUC score: {auc}\")\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aecf4e853c2a06e9a3d98203b0bfcb89edde136ff484aed399b3da44301ece48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
