{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zhoux\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# IMPORTING MODULES\n",
    "import glob\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "cvx_path = os.path.abspath(os.path.join('..', '..', 'cvxEDA', 'src'))\n",
    "module_path = os.path.abspath(os.path.join('..', '..', 'src'))\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy.signal as ss\n",
    "import shap\n",
    "import sys\n",
    "sys.path.append(module_path)\n",
    "\n",
    "import tools.data_reader_apd as dr_a\n",
    "import tools.data_reader_ascertain as dr_asc\n",
    "import tools.display_tools as dt\n",
    "import tools.preprocessing as preprocessing\n",
    "import train\n",
    "\n",
    "from scipy.fft import fft, fftfreq, fftshift\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold\n",
    "from sklearn.preprocessing import normalize\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import cvxopt.solvers\n",
    "cvxopt.solvers.options['show_progress'] = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", \n",
    "    category=RuntimeWarning\n",
    ")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    train.Metrics.BPM, \n",
    "    train.Metrics.RMSSD, \n",
    "    train.Metrics.HF_RR, \n",
    "    train.Metrics.LF_RR, \n",
    "    # train.Metrics.IBI, \n",
    "    train.Metrics.SDNN, \n",
    "    train.Metrics.MEAN_SCL, \n",
    "    train.Metrics.SCR_RATE\n",
    "]\n",
    "\n",
    "model_phases_apd = [\n",
    "    \"Baseline_Rest\", \n",
    "    \"BugBox_Relax\", \"BugBox_Anticipate\", \"BugBox_Exposure\", \"BugBox_Break\",\n",
    "    \"Speech_Relax\", \"Speech_Anticipate\", \"Speech_Exposure\", \"Speech_Break\"\n",
    "]\n",
    "\n",
    "# anxiety_label_type = \"Anxiety\"\n",
    "anxiety_label_type = None\n",
    "asc_label_type = dr_asc.SelfReports.AROUSAL\n",
    "\n",
    "models = {\n",
    "    # \"SVM\": SVC(C=10, gamma=1),  # C=10, gamma=1\n",
    "    # \"KNN\": KNeighborsClassifier(n_neighbors=7),\n",
    "    # \"DT\": DecisionTreeClassifier(),\n",
    "    \"LogReg\": LogisticRegression(max_iter=1000),\n",
    "    # \"Bayes\": GaussianNB(),\n",
    "    \"RF\": RandomForestClassifier(),\n",
    "    \"XGB\": XGBClassifier(use_label_encoder=False, objective=\"binary:logistic\", eval_metric=\"logloss\")\n",
    "}\n",
    "\n",
    "threshold = \"fixed\"\n",
    "asc_threshold = \"fixed\"\n",
    "test_size = 1.0\n",
    "\n",
    "temp_a, _ = train.Train_APD.get_apd_data_ranking([train.Metrics.BPM], phases=dr_a.Phases.PHASES_LIST, normalize=False)\n",
    "idx = temp_a[temp_a[\"bpm\"] > 200].index \n",
    "invalid_apd_subjects = set(temp_a[\"subject\"].iloc[idx].tolist())\n",
    "idx = temp_a[temp_a[\"bpm\"] < 35].index \n",
    "invalid_apd_subjects.update(set(temp_a[\"subject\"].iloc[idx].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APD PHASES ['Baseline_Rest', 'BugBox_Relax', 'BugBox_Anticipate', 'BugBox_Exposure', 'BugBox_Break', 'Speech_Relax', 'Speech_Anticipate', 'Speech_Exposure', 'Speech_Break'] --------------------------------------------------\n",
      "Ratio of positive to negative labels (0.2857142857142857) is under 0.333, oversampling positive class.\n",
      "Ratio of negative to positive labels (0.1721419185282523) is under 0.333, oversampling negative class.\n",
      "y_train:\n",
      "0    315\n",
      "1    104\n",
      "Name: label, dtype: int64\n",
      "y_test:\n",
      "1    1522\n",
      "0     506\n",
      "Name: label, dtype: int64\n",
      "Model LogReg, Predictions: [0 1], [2005   23]\n",
      "Model RF, Predictions: [0 1], [1694  334]\n",
      "Model XGB, Predictions: [0 1], [ 899 1129]\n",
      "\n",
      "[('lf_hf_ratio', 1.6351400257246573), ('lf_rr', 1.338212101892737), ('mean_SCL', 1.0611097559455704), ('hf_rr', 0.9352656497568884), ('bpm', 0.34182214667659633), ('sdnn', 0.2913207588749317), ('rmssd', -0.0038000661736971495), ('SCR_rate', -0.28231650229601496)]\n",
      "\n",
      "\n",
      "[('mean_SCL', 0.1547583447847234), ('bpm', 0.13669843804811868), ('hf_rr', 0.13316233441789677), ('lf_hf_ratio', 0.13051938544510225), ('SCR_rate', 0.12318962980803844), ('lf_rr', 0.11565799638113931), ('sdnn', 0.10450319369169729), ('rmssd', 0.10151067742328396)]\n",
      "\n",
      "\n",
      "[('mean_SCL', 0.14574288), ('lf_hf_ratio', 0.14076988), ('rmssd', 0.1335452), ('bpm', 0.1295997), ('SCR_rate', 0.11972495), ('hf_rr', 0.11947071), ('lf_rr', 0.10789114), ('sdnn', 0.1032555)]\n",
      "\n",
      "LogReg accuracy over 1 rounds: 0.2578895463510848\n",
      "RF accuracy over 1 rounds: 0.32938856015779094\n",
      "XGB accuracy over 1 rounds: 0.5359960552268245\n",
      "Model evaluation metrics for XGB:\n",
      "\tPrecision: 0.7573073516386183\n",
      "\tRecall: 0.561760840998686\n",
      "\tF1-score: 0.6450396076952093\n",
      "\tAUC score: 0.5101294323570504\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAIN ON APD AND TEST ON ASCERTAIN\n",
    "importlib.reload(train)\n",
    "importlib.reload(dr_a)\n",
    "importlib.reload(dr_asc)\n",
    "importlib.reload(dt)\n",
    "\n",
    "\n",
    "print(f\"APD PHASES {model_phases_apd} \" + \"-\"*50)\n",
    "x_a, y_a = train.Train_APD.get_apd_data_ranking(metrics, model_phases_apd, verbose=False, anxiety_label_type=anxiety_label_type, threshold=threshold, normalize=True)\n",
    "x_b, y_b = train.Train_ASCERTAIN.get_ascertain_data(metrics, verbose=False, label_type=asc_label_type, threshold=asc_threshold, normalize=True)\n",
    "# drop subjects with noisy data\n",
    "x_a = x_a[~x_a[\"subject\"].isin(invalid_apd_subjects)]\n",
    "y_a = y_a[~y_a[\"subject\"].isin(invalid_apd_subjects)]\n",
    "inds = pd.isnull(x_b).any(axis=1).to_numpy().nonzero()[0]\n",
    "x_b = x_b.drop(labels=inds, axis=0)\n",
    "y_b = y_b.drop(labels=inds, axis=0)\n",
    "\n",
    "if anxiety_label_type is not None:\n",
    "    x_a = x_a.drop([\"anxietyGroup\"], axis=1)  # drop anxietyGroup column because WESAD doesn't have this feature\n",
    "\n",
    "x_a = x_a.drop([\"phaseId\"], axis=1)\n",
    "x_b = x_b.drop([\"phaseId\"], axis=1)\n",
    "\n",
    "# make sure subjects from different datasets aren't labeled with the same index\n",
    "x_b[\"subject\"] = x_b[\"subject\"] + 500\n",
    "y_b[\"subject\"] = y_b[\"subject\"] + 500\n",
    "\n",
    "acc_results = {\n",
    "    # \"SVM\": [],\n",
    "    \"LogReg\": [],\n",
    "    \"RF\": [],\n",
    "    \"XGB\": []\n",
    "}\n",
    "reports = {\n",
    "    # \"SVM\": [],\n",
    "    \"LogReg\": [],\n",
    "    \"RF\": [],\n",
    "    \"XGB\": []\n",
    "}\n",
    "num_iters = 1\n",
    "get_importance = True\n",
    "for _ in range(num_iters):\n",
    "    out = train.Train_Multi_Dataset.train_across_datasets(models, x_a, y_a, x_b, y_b, by_subject=True, save_metrics=True, test_size=test_size, is_resample=True, get_importance=get_importance, drop_subject=True)\n",
    "    for model_name in acc_results:\n",
    "        acc_results[model_name].append(out[model_name][0])\n",
    "        reports[model_name].append(out[model_name][1])\n",
    "        if get_importance:\n",
    "            try:\n",
    "                print(\"\")\n",
    "                feature_imp = list(zip(metrics + [\"lf_hf_ratio\"], out[model_name][2]))\n",
    "                feature_imp = sorted(feature_imp, key=lambda x: x[1], reverse=True)\n",
    "                print(feature_imp)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                # print(out[model_name][0][2])\n",
    "            print(\"\")\n",
    "\n",
    "for model_name in acc_results.keys():\n",
    "    acc = np.mean(acc_results[model_name])\n",
    "    print(f\"{model_name} accuracy over {num_iters} rounds: {acc}\")\n",
    "    if acc > 0.5:\n",
    "        print(f\"Model evaluation metrics for {model_name}:\")\n",
    "        p = np.mean([report[\"precision\"] for report in reports[model_name]])\n",
    "        r = np.mean([report[\"recall\"] for report in reports[model_name]])\n",
    "        f1 = np.mean([report[\"f1\"] for report in reports[model_name]])\n",
    "        auc = np.mean([report[\"auc\"] for report in reports[model_name]])\n",
    "        report = reports[model_name]\n",
    "        print(f\"\\tPrecision: {p}\\n\\tRecall: {r}\\n\\tF1-score: {f1}\\n\\tAUC score: {auc}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(train)\n",
    "importlib.reload(dr_a)\n",
    "\n",
    "ha, la = train.Train_APD.get_ratings(phases=model_phases_apd, threshold=threshold)\n",
    "ha = ha[~ha[\"subject\"].isin(invalid_apd_subjects)]\n",
    "la = la[~la[\"subject\"].isin(invalid_apd_subjects)]\n",
    "print(ha)\n",
    "print(la)\n",
    "\n",
    "# x, y = train.Train_APD.get_apd_data_ranking(metrics, model_phases_apd, verbose=False, anxiety_label_type=anxiety_label_type, threshold=threshold)\n",
    "# x = x[~x[\"subject\"].isin(invalid_apd_subjects)]\n",
    "# y = y[~y[\"subject\"].isin(invalid_apd_subjects)]\n",
    "# for i in range(y.shape[0] // 52):\n",
    "#     print(y.iloc[i*52:i*52+52, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of negative to positive labels (0.1721419185282523) is under 0.333, oversampling negative class.\n",
      "Ratio of positive to negative labels (0.2857142857142857) is under 0.333, oversampling positive class.\n",
      "y_train:\n",
      "1    1522\n",
      "0     506\n",
      "Name: label, dtype: int64\n",
      "y_test:\n",
      "0    315\n",
      "1    104\n",
      "Name: label, dtype: int64\n",
      "Model LogReg, Predictions: [0 1], [ 83 336]\n",
      "Model RF, Predictions: [0 1], [ 20 399]\n",
      "Model XGB, Predictions: [0 1], [  8 411]\n",
      "\n",
      "[('SCR_rate', 0.5423907062841241), ('lf_rr', 0.43382203941908937), ('mean_SCL', 0.36614201442400574), ('hf_rr', -0.1539433025794157), ('bpm', -0.21198984293222534), ('lf_hf_ratio', -1.0168464999084323), ('sdnn', -1.3623548991903223), ('rmssd', -1.6599077673332767)]\n",
      "\n",
      "\n",
      "[('rmssd', 0.1448219194559239), ('sdnn', 0.1438026484750218), ('mean_SCL', 0.14187179663102764), ('bpm', 0.13290754484552633), ('lf_hf_ratio', 0.12540383863473895), ('lf_rr', 0.10953640778676842), ('hf_rr', 0.10798570535006517), ('SCR_rate', 0.09367013882092783)]\n",
      "\n",
      "\n",
      "[('sdnn', 0.15095654), ('SCR_rate', 0.13005678), ('mean_SCL', 0.12866814), ('lf_hf_ratio', 0.12769717), ('bpm', 0.12340485), ('rmssd', 0.1221959), ('lf_rr', 0.117525086), ('hf_rr', 0.09949553)]\n",
      "\n",
      "LogReg accuracy over 1 rounds: 0.3412887828162291\n",
      "\tReport:\n",
      "\tPrecision: 0.24404761904761904\n",
      "\tRecall: 0.7884615384615384\n",
      "\tF1-score: 0.37272727272727274\n",
      "\tAUC score: 0.491056166056166\n",
      "RF accuracy over 1 rounds: 0.28162291169451076\n",
      "\tReport:\n",
      "\tPrecision: 0.2531328320802005\n",
      "\tRecall: 0.9711538461538461\n",
      "\tF1-score: 0.4015904572564612\n",
      "\tAUC score: 0.51256105006105\n",
      "XGB accuracy over 1 rounds: 0.2577565632458234\n",
      "\tReport:\n",
      "\tPrecision: 0.24817518248175183\n",
      "\tRecall: 0.9807692307692307\n",
      "\tF1-score: 0.39611650485436894\n",
      "\tAUC score: 0.4999084249084249\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAIN ON ASCERTAIN AND TEST ON APD -- ALL\n",
    "importlib.reload(train)\n",
    "importlib.reload(dr_a)\n",
    "importlib.reload(dr_asc)\n",
    "importlib.reload(dt)\n",
    "\n",
    "\n",
    "x_a, y_a = train.Train_ASCERTAIN.get_ascertain_data(metrics, verbose=False, label_type=asc_label_type, threshold=asc_threshold, normalize=True)\n",
    "# x_b, y_b = train.Train_APD.get_apd_data_ranking(metrics, phases_apd, verbose=False, anxiety_label_type=anxiety_label_type, threshold=threshold, normalize=True)\n",
    "x_b, y_b = train.Train_APD.get_apd_data_ranking(metrics, model_phases_apd, verbose=False, anxiety_label_type=anxiety_label_type, threshold=threshold, normalize=True)\n",
    "# drop subjects with noisy data\n",
    "x_b = x_b[~x_b[\"subject\"].isin(invalid_apd_subjects)].reset_index(drop=True)\n",
    "y_b = y_b[~y_b[\"subject\"].isin(invalid_apd_subjects)].reset_index(drop=True)\n",
    "inds = pd.isnull(x_a).any(axis=1).to_numpy().nonzero()[0]\n",
    "x_a = x_a.drop(labels=inds, axis=0).reset_index(drop=True)\n",
    "y_a = y_a.drop(labels=inds, axis=0).reset_index(drop=True)\n",
    "\n",
    "if anxiety_label_type is not None:\n",
    "    x_a = x_a.drop([\"anxietyGroup\"], axis=1)  # drop anxietyGroup column because WESAD doesn't have this feature\n",
    "\n",
    "x_a = x_a.drop([\"phaseId\"], axis=1)\n",
    "x_b = x_b.drop([\"phaseId\"], axis=1)\n",
    "\n",
    "# make sure subjects from different datasets aren't labeled with the same index\n",
    "x_b[\"subject\"] = x_b[\"subject\"] + 500\n",
    "y_b[\"subject\"] = y_b[\"subject\"] + 500\n",
    "\n",
    "acc_results = {\n",
    "    # \"SVM\": [],\n",
    "    \"LogReg\": [],\n",
    "    \"RF\": [],\n",
    "    \"XGB\": []\n",
    "}\n",
    "reports = {\n",
    "    # \"SVM\": [],\n",
    "    \"LogReg\": [],\n",
    "    \"RF\": [],\n",
    "    \"XGB\": []\n",
    "}\n",
    "num_iters = 1\n",
    "get_importance = True\n",
    "for _ in range(num_iters):\n",
    "    out = train.Train_Multi_Dataset.train_across_datasets(models, x_a, y_a, x_b, y_b, by_subject=True, save_metrics=True, test_size=test_size, is_resample=True, get_importance=get_importance, drop_subject=True)\n",
    "    for model_name in acc_results:\n",
    "        acc_results[model_name].append(out[model_name][0])\n",
    "        reports[model_name].append(out[model_name][1])\n",
    "        if get_importance:\n",
    "            try:\n",
    "                print(\"\")\n",
    "                feature_imp = list(zip(metrics + [\"lf_hf_ratio\"], out[model_name][2]))\n",
    "                feature_imp = sorted(feature_imp, key=lambda x: x[1], reverse=True)\n",
    "                print(feature_imp)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                # print(out[model_name][0][2])\n",
    "            print(\"\")\n",
    "\n",
    "for model_name in acc_results.keys():\n",
    "    acc = np.mean(acc_results[model_name])\n",
    "    print(f\"{model_name} accuracy over {num_iters} rounds: {acc}\")\n",
    "    if acc > 0.0:\n",
    "        p = np.mean([report[\"precision\"] for report in reports[model_name]])\n",
    "        r = np.mean([report[\"recall\"] for report in reports[model_name]])\n",
    "        f1 = np.mean([report[\"f1\"] for report in reports[model_name]])\n",
    "        auc = np.mean([report[\"auc\"] for report in reports[model_name]])\n",
    "        report = reports[model_name]\n",
    "        print(f\"\\tReport:\\n\\tPrecision: {p}\\n\\tRecall: {r}\\n\\tF1-score: {f1}\\n\\tAUC score: {auc}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APD PHASES Baseline_Rest --------------------------------------------------\n",
      "Ratio of negative to positive labels (0.1721419185282523) is under 0.333, oversampling negative class.\n",
      "Ratio of positive to negative labels (0.125) is under 0.333, oversampling positive class.\n",
      "y_train:\n",
      "1    1522\n",
      "0     506\n",
      "Name: label, dtype: int64\n",
      "y_test:\n",
      "0    40\n",
      "1    13\n",
      "Name: label, dtype: int64\n",
      "Model LogReg, Predictions: [0 1], [18 35]\n",
      "Model RF, Predictions: [0 1], [ 5 48]\n",
      "Model XGB, Predictions: [0 1], [ 8 45]\n",
      "\n",
      "[('rmssd', 0.14361238), ('sdnn', 0.13509855), ('lf_rr', 0.13224714), ('mean_SCL', 0.13148601), ('lf_hf_ratio', 0.12908824), ('bpm', 0.12131147), ('SCR_rate', 0.10485376), ('hf_rr', 0.10230247)]\n",
      "\n",
      "LogReg accuracy over 1 rounds: 0.20754716981132076\n",
      "\tReport:\n",
      "\tPrecision: 0.08571428571428572\n",
      "\tRecall: 0.23076923076923078\n",
      "\tF1-score: 0.12500000000000003\n",
      "\tAUC score: 0.21538461538461537\n",
      "RF accuracy over 1 rounds: 0.22641509433962265\n",
      "\tReport:\n",
      "\tPrecision: 0.20833333333333334\n",
      "\tRecall: 0.7692307692307693\n",
      "\tF1-score: 0.32786885245901637\n",
      "\tAUC score: 0.4096153846153846\n",
      "XGB accuracy over 1 rounds: 0.24528301886792453\n",
      "\tReport:\n",
      "\tPrecision: 0.2\n",
      "\tRecall: 0.6923076923076923\n",
      "\tF1-score: 0.31034482758620696\n",
      "\tAUC score: 0.39615384615384613\n",
      "\n",
      "\n",
      "APD PHASES BugBox_Relax --------------------------------------------------\n",
      "Ratio of negative to positive labels (0.1721419185282523) is under 0.333, oversampling negative class.\n",
      "Ratio of positive to negative labels (0.022727272727272728) is under 0.333, oversampling positive class.\n",
      "y_train:\n",
      "1    1522\n",
      "0     506\n",
      "Name: label, dtype: int64\n",
      "y_test:\n",
      "0    44\n",
      "1    14\n",
      "Name: label, dtype: int64\n",
      "Model LogReg, Predictions: [0 1], [11 47]\n",
      "Model RF, Predictions: [0 1], [ 1 57]\n",
      "Model XGB, Predictions: [0 1], [ 5 53]\n",
      "\n",
      "[('sdnn', 0.15441266), ('mean_SCL', 0.14964221), ('hf_rr', 0.13490641), ('bpm', 0.12113386), ('rmssd', 0.11979633), ('lf_hf_ratio', 0.11661804), ('lf_rr', 0.10338507), ('SCR_rate', 0.100105435)]\n",
      "\n",
      "LogReg accuracy over 1 rounds: 0.43103448275862066\n",
      "\tReport:\n",
      "\tPrecision: 0.2978723404255319\n",
      "\tRecall: 1.0\n",
      "\tF1-score: 0.45901639344262296\n",
      "\tAUC score: 0.625\n",
      "RF accuracy over 1 rounds: 0.25862068965517243\n",
      "\tReport:\n",
      "\tPrecision: 0.24561403508771928\n",
      "\tRecall: 1.0\n",
      "\tF1-score: 0.3943661971830986\n",
      "\tAUC score: 0.5113636363636364\n",
      "XGB accuracy over 1 rounds: 0.3275862068965517\n",
      "\tReport:\n",
      "\tPrecision: 0.2641509433962264\n",
      "\tRecall: 1.0\n",
      "\tF1-score: 0.41791044776119407\n",
      "\tAUC score: 0.5568181818181819\n",
      "\n",
      "\n",
      "APD PHASES BugBox_Anticipate --------------------------------------------------\n",
      "Ratio of negative to positive labels (0.1721419185282523) is under 0.333, oversampling negative class.\n",
      "y_train:\n",
      "1    1522\n",
      "0     506\n",
      "Name: label, dtype: int64\n",
      "y_test:\n",
      "0    31\n",
      "1    14\n",
      "Name: label, dtype: int64\n",
      "Model LogReg, Predictions: [0 1], [ 7 38]\n",
      "Model RF, Predictions: [0 1], [ 1 44]\n",
      "Model XGB, Predictions: [0 1], [ 5 40]\n",
      "\n",
      "[('rmssd', 0.14359531), ('sdnn', 0.13839898), ('mean_SCL', 0.13307999), ('lf_hf_ratio', 0.12789996), ('lf_rr', 0.12703574), ('hf_rr', 0.11804701), ('bpm', 0.10709452), ('SCR_rate', 0.10484848)]\n",
      "\n",
      "LogReg accuracy over 1 rounds: 0.37777777777777777\n",
      "\tReport:\n",
      "\tPrecision: 0.3157894736842105\n",
      "\tRecall: 0.8571428571428571\n",
      "\tF1-score: 0.46153846153846156\n",
      "\tAUC score: 0.5092165898617511\n",
      "RF accuracy over 1 rounds: 0.3333333333333333\n",
      "\tReport:\n",
      "\tPrecision: 0.3181818181818182\n",
      "\tRecall: 1.0\n",
      "\tF1-score: 0.4827586206896552\n",
      "\tAUC score: 0.5161290322580645\n",
      "XGB accuracy over 1 rounds: 0.4222222222222222\n",
      "\tReport:\n",
      "\tPrecision: 0.35\n",
      "\tRecall: 1.0\n",
      "\tF1-score: 0.5185185185185185\n",
      "\tAUC score: 0.5806451612903225\n",
      "\n",
      "\n",
      "APD PHASES BugBox_Exposure --------------------------------------------------\n",
      "Ratio of negative to positive labels (0.1721419185282523) is under 0.333, oversampling negative class.\n",
      "y_train:\n",
      "1    1522\n",
      "0     506\n",
      "Name: label, dtype: int64\n",
      "y_test:\n",
      "1    24\n",
      "0    21\n",
      "Name: label, dtype: int64\n",
      "Model LogReg, Predictions: [0 1], [14 31]\n",
      "Model RF, Predictions: [1], [45]\n",
      "Model XGB, Predictions: [0 1], [ 3 42]\n",
      "\n",
      "[('sdnn', 0.14816026), ('lf_rr', 0.13043228), ('bpm', 0.13022885), ('mean_SCL', 0.1301755), ('rmssd', 0.123691864), ('lf_hf_ratio', 0.11488902), ('SCR_rate', 0.11289425), ('hf_rr', 0.109528)]\n",
      "\n",
      "LogReg accuracy over 1 rounds: 0.4888888888888889\n",
      "\tReport:\n",
      "\tPrecision: 0.5161290322580645\n",
      "\tRecall: 0.6666666666666666\n",
      "\tF1-score: 0.5818181818181819\n",
      "\tAUC score: 0.47619047619047616\n",
      "RF accuracy over 1 rounds: 0.5333333333333333\n",
      "\tReport:\n",
      "\tPrecision: 0.5333333333333333\n",
      "\tRecall: 1.0\n",
      "\tF1-score: 0.6956521739130436\n",
      "\tAUC score: 0.5\n",
      "XGB accuracy over 1 rounds: 0.5111111111111111\n",
      "\tReport:\n",
      "\tPrecision: 0.5238095238095238\n",
      "\tRecall: 0.9166666666666666\n",
      "\tF1-score: 0.6666666666666667\n",
      "\tAUC score: 0.48214285714285715\n",
      "\n",
      "\n",
      "APD PHASES BugBox_Break --------------------------------------------------\n",
      "Ratio of negative to positive labels (0.1721419185282523) is under 0.333, oversampling negative class.\n",
      "Ratio of positive to negative labels (0.2857142857142857) is under 0.333, oversampling positive class.\n",
      "y_train:\n",
      "1    1522\n",
      "0     506\n",
      "Name: label, dtype: int64\n",
      "y_test:\n",
      "0    35\n",
      "1    11\n",
      "Name: label, dtype: int64\n",
      "Model LogReg, Predictions: [0 1], [17 29]\n",
      "Model RF, Predictions: [0 1], [ 5 41]\n",
      "Model XGB, Predictions: [0 1], [ 5 41]\n",
      "\n",
      "[('sdnn', 0.146923), ('mean_SCL', 0.13212195), ('hf_rr', 0.13076057), ('rmssd', 0.12997422), ('SCR_rate', 0.12094273), ('lf_rr', 0.11956728), ('lf_hf_ratio', 0.11250944), ('bpm', 0.10720083)]\n",
      "\n",
      "LogReg accuracy over 1 rounds: 0.4782608695652174\n",
      "\tReport:\n",
      "\tPrecision: 0.27586206896551724\n",
      "\tRecall: 0.7272727272727273\n",
      "\tF1-score: 0.4\n",
      "\tAUC score: 0.5636363636363636\n",
      "RF accuracy over 1 rounds: 0.30434782608695654\n",
      "\tReport:\n",
      "\tPrecision: 0.24390243902439024\n",
      "\tRecall: 0.9090909090909091\n",
      "\tF1-score: 0.38461538461538464\n",
      "\tAUC score: 0.5116883116883117\n",
      "XGB accuracy over 1 rounds: 0.30434782608695654\n",
      "\tReport:\n",
      "\tPrecision: 0.24390243902439024\n",
      "\tRecall: 0.9090909090909091\n",
      "\tF1-score: 0.38461538461538464\n",
      "\tAUC score: 0.5116883116883117\n",
      "\n",
      "\n",
      "APD PHASES Speech_Relax --------------------------------------------------\n",
      "Ratio of negative to positive labels (0.1721419185282523) is under 0.333, oversampling negative class.\n",
      "Ratio of positive to negative labels (0.022727272727272728) is under 0.333, oversampling positive class.\n",
      "y_train:\n",
      "1    1522\n",
      "0     506\n",
      "Name: label, dtype: int64\n",
      "y_test:\n",
      "0    44\n",
      "1    14\n",
      "Name: label, dtype: int64\n",
      "Model LogReg, Predictions: [0 1], [20 38]\n",
      "Model RF, Predictions: [0 1], [17 41]\n",
      "Model XGB, Predictions: [0 1], [ 2 56]\n",
      "\n",
      "[('sdnn', 0.14541362), ('mean_SCL', 0.14059041), ('rmssd', 0.1370768), ('hf_rr', 0.1253938), ('bpm', 0.12152927), ('lf_hf_ratio', 0.117900096), ('lf_rr', 0.10776633), ('SCR_rate', 0.104329675)]\n",
      "\n",
      "LogReg accuracy over 1 rounds: 0.10344827586206896\n",
      "\tReport:\n",
      "\tPrecision: 0.0\n",
      "\tRecall: 0.0\n",
      "\tF1-score: 0.0\n",
      "\tAUC score: 0.06818181818181818\n",
      "RF accuracy over 1 rounds: 0.05172413793103448\n",
      "\tReport:\n",
      "\tPrecision: 0.0\n",
      "\tRecall: 0.0\n",
      "\tF1-score: 0.0\n",
      "\tAUC score: 0.034090909090909116\n",
      "XGB accuracy over 1 rounds: 0.27586206896551724\n",
      "\tReport:\n",
      "\tPrecision: 0.25\n",
      "\tRecall: 1.0\n",
      "\tF1-score: 0.4\n",
      "\tAUC score: 0.5227272727272727\n",
      "\n",
      "\n",
      "APD PHASES Speech_Anticipate --------------------------------------------------\n",
      "Ratio of negative to positive labels (0.1721419185282523) is under 0.333, oversampling negative class.\n",
      "y_train:\n",
      "1    1522\n",
      "0     506\n",
      "Name: label, dtype: int64\n",
      "y_test:\n",
      "0    32\n",
      "1    13\n",
      "Name: label, dtype: int64\n",
      "Model LogReg, Predictions: [0 1], [11 34]\n",
      "Model RF, Predictions: [0 1], [ 2 43]\n",
      "Model XGB, Predictions: [0 1], [ 4 41]\n",
      "\n",
      "[('sdnn', 0.13675421), ('lf_rr', 0.13462737), ('rmssd', 0.12914857), ('mean_SCL', 0.12910475), ('SCR_rate', 0.121029384), ('bpm', 0.118246466), ('hf_rr', 0.117762566), ('lf_hf_ratio', 0.11332669)]\n",
      "\n",
      "LogReg accuracy over 1 rounds: 0.4888888888888889\n",
      "\tReport:\n",
      "\tPrecision: 0.35294117647058826\n",
      "\tRecall: 0.9230769230769231\n",
      "\tF1-score: 0.5106382978723405\n",
      "\tAUC score: 0.6177884615384616\n",
      "RF accuracy over 1 rounds: 0.28888888888888886\n",
      "\tReport:\n",
      "\tPrecision: 0.27906976744186046\n",
      "\tRecall: 0.9230769230769231\n",
      "\tF1-score: 0.42857142857142855\n",
      "\tAUC score: 0.47716346153846156\n",
      "XGB accuracy over 1 rounds: 0.3333333333333333\n",
      "\tReport:\n",
      "\tPrecision: 0.2926829268292683\n",
      "\tRecall: 0.9230769230769231\n",
      "\tF1-score: 0.4444444444444444\n",
      "\tAUC score: 0.5084134615384616\n",
      "\n",
      "\n",
      "APD PHASES Speech_Exposure --------------------------------------------------\n",
      "Ratio of negative to positive labels (0.1721419185282523) is under 0.333, oversampling negative class.\n",
      "y_train:\n",
      "1    1522\n",
      "0     506\n",
      "Name: label, dtype: int64\n",
      "y_test:\n",
      "0    27\n",
      "1    18\n",
      "Name: label, dtype: int64\n",
      "Model LogReg, Predictions: [0 1], [11 34]\n",
      "Model RF, Predictions: [0 1], [ 5 40]\n",
      "Model XGB, Predictions: [0 1], [ 1 44]\n",
      "\n",
      "[('rmssd', 0.14046417), ('mean_SCL', 0.13616517), ('sdnn', 0.13229671), ('hf_rr', 0.1283954), ('SCR_rate', 0.12189639), ('lf_rr', 0.11989624), ('lf_hf_ratio', 0.11138994), ('bpm', 0.109495915)]\n",
      "\n",
      "LogReg accuracy over 1 rounds: 0.5111111111111111\n",
      "\tReport:\n",
      "\tPrecision: 0.4411764705882353\n",
      "\tRecall: 0.8333333333333334\n",
      "\tF1-score: 0.576923076923077\n",
      "\tAUC score: 0.5648148148148149\n",
      "RF accuracy over 1 rounds: 0.4666666666666667\n",
      "\tReport:\n",
      "\tPrecision: 0.425\n",
      "\tRecall: 0.9444444444444444\n",
      "\tF1-score: 0.5862068965517241\n",
      "\tAUC score: 0.5462962962962963\n",
      "XGB accuracy over 1 rounds: 0.4222222222222222\n",
      "\tReport:\n",
      "\tPrecision: 0.4090909090909091\n",
      "\tRecall: 1.0\n",
      "\tF1-score: 0.5806451612903226\n",
      "\tAUC score: 0.5185185185185186\n",
      "\n",
      "\n",
      "APD PHASES Speech_Break --------------------------------------------------\n",
      "Ratio of negative to positive labels (0.1721419185282523) is under 0.333, oversampling negative class.\n",
      "Ratio of positive to negative labels (0.0975609756097561) is under 0.333, oversampling positive class.\n",
      "y_train:\n",
      "1    1522\n",
      "0     506\n",
      "Name: label, dtype: int64\n",
      "y_test:\n",
      "0    41\n",
      "1    13\n",
      "Name: label, dtype: int64\n",
      "Model LogReg, Predictions: [0 1], [14 40]\n",
      "Model RF, Predictions: [0 1], [ 1 53]\n",
      "Model XGB, Predictions: [0 1], [ 4 50]\n",
      "\n",
      "[('mean_SCL', 0.14182869), ('sdnn', 0.13722768), ('bpm', 0.13693616), ('hf_rr', 0.122489505), ('rmssd', 0.12022341), ('lf_rr', 0.11587917), ('lf_hf_ratio', 0.11443353), ('SCR_rate', 0.110981844)]\n",
      "\n",
      "LogReg accuracy over 1 rounds: 0.46296296296296297\n",
      "\tReport:\n",
      "\tPrecision: 0.3\n",
      "\tRecall: 0.9230769230769231\n",
      "\tF1-score: 0.4528301886792453\n",
      "\tAUC score: 0.6200750469043153\n",
      "RF accuracy over 1 rounds: 0.25925925925925924\n",
      "\tReport:\n",
      "\tPrecision: 0.24528301886792453\n",
      "\tRecall: 1.0\n",
      "\tF1-score: 0.393939393939394\n",
      "\tAUC score: 0.5121951219512195\n",
      "XGB accuracy over 1 rounds: 0.16666666666666666\n",
      "\tReport:\n",
      "\tPrecision: 0.18\n",
      "\tRecall: 0.6923076923076923\n",
      "\tF1-score: 0.28571428571428575\n",
      "\tAUC score: 0.34615384615384615\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAIN ON ASCERTAIN AND TEST ON APD\n",
    "importlib.reload(train)\n",
    "importlib.reload(dr_a)\n",
    "importlib.reload(dr_asc)\n",
    "importlib.reload(dt)\n",
    "\n",
    "\n",
    "for j, phases_apd in enumerate(model_phases_apd):\n",
    "    print(f\"APD PHASES {phases_apd} \" + \"-\"*50)\n",
    "    phases_apd = [phases_apd]\n",
    "    x_a, y_a = train.Train_ASCERTAIN.get_ascertain_data(metrics, verbose=False, label_type=asc_label_type, threshold=asc_threshold, normalize=True)\n",
    "    x_b, y_b = train.Train_APD.get_apd_data_ranking(metrics, phases_apd, verbose=False, anxiety_label_type=anxiety_label_type, threshold=threshold, normalize=True)\n",
    "    # drop subjects with noisy data\n",
    "    x_b = x_b[~x_b[\"subject\"].isin(invalid_apd_subjects)].reset_index(drop=True)\n",
    "    y_b = y_b[~y_b[\"subject\"].isin(invalid_apd_subjects)].reset_index(drop=True)\n",
    "    inds = pd.isnull(x_a).any(axis=1).to_numpy().nonzero()[0]\n",
    "    x_a = x_a.drop(labels=inds, axis=0).reset_index(drop=True)\n",
    "    y_a = y_a.drop(labels=inds, axis=0).reset_index(drop=True)\n",
    "\n",
    "    if anxiety_label_type is not None:\n",
    "        x_a = x_a.drop([\"anxietyGroup\"], axis=1)  # drop anxietyGroup column because WESAD doesn't have this feature\n",
    "\n",
    "    x_a = x_a.drop([\"phaseId\"], axis=1)\n",
    "    x_b = x_b.drop([\"phaseId\"], axis=1)\n",
    "\n",
    "    # make sure subjects from different datasets aren't labeled with the same index\n",
    "    x_b[\"subject\"] = x_b[\"subject\"] + 500\n",
    "    y_b[\"subject\"] = y_b[\"subject\"] + 500\n",
    "\n",
    "    acc_results = {\n",
    "        # \"SVM\": [],\n",
    "        \"LogReg\": [],\n",
    "        \"RF\": [],\n",
    "        \"XGB\": []\n",
    "    }\n",
    "    reports = {\n",
    "        # \"SVM\": [],\n",
    "        \"LogReg\": [],\n",
    "        \"RF\": [],\n",
    "        \"XGB\": []\n",
    "    }\n",
    "    num_iters = 1\n",
    "    get_importance = True\n",
    "    for _ in range(num_iters):\n",
    "        out = train.Train_Multi_Dataset.train_across_datasets(models, x_a, y_a, x_b, y_b, by_subject=True, save_metrics=True, test_size=test_size, is_resample=True, get_importance=get_importance, drop_subject=True)\n",
    "        for model_name in acc_results:\n",
    "            acc_results[model_name].append(out[model_name][0])\n",
    "            reports[model_name].append(out[model_name][1])\n",
    "        if get_importance:\n",
    "            try:\n",
    "                print(\"\")\n",
    "                feature_imp = list(zip(metrics + [\"lf_hf_ratio\"], out[model_name][2]))\n",
    "                feature_imp = sorted(feature_imp, key=lambda x: x[1], reverse=True)\n",
    "                print(feature_imp)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                # print(out[model_name][0][2])\n",
    "            print(\"\")\n",
    "\n",
    "    for model_name in acc_results.keys():\n",
    "        acc = np.mean(acc_results[model_name])\n",
    "        print(f\"{model_name} accuracy over {num_iters} rounds: {acc}\")\n",
    "        if acc > 0.0:\n",
    "            p = np.mean([report[\"precision\"] for report in reports[model_name]])\n",
    "            r = np.mean([report[\"recall\"] for report in reports[model_name]])\n",
    "            f1 = np.mean([report[\"f1\"] for report in reports[model_name]])\n",
    "            auc = np.mean([report[\"auc\"] for report in reports[model_name]])\n",
    "            report = reports[model_name]\n",
    "            print(f\"\\tReport:\\n\\tPrecision: {p}\\n\\tRecall: {r}\\n\\tF1-score: {f1}\\n\\tAUC score: {auc}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
