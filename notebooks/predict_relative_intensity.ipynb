{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING MODULES\n",
    "import glob\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "cvx_path = os.path.abspath(os.path.join('..', 'cvxEDA', 'src'))\n",
    "module_path = os.path.abspath(os.path.join('..', 'src'))\n",
    "sys.path.append(module_path)\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy.signal as ss\n",
    "import sys\n",
    "\n",
    "import tools.data_reader_apd as dr\n",
    "import tools.display_tools as dt\n",
    "import tools.preprocessing as preprocessing\n",
    "\n",
    "from scipy.fft import fft, fftfreq, fftshift\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import cvxopt.solvers\n",
    "cvxopt.solvers.options['show_progress'] = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", \n",
    "    category=RuntimeWarning\n",
    ")\n",
    "\n",
    "\n",
    "metrics = [\n",
    "    # \"rmssd\", \"hf_rr\", \"lf_rr\", \"ibi\", \n",
    "    \"bpm\", \"rmssd\", \"hf_rr\", \"lf_rr\", \"ibi\", \n",
    "    \"mean_SCL\", \"SCR_rate\"\n",
    "]\n",
    "\n",
    "phases = {\n",
    "    \"Baseline\": [dr.Phases.BASE_REST, dr.Phases.BASE_SPEECH],\n",
    "    \"Bug baseline\": [dr.Phases.BUG_RELAX],\n",
    "    \"Speech baseline\": [dr.Phases.SPEECH_RELAX],\n",
    "    \"Bug all\": [dr.Phases.BUG_RELAX, dr.Phases.BUG_ANTICIPATE, dr.Phases.BUG_EXPOSURE, dr.Phases.BUG_BREAK, dr.Phases.BUG_REFLECT],\n",
    "    \"Speech all\": [dr.Phases.SPEECH_RELAX, dr.Phases.SPEECH_ANTICIPATE, dr.Phases.SPEECH_EXPOSURE, dr.Phases.SPEECH_BREAK, dr.Phases.SPEECH_REFLECT],\n",
    "    \"Bug pre-anxiety\": [dr.Phases.BUG_RELAX, dr.Phases.BUG_ANTICIPATE],\n",
    "    \"Speech pre-anxiety\": [dr.Phases.SPEECH_RELAX, dr.Phases.SPEECH_ANTICIPATE],\n",
    "    \"Bug anxiety\": [dr.Phases.BUG_EXPOSURE],\n",
    "    \"Speech anxiety\": [dr.Phases.SPEECH_EXPOSURE],\n",
    "    \"Bug post-anxiety\": [dr.Phases.BUG_BREAK, dr.Phases.BUG_REFLECT],\n",
    "    \"Speech post-anxiety\": [dr.Phases.SPEECH_BREAK, dr.Phases.SPEECH_REFLECT],\n",
    "}\n",
    "\n",
    "test_phases = [\n",
    "    phases[\"Baseline\"],\n",
    "    phases[\"Bug baseline\"],\n",
    "    phases[\"Speech baseline\"],\n",
    "    phases[\"Bug baseline\"] + phases[\"Speech baseline\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug baseline\"],\n",
    "    phases[\"Baseline\"] + phases[\"Speech baseline\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug baseline\"] + phases[\"Speech baseline\"],\n",
    "\n",
    "    phases[\"Bug all\"],\n",
    "    phases[\"Speech all\"],\n",
    "    phases[\"Bug all\"] + phases[\"Speech all\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug all\"],\n",
    "    phases[\"Baseline\"] + phases[\"Speech all\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug all\"] + phases[\"Speech all\"],\n",
    "\n",
    "    phases[\"Bug pre-anxiety\"],\n",
    "    phases[\"Speech pre-anxiety\"],\n",
    "    phases[\"Bug pre-anxiety\"] + phases[\"Speech pre-anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug pre-anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Speech pre-anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug pre-anxiety\"] + phases[\"Speech pre-anxiety\"],\n",
    "\n",
    "    phases[\"Bug anxiety\"],\n",
    "    phases[\"Speech anxiety\"],\n",
    "    phases[\"Bug pre-anxiety\"] + phases[\"Speech anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Speech anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug anxiety\"] + phases[\"Speech anxiety\"],\n",
    "\n",
    "    phases[\"Bug post-anxiety\"],\n",
    "    phases[\"Speech post-anxiety\"],\n",
    "    phases[\"Bug post-anxiety\"] + phases[\"Speech post-anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug post-anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Speech post-anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug post-anxiety\"] + phases[\"Speech post-anxiety\"],\n",
    "\n",
    "    phases[\"Bug pre-anxiety\"] + phases[\"Bug anxiety\"],\n",
    "    phases[\"Speech pre-anxiety\"] + phases[\"Speech anxiety\"],\n",
    "    phases[\"Bug pre-anxiety\"] + phases[\"Bug anxiety\"] + phases[\"Speech pre-anxiety\"] + phases[\"Speech anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug pre-anxiety\"] + phases[\"Bug anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Speech pre-anxiety\"] + phases[\"Speech anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug pre-anxiety\"] + phases[\"Bug anxiety\"] + phases[\"Speech pre-anxiety\"] + phases[\"Speech anxiety\"],\n",
    "\n",
    "    phases[\"Bug post-anxiety\"] + phases[\"Bug anxiety\"],\n",
    "    phases[\"Speech post-anxiety\"] + phases[\"Speech anxiety\"],\n",
    "    phases[\"Bug post-anxiety\"] + phases[\"Bug anxiety\"] + phases[\"Speech post-anxiety\"] + phases[\"Speech anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug post-anxiety\"] + phases[\"Bug anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Speech post-anxiety\"] + phases[\"Speech anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug post-anxiety\"] + phases[\"Bug anxiety\"] + phases[\"Speech post-anxiety\"] + phases[\"Speech anxiety\"],\n",
    "\n",
    "    phases[\"Bug pre-anxiety\"] + phases[\"Bug post-anxiety\"],\n",
    "    phases[\"Speech pre-anxiety\"] + phases[\"Speech post-anxiety\"],\n",
    "    phases[\"Bug pre-anxiety\"] + phases[\"Bug post-anxiety\"] + phases[\"Speech pre-anxiety\"] + phases[\"Speech post-anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug pre-anxiety\"] + phases[\"Bug post-anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Speech pre-anxiety\"] + phases[\"Speech post-anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug pre-anxiety\"] + phases[\"Bug post-anxiety\"] + phases[\"Speech pre-anxiety\"] + phases[\"Speech post-anxiety\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANKING PHASES BY LOW TO HIGH ANXIETY\n",
    "SUDS_labels = [\n",
    "    \"Participant\",\n",
    "    \"Baseline_SUDS\",\n",
    "    # \"BugBox_Relax_SUDS\", \"BugBox_Preparation_SUDS\", \"BugBox_Exposure_SUDS\", \"BugBox_Break_SUDS\",\n",
    "    \"BugBox_Relax_SUDS\", \"BugBox_Preparation_SUDS\", \"BugBox_Break_SUDS\",\n",
    "    \"Speech_Relax_SUDS\", \"Speech_SUDS\", \"Speech_Exposure_SUDS\", \"Speech_Break_SUDS\"\n",
    "]\n",
    "\n",
    "\n",
    "ha_participant_indices = [\n",
    "    'P4', 'P6', 'P7', 'P8', 'P10', 'P12', 'P15', 'P16', 'P18', 'P22', 'P26', 'P27', 'P29', 'P31', 'P32', 'P33', 'P35', 'P42', 'P45', 'P47', 'P48', 'P49', 'P54', 'P55', 'P66', 'P69'\n",
    "]\n",
    "\n",
    "la_participant_indices = [\n",
    "    'P14', 'P21', 'P23', 'P25', 'P34', 'P39', 'P43', 'P46', 'P51', 'P57', 'P71', 'P72', 'P77', 'P78', 'P79', 'P80', 'P82', 'P83', 'P84', 'P85', 'P87', 'P88', 'P89', 'P91', 'P92', 'P93'\n",
    "]\n",
    "\n",
    "participant_file = os.path.join(dr.Paths.DATA_DIR, \"participants_details.csv\")\n",
    "df = pd.read_csv(participant_file)\n",
    "\n",
    "suds_df = df[SUDS_labels]\n",
    "ha_suds_df = suds_df.loc[suds_df['Participant'].isin(ha_participant_indices)]\n",
    "la_suds_df = suds_df.loc[suds_df['Participant'].isin(la_participant_indices)]\n",
    "\n",
    "ha_ranked = {}\n",
    "la_ranked = {}\n",
    "\n",
    "for i in range(ha_suds_df.shape[0]):\n",
    "    phases_ranked = []\n",
    "    for j in range(1, ha_suds_df.shape[1]):\n",
    "        phases_ranked.append((ha_suds_df.iloc[i, j], ha_suds_df.columns[j]))\n",
    "    ha_ranked[ha_suds_df.iloc[i, 0]] = phases_ranked\n",
    "\n",
    "for i in range(la_suds_df.shape[0]):\n",
    "    phases_ranked = []\n",
    "    for j in range(1, la_suds_df.shape[1]):\n",
    "        phases_ranked.append((la_suds_df.iloc[i, j], la_suds_df.columns[j]))\n",
    "    la_ranked[la_suds_df.iloc[i, 0]] = phases_ranked\n",
    "\n",
    "ha_labels = {}\n",
    "la_labels = {}\n",
    "\n",
    "for s in ha_ranked.keys():\n",
    "    suds = ha_ranked[s]\n",
    "    suds.sort(key=lambda x:x[0])\n",
    "    ordered = [phase[1] for phase in ha_ranked[s]]\n",
    "    ha_labels[int(s[1:])] = [ordered.index(p) for p in SUDS_labels[1:]]\n",
    "\n",
    "for s in la_ranked.keys():\n",
    "    suds = la_ranked[s]\n",
    "    suds.sort(key=lambda x:x[0])\n",
    "    ordered = [phase[1] for phase in la_ranked[s]]\n",
    "    la_labels[int(s[1:])] = [ordered.index(p) for p in SUDS_labels[1:]]\n",
    "\n",
    "# Phase index + 1 corresponds to phase name in SUDS_labels. Value corresponds to ranking from low to high anxiety.\n",
    "ha_rankings = pd.DataFrame(ha_labels.values(), columns=[i for i in range(len(SUDS_labels[1:]))])\n",
    "subjects = pd.DataFrame(ha_labels.keys())\n",
    "ha_rankings.insert(0, \"subject\", subjects)\n",
    "la_rankings = pd.DataFrame(la_labels.values(), columns=[i for i in range(len(SUDS_labels[1:]))])\n",
    "subjects = pd.DataFrame(la_labels.keys())\n",
    "la_rankings.insert(0, \"subject\", subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANKING_PHASES = [\n",
    "    dr.Phases.BASE_REST,\n",
    "    # dr.Phases.BUG_RELAX, dr.Phases.BUG_ANTICIPATE, dr.Phases.BUG_EXPOSURE, dr.Phases.BUG_BREAK,\n",
    "    dr.Phases.BUG_RELAX, dr.Phases.BUG_ANTICIPATE, dr.Phases.BUG_BREAK,\n",
    "    dr.Phases.SPEECH_RELAX, dr.Phases.SPEECH_ANTICIPATE, dr.Phases.SPEECH_EXPOSURE, dr.Phases.SPEECH_BREAK\n",
    "]\n",
    "\n",
    "NUM_SUBJECTS = 52\n",
    "TEST_SIZE = 0.1\n",
    "\n",
    "def get_apd_data_ranking(metrics, phases, verbose=False):\n",
    "    metrics_folder = os.path.join(dr.Paths.DATA_DIR, \"metrics\")\n",
    "\n",
    "    columns = metrics.copy()\n",
    "    columns.insert(0, \"subject\")\n",
    "\n",
    "    data_x = []\n",
    "    data_y = pd.concat([ha_rankings, la_rankings], axis=0).reset_index(drop=True)\n",
    "    # print(data_y.head())\n",
    "\n",
    "    for phase in phases:\n",
    "        if verbose: print(f\"Generating features for phase {phase} \" + \"-\"*30)\n",
    "        phase_id = phases.index(phase)\n",
    "        ha_features = []\n",
    "        la_features = []\n",
    "\n",
    "        for i in range(len(metrics)):\n",
    "            metric = metrics[i]\n",
    "            if verbose: print(f\"Generating features for metric {metric}\")\n",
    "            file = os.path.join(metrics_folder, f\"{metric}_{phase}_ha.csv\")\n",
    "            arr = pd.read_csv(file, index_col=[0]).to_numpy()\n",
    "\n",
    "            if i == 0:  # subject IDs\n",
    "                ids = np.reshape(arr[:, 0], (arr[:, 0].size, 1))\n",
    "                ids = pd.DataFrame(data=ids, columns=[\"subject\"])\n",
    "                ha_features.append(ids)\n",
    "\n",
    "            # arr = arr[1:, 1:]\n",
    "            col_mean = np.nanmean(arr, axis=1)\n",
    "            idx = np.where(np.isnan(arr))\n",
    "            arr[idx] = np.take(col_mean, idx[0])\n",
    "            arr = np.nan_to_num(arr)\n",
    "            arr = np.mean(arr[:, 1:], axis=1)\n",
    "            arr = np.reshape(arr, (arr.size, 1))\n",
    "            arr = pd.DataFrame(data=arr, columns=[f\"{metric}\"])\n",
    "            ha_features.append(arr)\n",
    "\n",
    "            file = os.path.join(metrics_folder, f\"{metric}_{phase}_la.csv\")\n",
    "            arr = pd.read_csv(file, index_col=[0]).to_numpy()\n",
    "\n",
    "            if i == 0:  # subject IDs\n",
    "                ids = np.reshape(arr[:, 0], (arr[:, 0].size, 1))\n",
    "                ids = pd.DataFrame(data=ids, columns=[\"subject\"])\n",
    "                la_features.append(ids)\n",
    "\n",
    "            # arr = arr[1:, 1:]\n",
    "            col_mean = np.nanmean(arr, axis=1)\n",
    "            idx = np.where(np.isnan(arr))\n",
    "            arr[idx] = np.take(col_mean, idx[0])\n",
    "            arr = np.nan_to_num(arr)\n",
    "            arr = np.mean(arr[:, 1:], axis=1)\n",
    "            arr = np.reshape(arr, (arr.size, 1))\n",
    "            arr = pd.DataFrame(data=arr, columns=[f\"{metric}\"])\n",
    "            la_features.append(arr)\n",
    "\n",
    "        ha_features = pd.concat(ha_features, axis=1)\n",
    "        la_features = pd.concat(la_features, axis=1)\n",
    "        x = pd.concat([ha_features, la_features], axis=0)\n",
    "        print(x[\"subject\"].value_counts().iloc[0:8])\n",
    "        phase = pd.DataFrame(data=[phase_id for _ in range(x.shape[0])])\n",
    "        x.insert(1, \"phaseId\", phase)\n",
    "\n",
    "        data_x.append(x)\n",
    "    \n",
    "    data_x = pd.concat(data_x).reset_index(drop=True)\n",
    "    # data_x.sort_values(by=[\"phaseId\", \"subject\"], inplace=True)\n",
    "\n",
    "    # print(data_y)\n",
    "\n",
    "    subjects = data_x.loc[:, \"subject\"]\n",
    "    # print(subjects.shape)\n",
    "    # print(subjects.value_counts())\n",
    "    # print(subjects.unique().shape)\n",
    "    phase_col = data_x.loc[:, \"phaseId\"]\n",
    "    ranking_col = []\n",
    "    for i in range(data_x.shape[0]):\n",
    "        s = subjects.iloc[i]\n",
    "        p = phase_col.iloc[i]\n",
    "        rank = int(data_y.loc[data_y[\"subject\"] == s].loc[:, p])\n",
    "        ranking_col.append(rank)\n",
    "    \n",
    "    data_y = pd.DataFrame({\"subject\": subjects, \"phaseId\": phase_col, \"ranking\": ranking_col})\n",
    "    # data_y = pd.DataFrame({\"ranking\": ranking_col})\n",
    "\n",
    "    # print(data_x.shape)\n",
    "    # print(data_y.shape)\n",
    "    \n",
    "    return data_x, data_y\n",
    "\n",
    "\n",
    "def train_test_split(x, y):\n",
    "    subjects = list(x.loc[:, \"subject\"].unique())\n",
    "    test_subjects = random.sample(subjects, int(NUM_SUBJECTS*TEST_SIZE))\n",
    "    print(f\"test subjects: {test_subjects}\")\n",
    "    x_train = x[~x[\"subject\"].isin(test_subjects)]\n",
    "    y_train = y[~y[\"subject\"].isin(test_subjects)]\n",
    "    x_test = x[x[\"subject\"].isin(test_subjects)]\n",
    "    y_test = y[y[\"subject\"].isin(test_subjects)]\n",
    "\n",
    "    # print(x.shape)\n",
    "    # print(y.shape)\n",
    "    # print(x_train.shape)\n",
    "    # print(y_train.shape)\n",
    "    # print(x_test.shape)\n",
    "    # print(y_test.shape)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def predict(data, labels, model):\n",
    "    test_subjects = list(data.loc[:, \"subject\"].unique())\n",
    "    subject_list = []\n",
    "    phase_ids = []\n",
    "    ranks = []\n",
    "    for s in test_subjects:\n",
    "        df = data.loc[data[\"subject\"] == s]\n",
    "        # print(df.iloc[0:8, 0:3])\n",
    "        pred = model.predict(df)\n",
    "        # print(f\"pred: {pred}\")\n",
    "        phaseId = np.array(df.reset_index()['phaseId'])\n",
    "        pred = np.argsort(pred)  # lowest to highest anxiety\n",
    "        # print(f\"pred indices: {pred}\")\n",
    "        phase_ranking = list(phaseId[pred])\n",
    "        # print(f\"phase ranking: {phase_ranking}\")\n",
    "        phase_ids.extend(phase_ranking)\n",
    "        subject_list.extend([s]*len(pred))\n",
    "        ranks.extend(list(range(len(pred))))\n",
    "    \n",
    "    actual = labels.sort_values(by=[\"subject\"]).loc[:, \"ranking\"]\n",
    "    results = pd.DataFrame({\"subject\": subject_list, \"phaseId\": phase_ids, \"ranking\": ranks, \"actual\": actual})\n",
    "    \n",
    "    return results\n",
    "\n",
    "# print(x.head())\n",
    "# print(y.head())\n",
    "\n",
    "# print(x_train.shape)\n",
    "# print(y_train.shape)\n",
    "# print(x_test.shape)\n",
    "# print(y_test.shape)\n",
    "\n",
    "# print(x_train.head())\n",
    "# print(y_train.head())\n",
    "# print(x_test.head())\n",
    "# print(y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating features for phase Baseline_Rest ------------------------------\n",
      "Generating features for metric bpm\n",
      "Generating features for metric rmssd\n",
      "Generating features for metric hf_rr\n",
      "Generating features for metric lf_rr\n",
      "Generating features for metric ibi\n",
      "Generating features for metric mean_SCL\n",
      "Generating features for metric SCR_rate\n",
      "14.0    1\n",
      "21.0    1\n",
      "15.0    1\n",
      "16.0    1\n",
      "18.0    1\n",
      "22.0    1\n",
      "26.0    1\n",
      "27.0    1\n",
      "Name: subject, dtype: int64\n",
      "Generating features for phase BugBox_Relax ------------------------------\n",
      "Generating features for metric bpm\n",
      "Generating features for metric rmssd\n",
      "Generating features for metric hf_rr\n",
      "Generating features for metric lf_rr\n",
      "Generating features for metric ibi\n",
      "Generating features for metric mean_SCL\n",
      "Generating features for metric SCR_rate\n",
      "14.0    1\n",
      "21.0    1\n",
      "15.0    1\n",
      "16.0    1\n",
      "18.0    1\n",
      "22.0    1\n",
      "26.0    1\n",
      "27.0    1\n",
      "Name: subject, dtype: int64\n",
      "Generating features for phase BugBox_Anticipate ------------------------------\n",
      "Generating features for metric bpm\n",
      "Generating features for metric rmssd\n",
      "Generating features for metric hf_rr\n",
      "Generating features for metric lf_rr\n",
      "Generating features for metric ibi\n",
      "Generating features for metric mean_SCL\n",
      "Generating features for metric SCR_rate\n",
      "14.0    1\n",
      "21.0    1\n",
      "15.0    1\n",
      "16.0    1\n",
      "18.0    1\n",
      "22.0    1\n",
      "26.0    1\n",
      "27.0    1\n",
      "Name: subject, dtype: int64\n",
      "Generating features for phase BugBox_Exposure ------------------------------\n",
      "Generating features for metric bpm\n",
      "Generating features for metric rmssd\n",
      "Generating features for metric hf_rr\n",
      "Generating features for metric lf_rr\n",
      "Generating features for metric ibi\n",
      "Generating features for metric mean_SCL\n",
      "Generating features for metric SCR_rate\n",
      "14.0    3\n",
      "12.0    3\n",
      "85.0    3\n",
      "77.0    2\n",
      "83.0    2\n",
      "42.0    1\n",
      "29.0    1\n",
      "31.0    1\n",
      "Name: subject, dtype: int64\n",
      "Generating features for phase BugBox_Break ------------------------------\n",
      "Generating features for metric bpm\n",
      "Generating features for metric rmssd\n",
      "Generating features for metric hf_rr\n",
      "Generating features for metric lf_rr\n",
      "Generating features for metric ibi\n",
      "Generating features for metric mean_SCL\n",
      "Generating features for metric SCR_rate\n",
      "14.0    1\n",
      "21.0    1\n",
      "15.0    1\n",
      "16.0    1\n",
      "18.0    1\n",
      "22.0    1\n",
      "26.0    1\n",
      "27.0    1\n",
      "Name: subject, dtype: int64\n",
      "Generating features for phase Speech_Relax ------------------------------\n",
      "Generating features for metric bpm\n",
      "Generating features for metric rmssd\n",
      "Generating features for metric hf_rr\n",
      "Generating features for metric lf_rr\n",
      "Generating features for metric ibi\n",
      "Generating features for metric mean_SCL\n",
      "Generating features for metric SCR_rate\n",
      "14.0    1\n",
      "21.0    1\n",
      "15.0    1\n",
      "16.0    1\n",
      "18.0    1\n",
      "22.0    1\n",
      "26.0    1\n",
      "27.0    1\n",
      "Name: subject, dtype: int64\n",
      "Generating features for phase Speech_Anticipate ------------------------------\n",
      "Generating features for metric bpm\n",
      "Generating features for metric rmssd\n",
      "Generating features for metric hf_rr\n",
      "Generating features for metric lf_rr\n",
      "Generating features for metric ibi\n",
      "Generating features for metric mean_SCL\n",
      "Generating features for metric SCR_rate\n",
      "14.0    1\n",
      "21.0    1\n",
      "15.0    1\n",
      "16.0    1\n",
      "18.0    1\n",
      "22.0    1\n",
      "26.0    1\n",
      "27.0    1\n",
      "Name: subject, dtype: int64\n",
      "Generating features for phase Speech_Exposure ------------------------------\n",
      "Generating features for metric bpm\n",
      "Generating features for metric rmssd\n",
      "Generating features for metric hf_rr\n",
      "Generating features for metric lf_rr\n",
      "Generating features for metric ibi\n",
      "Generating features for metric mean_SCL\n",
      "Generating features for metric SCR_rate\n",
      "92.0    2\n",
      "51.0    2\n",
      "14.0    1\n",
      "4.0     1\n",
      "18.0    1\n",
      "22.0    1\n",
      "26.0    1\n",
      "27.0    1\n",
      "Name: subject, dtype: int64\n",
      "Generating features for phase Speech_Break ------------------------------\n",
      "Generating features for metric bpm\n",
      "Generating features for metric rmssd\n",
      "Generating features for metric hf_rr\n",
      "Generating features for metric lf_rr\n",
      "Generating features for metric ibi\n",
      "Generating features for metric mean_SCL\n",
      "Generating features for metric SCR_rate\n",
      "14.0    1\n",
      "21.0    1\n",
      "15.0    1\n",
      "16.0    1\n",
      "18.0    1\n",
      "22.0    1\n",
      "26.0    1\n",
      "27.0    1\n",
      "Name: subject, dtype: int64\n",
      "test subjects: [87.0, 26.0, 89.0, 82.0, 7.0]\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[07:34:26] C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/data/data.cc:689: Check failed: group_ptr_.back() == num_row_ (423 vs. 424) : Invalid group structure.  Number of rows obtained from groups doesn't equal to actual number of rows given by data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [951], line 50\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m# print(len(groups))\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[39m# print(groups[0])\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39m# print(x_test.head())\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39m# print(y_test.head())\u001b[39;00m\n\u001b[0;32m     37\u001b[0m model \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBRanker(  \n\u001b[0;32m     38\u001b[0m     \u001b[39m# tree_method='gpu_hist',\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     \u001b[39m# booster='gbtree',\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[39m# subsample=0.75 \u001b[39;00m\n\u001b[0;32m     48\u001b[0m )\n\u001b[1;32m---> 50\u001b[0m model\u001b[39m.\u001b[39;49mfit(x_train, y_train\u001b[39m.\u001b[39;49mloc[:, \u001b[39m\"\u001b[39;49m\u001b[39mranking\u001b[39;49m\u001b[39m\"\u001b[39;49m], group\u001b[39m=\u001b[39;49mgroups, verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     51\u001b[0m predicted \u001b[39m=\u001b[39m predict(x_test, y_test, model)\n",
      "File \u001b[1;32mc:\\Users\\zhoux\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\zhoux\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1993\u001b[0m, in \u001b[0;36mXGBRanker.fit\u001b[1;34m(self, X, y, group, qid, sample_weight, base_margin, eval_set, eval_group, eval_qid, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1988\u001b[0m \u001b[39mif\u001b[39;00m callable(metric):\n\u001b[0;32m   1989\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1990\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCustom evaluation metric is not yet supported for XGBRanker.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1991\u001b[0m     )\n\u001b[1;32m-> 1993\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m   1994\u001b[0m     params,\n\u001b[0;32m   1995\u001b[0m     train_dmatrix,\n\u001b[0;32m   1996\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[0;32m   1997\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[0;32m   1998\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[0;32m   1999\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[0;32m   2000\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[0;32m   2001\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   2002\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   2003\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   2004\u001b[0m )\n\u001b[0;32m   2006\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   2008\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n",
      "File \u001b[1;32mc:\\Users\\zhoux\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\zhoux\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[0;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhoux\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[0;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[0;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[0;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\zhoux\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:279\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[39m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \n\u001b[0;32m    270\u001b[0m \u001b[39mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[39m    return value from API calls\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 279\u001b[0m     \u001b[39mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[39m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [07:34:26] C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/data/data.cc:689: Check failed: group_ptr_.back() == num_row_ (423 vs. 424) : Invalid group structure.  Number of rows obtained from groups doesn't equal to actual number of rows given by data."
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "model_phases = [\n",
    "    dr.Phases.BASE_REST,\n",
    "    dr.Phases.BUG_RELAX, dr.Phases.BUG_ANTICIPATE, dr.Phases.BUG_EXPOSURE, dr.Phases.BUG_BREAK,\n",
    "    dr.Phases.SPEECH_RELAX, dr.Phases.SPEECH_ANTICIPATE, dr.Phases.SPEECH_EXPOSURE, dr.Phases.SPEECH_BREAK\n",
    "]\n",
    "\n",
    "if type(model_phases) != list:\n",
    "    model_phases = [model_phases]\n",
    "\n",
    "x, y = get_apd_data_ranking(metrics, model_phases, verbose=True)\n",
    "\n",
    "# print(x.shape)\n",
    "# print(y.shape)\n",
    "# print(x[\"subject\"].value_counts())\n",
    "\n",
    "num_phases = len(model_phases)\n",
    "num_rankings = y.shape[1]\n",
    "x_train, y_train, x_test, y_test = train_test_split(x, y)\n",
    "num_train_subjects = NUM_SUBJECTS - int(NUM_SUBJECTS*TEST_SIZE)\n",
    "groups = [num_phases for _ in range(num_train_subjects)]\n",
    "\n",
    "# print(len(groups))\n",
    "# print(groups[0])\n",
    "\n",
    "# print(x_train.shape)\n",
    "# print(y_train.shape)\n",
    "# print(x_test.shape)\n",
    "# print(y_test.shape)\n",
    "\n",
    "# print(x_train.head())\n",
    "# print(y_train.head())\n",
    "# print(x_test.head())\n",
    "# print(y_test.head())\n",
    "\n",
    "model = xgb.XGBRanker(  \n",
    "    # tree_method='gpu_hist',\n",
    "    # booster='gbtree',\n",
    "    objective='rank:ndcg',\n",
    "    n_estimators=100, \n",
    "    random_state=42, \n",
    "    learning_rate=0.1,\n",
    "    # colsample_bytree=0.9, \n",
    "    # eta=0.05, \n",
    "    # max_depth=6, \n",
    "    # subsample=0.75 \n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train.loc[:, \"ranking\"], group=groups, verbose=True)\n",
    "predicted = predict(x_test, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    subject  phaseId  ranking  actual\n",
      "0      12.0        0        3       1\n",
      "1      12.0        1        4       6\n",
      "2      12.0        2        6       3\n",
      "3      12.0        3        2       8\n",
      "4      12.0        3        9       7\n",
      "5      12.0        3       10       5\n",
      "6      12.0        4        1       4\n",
      "7      12.0        5        8       4\n",
      "8      12.0        6        7       0\n",
      "9      12.0        7        5       2\n",
      "10     12.0        8        0       0\n",
      "11     16.0        0        6       0\n",
      "12     16.0        1        1       5\n",
      "13     16.0        2        2       8\n",
      "14     16.0        4        0       3\n",
      "15     16.0        5        3       7\n",
      "16     16.0        6        7       4\n",
      "17     16.0        7        5       6\n",
      "18     16.0        8        4       2\n",
      "19     22.0        0        4       8\n",
      "20     22.0        1        6       3\n",
      "21     22.0        2        0       5\n",
      "22     22.0        3        7       4\n",
      "23     22.0        4        5       2\n",
      "24     22.0        5        2       7\n",
      "25     22.0        6        8       6\n",
      "26     22.0        7        3       0\n",
      "27     22.0        8        1       1\n",
      "28     23.0        0        0       1\n",
      "29     23.0        1        7       3\n",
      "30     23.0        2        4       8\n",
      "31     23.0        4        3       8\n",
      "32     23.0        5        1       2\n",
      "33     23.0        6        5       5\n",
      "34     23.0        7        6       0\n",
      "35     23.0        8        2       8\n",
      "36     82.0        0        1       7\n",
      "37     82.0        1        2       4\n",
      "38     82.0        2        3       1\n",
      "39     82.0        3        5       5\n",
      "40     82.0        4        7       7\n",
      "41     82.0        5        4       3\n",
      "42     82.0        6        8       2\n",
      "43     82.0        7        0       6\n",
      "44     82.0        8        6       6\n"
     ]
    }
   ],
   "source": [
    "# print(predicted)\n",
    "# print(y_test)\n",
    "subjects = list(predicted.loc[:, \"subject\"].unique())\n",
    "predicted = predicted.sort_values(by=[\"subject\", \"phaseId\"]).reset_index(drop=True)\n",
    "\n",
    "print(predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "546118464d5f1b8107aba37f58db47ce6901389061f2cf944aaa875419724407"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
