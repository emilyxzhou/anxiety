{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we classify each phase as relatively low or high anxiety for each subject? ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING MODULES\n",
    "import glob\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "cvx_path = os.path.abspath(os.path.join('..', 'cvxEDA', 'src'))\n",
    "module_path = os.path.abspath(os.path.join('..', 'src'))\n",
    "sys.path.append(module_path)\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy.signal as ss\n",
    "import sys\n",
    "\n",
    "import tools.data_reader_apd as dr\n",
    "import tools.display_tools as dt\n",
    "import tools.preprocessing as preprocessing\n",
    "\n",
    "from scipy.fft import fft, fftfreq, fftshift\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import cvxopt.solvers\n",
    "cvxopt.solvers.options['show_progress'] = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", \n",
    "    category=RuntimeWarning\n",
    ")\n",
    "\n",
    "\n",
    "phases = {\n",
    "    \"Baseline\": [dr.Phases.BASE_REST, dr.Phases.BASE_SPEECH],\n",
    "    \"Bug baseline\": [dr.Phases.BUG_RELAX],\n",
    "    \"Speech baseline\": [dr.Phases.SPEECH_RELAX],\n",
    "    \"Bug all\": [dr.Phases.BUG_RELAX, dr.Phases.BUG_ANTICIPATE, dr.Phases.BUG_EXPOSURE, dr.Phases.BUG_BREAK, dr.Phases.BUG_REFLECT],\n",
    "    \"Speech all\": [dr.Phases.SPEECH_RELAX, dr.Phases.SPEECH_ANTICIPATE, dr.Phases.SPEECH_EXPOSURE, dr.Phases.SPEECH_BREAK, dr.Phases.SPEECH_REFLECT],\n",
    "    \"Bug pre-anxiety\": [dr.Phases.BUG_RELAX, dr.Phases.BUG_ANTICIPATE],\n",
    "    \"Speech pre-anxiety\": [dr.Phases.SPEECH_RELAX, dr.Phases.SPEECH_ANTICIPATE],\n",
    "    \"Bug anxiety\": [dr.Phases.BUG_EXPOSURE],\n",
    "    \"Speech anxiety\": [dr.Phases.SPEECH_EXPOSURE],\n",
    "    \"Bug post-anxiety\": [dr.Phases.BUG_BREAK, dr.Phases.BUG_REFLECT],\n",
    "    \"Speech post-anxiety\": [dr.Phases.SPEECH_BREAK, dr.Phases.SPEECH_REFLECT],\n",
    "}\n",
    "\n",
    "test_phases = [\n",
    "    phases[\"Baseline\"],\n",
    "    phases[\"Bug baseline\"],\n",
    "    phases[\"Speech baseline\"],\n",
    "    phases[\"Bug baseline\"] + phases[\"Speech baseline\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug baseline\"],\n",
    "    phases[\"Baseline\"] + phases[\"Speech baseline\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug baseline\"] + phases[\"Speech baseline\"],\n",
    "\n",
    "    phases[\"Bug all\"],\n",
    "    phases[\"Speech all\"],\n",
    "    phases[\"Bug all\"] + phases[\"Speech all\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug all\"],\n",
    "    phases[\"Baseline\"] + phases[\"Speech all\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug all\"] + phases[\"Speech all\"],\n",
    "\n",
    "    phases[\"Bug pre-anxiety\"],\n",
    "    phases[\"Speech pre-anxiety\"],\n",
    "    phases[\"Bug pre-anxiety\"] + phases[\"Speech pre-anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug pre-anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Speech pre-anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug pre-anxiety\"] + phases[\"Speech pre-anxiety\"],\n",
    "\n",
    "    phases[\"Bug anxiety\"],\n",
    "    phases[\"Speech anxiety\"],\n",
    "    phases[\"Bug pre-anxiety\"] + phases[\"Speech anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Speech anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug anxiety\"] + phases[\"Speech anxiety\"],\n",
    "\n",
    "    phases[\"Bug post-anxiety\"],\n",
    "    phases[\"Speech post-anxiety\"],\n",
    "    phases[\"Bug post-anxiety\"] + phases[\"Speech post-anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug post-anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Speech post-anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug post-anxiety\"] + phases[\"Speech post-anxiety\"],\n",
    "\n",
    "    phases[\"Bug pre-anxiety\"] + phases[\"Bug anxiety\"],\n",
    "    phases[\"Speech pre-anxiety\"] + phases[\"Speech anxiety\"],\n",
    "    phases[\"Bug pre-anxiety\"] + phases[\"Bug anxiety\"] + phases[\"Speech pre-anxiety\"] + phases[\"Speech anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug pre-anxiety\"] + phases[\"Bug anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Speech pre-anxiety\"] + phases[\"Speech anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug pre-anxiety\"] + phases[\"Bug anxiety\"] + phases[\"Speech pre-anxiety\"] + phases[\"Speech anxiety\"],\n",
    "\n",
    "    phases[\"Bug post-anxiety\"] + phases[\"Bug anxiety\"],\n",
    "    phases[\"Speech post-anxiety\"] + phases[\"Speech anxiety\"],\n",
    "    phases[\"Bug post-anxiety\"] + phases[\"Bug anxiety\"] + phases[\"Speech post-anxiety\"] + phases[\"Speech anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug post-anxiety\"] + phases[\"Bug anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Speech post-anxiety\"] + phases[\"Speech anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug post-anxiety\"] + phases[\"Bug anxiety\"] + phases[\"Speech post-anxiety\"] + phases[\"Speech anxiety\"],\n",
    "\n",
    "    phases[\"Bug pre-anxiety\"] + phases[\"Bug post-anxiety\"],\n",
    "    phases[\"Speech pre-anxiety\"] + phases[\"Speech post-anxiety\"],\n",
    "    phases[\"Bug pre-anxiety\"] + phases[\"Bug post-anxiety\"] + phases[\"Speech pre-anxiety\"] + phases[\"Speech post-anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug pre-anxiety\"] + phases[\"Bug post-anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Speech pre-anxiety\"] + phases[\"Speech post-anxiety\"],\n",
    "    phases[\"Baseline\"] + phases[\"Bug pre-anxiety\"] + phases[\"Bug post-anxiety\"] + phases[\"Speech pre-anxiety\"] + phases[\"Speech post-anxiety\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANKING PHASES BY LOW TO HIGH ANXIETY\n",
    "SUDS_labels = [\n",
    "    \"Participant\",\n",
    "    \"Baseline_SUDS\",\n",
    "    # \"BugBox_Relax_SUDS\", \"BugBox_Preparation_SUDS\", \"BugBox_Exposure_SUDS\", \"BugBox_Break_SUDS\",\n",
    "    \"BugBox_Relax_SUDS\", \"BugBox_Preparation_SUDS\", \"BugBox_Break_SUDS\",\n",
    "    \"Speech_Relax_SUDS\", \"Speech_SUDS\", \"Speech_Exposure_SUDS\", \"Speech_Break_SUDS\"\n",
    "]\n",
    "\n",
    "\n",
    "ha_participant_indices = [\n",
    "    'P4', 'P6', 'P7', 'P8', 'P10', 'P12', 'P15', 'P16', 'P18', 'P22', 'P26', 'P27', 'P29', 'P31', 'P32', 'P33', 'P35', 'P42', 'P45', 'P47', 'P48', 'P49', 'P54', 'P55', 'P66', 'P69'\n",
    "]\n",
    "\n",
    "la_participant_indices = [\n",
    "    'P14', 'P21', 'P23', 'P25', 'P34', 'P39', 'P43', 'P46', 'P51', 'P57', 'P71', 'P72', 'P77', 'P78', 'P79', 'P80', 'P82', 'P83', 'P84', 'P85', 'P87', 'P88', 'P89', 'P91', 'P92', 'P93'\n",
    "]\n",
    "\n",
    "participant_file = os.path.join(dr.Paths.DATA_DIR, \"participants_details.csv\")\n",
    "df = pd.read_csv(participant_file)\n",
    "\n",
    "suds_df = df[SUDS_labels]\n",
    "ha_suds_df = suds_df.loc[suds_df['Participant'].isin(ha_participant_indices)]\n",
    "la_suds_df = suds_df.loc[suds_df['Participant'].isin(la_participant_indices)]\n",
    "\n",
    "ha_suds_df = ha_suds_df.rename(columns={\"Participant\": \"subject\"})\n",
    "la_suds_df = la_suds_df.rename(columns={\"Participant\": \"subject\"})\n",
    "\n",
    "for i in range(ha_suds_df.shape[0]):\n",
    "    p = int(ha_suds_df.iloc[i, ha_suds_df.columns.get_loc(\"subject\")][1:])\n",
    "    ha_suds_df.iloc[i, ha_suds_df.columns.get_loc(\"subject\")] = p\n",
    "for i in range(la_suds_df.shape[0]):\n",
    "    p = int(la_suds_df.iloc[i, la_suds_df.columns.get_loc(\"subject\")][1:])\n",
    "    la_suds_df.iloc[i, la_suds_df.columns.get_loc(\"subject\")] = p\n",
    "\n",
    "# ha_suds_df['median'] = ha_suds_df.iloc[:, 1:].median(axis=1)\n",
    "# la_suds_df['median'] = la_suds_df.iloc[:, 1:].median(axis=1)\n",
    "ha_suds_df['median'] = ha_suds_df.iloc[:, 1:].mean(axis=1)\n",
    "la_suds_df['median'] = la_suds_df.iloc[:, 1:].mean(axis=1)\n",
    "columns = {c: SUDS_labels.index(c)-1 for c in ha_suds_df.columns[1:-1]}\n",
    "\n",
    "ha_rankings = ha_suds_df.rename(columns={c: SUDS_labels.index(c)-1 for c in ha_suds_df.columns[1:-1]}).reset_index(drop=True)\n",
    "la_rankings = la_suds_df.rename(columns={c: SUDS_labels.index(c)-1 for c in la_suds_df.columns[1:-1]}).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANKING_PHASES = [\n",
    "    dr.Phases.BASE_REST,\n",
    "    # dr.Phases.BUG_RELAX, dr.Phases.BUG_ANTICIPATE, dr.Phases.BUG_EXPOSURE, dr.Phases.BUG_BREAK,\n",
    "    dr.Phases.BUG_RELAX, dr.Phases.BUG_ANTICIPATE, dr.Phases.BUG_BREAK,\n",
    "    dr.Phases.SPEECH_RELAX, dr.Phases.SPEECH_ANTICIPATE, dr.Phases.SPEECH_EXPOSURE, dr.Phases.SPEECH_BREAK\n",
    "]\n",
    "\n",
    "NUM_SUBJECTS = 52\n",
    "TEST_SIZE = 0.1\n",
    "\n",
    "def get_apd_data_ranking(metrics, phases, verbose=False, include_anxiety_labels=False):\n",
    "    metrics_folder = os.path.join(dr.Paths.DATA_DIR, \"metrics\")\n",
    "\n",
    "    columns = metrics.copy()\n",
    "    columns.insert(0, \"subject\")\n",
    "\n",
    "    data_x = []\n",
    "    data_y = pd.concat([ha_rankings, la_rankings], axis=0).reset_index(drop=True)\n",
    "\n",
    "    for phase in phases:\n",
    "        if verbose: print(f\"Generating features for phase {phase} \" + \"-\"*30)\n",
    "        phase_id = phases.index(phase)\n",
    "        ha_features = []\n",
    "        la_features = []\n",
    "\n",
    "        for i in range(len(metrics)):\n",
    "            metric = metrics[i]\n",
    "            if verbose: print(f\"Generating features for metric {metric}\")\n",
    "            file = os.path.join(metrics_folder, f\"{metric}_{phase}_ha.csv\")\n",
    "            arr = pd.read_csv(file, index_col=[0]).to_numpy()\n",
    "\n",
    "            if i == 0:  # subject IDs\n",
    "                ids = np.reshape(arr[:, 0], (arr[:, 0].size, 1))\n",
    "                ids = pd.DataFrame(data=ids, columns=[\"subject\"])\n",
    "                ha_features.append(ids)\n",
    "\n",
    "            # arr = arr[1:, 1:]\n",
    "            col_mean = np.nanmean(arr, axis=1)\n",
    "            idx = np.where(np.isnan(arr))\n",
    "            arr[idx] = np.take(col_mean, idx[0])\n",
    "            arr = np.nan_to_num(arr)\n",
    "            arr = np.mean(arr[:, 1:], axis=1)\n",
    "            arr = np.reshape(arr, (arr.size, 1))\n",
    "            arr = pd.DataFrame(data=arr, columns=[f\"{metric}\"])\n",
    "            ha_features.append(arr)\n",
    "\n",
    "            file = os.path.join(metrics_folder, f\"{metric}_{phase}_la.csv\")\n",
    "            arr = pd.read_csv(file, index_col=[0]).to_numpy()\n",
    "\n",
    "            if i == 0:  # subject IDs\n",
    "                ids = np.reshape(arr[:, 0], (arr[:, 0].size, 1))\n",
    "                ids = pd.DataFrame(data=ids, columns=[\"subject\"])\n",
    "                la_features.append(ids)\n",
    "\n",
    "            # arr = arr[1:, 1:]\n",
    "            col_mean = np.nanmean(arr, axis=1)\n",
    "            idx = np.where(np.isnan(arr))\n",
    "            arr[idx] = np.take(col_mean, idx[0])\n",
    "            arr = np.nan_to_num(arr)\n",
    "            arr = np.mean(arr[:, 1:], axis=1)\n",
    "            arr = np.reshape(arr, (arr.size, 1))\n",
    "            arr = pd.DataFrame(data=arr, columns=[f\"{metric}\"])\n",
    "            la_features.append(arr)\n",
    "\n",
    "        if include_anxiety_labels: \n",
    "            ha_group = pd.DataFrame(data=[1 for _ in range(len(ha_features[0]))])\n",
    "            la_group = pd.DataFrame(data=[0 for _ in range(len(la_features[0]))])\n",
    "            anxiety_label = pd.concat([ha_group, la_group])\n",
    "\n",
    "        ha_features = pd.concat(ha_features, axis=1)\n",
    "        la_features = pd.concat(la_features, axis=1)\n",
    "        x = pd.concat([ha_features, la_features], axis=0)\n",
    "        # print(x[\"subject\"].value_counts().iloc[0:8])\n",
    "        phase = pd.DataFrame(data=[phase_id for _ in range(x.shape[0])])\n",
    "\n",
    "        x.insert(1, \"phaseId\", phase)\n",
    "\n",
    "        if include_anxiety_labels: \n",
    "            x.insert(1, \"anxiety group\", anxiety_label)\n",
    "\n",
    "        data_x.append(x)\n",
    "    \n",
    "    data_x = pd.concat(data_x).reset_index(drop=True)\n",
    "    # data_x.sort_values(by=[\"phaseId\", \"subject\"], inplace=True)\n",
    "\n",
    "    # print(data_x.head())\n",
    "    # print(data_y.head())\n",
    "\n",
    "    subjects = data_x.loc[:, \"subject\"]\n",
    "    phase_col = data_x.loc[:, \"phaseId\"]\n",
    "    label = []\n",
    "    for i in range(data_x.shape[0]):\n",
    "        s = int(subjects.iloc[i])\n",
    "        p = int(phase_col.iloc[i])\n",
    "        rating = data_y.loc[data_y[\"subject\"] == s].loc[:, p].values[0]\n",
    "        med = data_y.loc[data_y[\"subject\"] == s].loc[:, 'median'].values[0]\n",
    "        if rating < med:\n",
    "            label.append(0)  # low anxiety\n",
    "        else:\n",
    "            label.append(1)  # high anxiety\n",
    "    \n",
    "    data_y = pd.DataFrame({\"subject\": subjects, \"label\": label})\n",
    "    # data_y = pd.DataFrame({\"ranking\": ranking_col})\n",
    "\n",
    "    # print(data_x.shape)\n",
    "    # print(data_y.shape)\n",
    "    \n",
    "    return data_x, data_y\n",
    "\n",
    "\n",
    "def train_test_split(x, y):\n",
    "    subjects = list(x.loc[:, \"subject\"].unique())\n",
    "    test_subjects = random.sample(subjects, int(NUM_SUBJECTS*TEST_SIZE))\n",
    "    # print(f\"test subjects: {test_subjects}\")\n",
    "    x_train = x[~x[\"subject\"].isin(test_subjects)]\n",
    "    y_train = y[~y[\"subject\"].isin(test_subjects)]\n",
    "    x_test = x[x[\"subject\"].isin(test_subjects)]\n",
    "    y_test = y[y[\"subject\"].isin(test_subjects)]\n",
    "\n",
    "    # print(x.shape)\n",
    "    # print(y.shape)\n",
    "    # print(x_train.shape)\n",
    "    # print(y_train.shape)\n",
    "    # print(x_test.shape)\n",
    "    # print(y_test.shape)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test, test_subjects\n",
    "\n",
    "\n",
    "def train_predict(models, x, y, show_classification=True):\n",
    "    \"\"\"\n",
    "    models: dictionary of {\"name\": model}\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    x_train, y_train, x_test, y_test, test_subjects = train_test_split(x, y)\n",
    "    y_true = y_test.loc[:, \"label\"]\n",
    "    for model_name in models.keys():\n",
    "        model = models[model_name]\n",
    "        model.fit(x_train, y_train.loc[:, \"label\"])\n",
    "        y_pred = model.predict(x_test)\n",
    "        if show_classification:\n",
    "            print(f\"Results for {model_name} -------------------------\")\n",
    "            print(classification_report(y_true, y_pred, target_names=[\"Low anxiety rating\", \"High anxiety rating\"]))\n",
    "        out[model_name] = accuracy_score(y_true, y_pred)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy over 10 rounds: 0.535\n",
      "KNN accuracy over 10 rounds: 0.6174999999999999\n"
     ]
    }
   ],
   "source": [
    "# LOAD TRAIN AND TEST DATA\n",
    "\n",
    "metrics = [\n",
    "    \"bpm\", \n",
    "    \"rmssd\", \n",
    "    \"hf_rr\", \n",
    "    \"lf_rr\", \n",
    "    \"ibi\", \n",
    "    \"mean_SCL\", \n",
    "    \"SCR_rate\"\n",
    "]\n",
    "\n",
    "model_phases = [\n",
    "    dr.Phases.BASE_REST,\n",
    "    # dr.Phases.BUG_RELAX, dr.Phases.BUG_ANTICIPATE, dr.Phases.BUG_EXPOSURE, dr.Phases.BUG_BREAK,\n",
    "    dr.Phases.BUG_RELAX, dr.Phases.BUG_ANTICIPATE, dr.Phases.BUG_BREAK,\n",
    "    dr.Phases.SPEECH_RELAX, dr.Phases.SPEECH_ANTICIPATE, dr.Phases.SPEECH_EXPOSURE, dr.Phases.SPEECH_BREAK\n",
    "]\n",
    "\n",
    "if type(model_phases) != list:\n",
    "    model_phases = [model_phases]\n",
    "\n",
    "x, y = get_apd_data_ranking(metrics, model_phases, verbose=False, include_anxiety_labels=True)\n",
    "# drop subjects with noisy data\n",
    "x = x[x['subject'] != 84.0]\n",
    "y = y[y['subject'] != 84.0]\n",
    "NUM_SUBJECTS -= 1\n",
    "\n",
    "models = {\n",
    "    \"SVM\": SVC(C=10, gamma=0.01), \n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "results = {\"SVM\": [], \"KNN\": []}\n",
    "num_iters = 10\n",
    "for _ in range(num_iters):\n",
    "    out = train_predict(models, x, y, show_classification=False)\n",
    "    for model_name in results:\n",
    "        results[model_name].append(out[model_name])\n",
    "\n",
    "for model_name in results.keys():\n",
    "    print(f\"{model_name} accuracy over {num_iters} rounds: {np.mean(results[model_name])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notes:\n",
    "KNN\n",
    "best results when using HR freq domain metrics instead of time domain\n",
    "mean SCL > SCR rate\n",
    "SVM > KNN when using both mean SCL and SCR rate\n",
    "7 > 5 = 9 neighbors\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "546118464d5f1b8107aba37f58db47ce6901389061f2cf944aaa875419724407"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
