{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING MODULES\n",
    "import glob\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('..', 'src'))\n",
    "sys.path.append(module_path)\n",
    "import pandas as pd\n",
    "import scipy.signal as ss\n",
    "import sys\n",
    "\n",
    "import tools.data_reader_apd as dr\n",
    "import tools.display_tools as dt\n",
    "import tools.preprocessing as preprocessing\n",
    "\n",
    "from scipy.fft import fft, fftfreq, fftshift\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", \n",
    "    category=RuntimeWarning\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "importlib.reload(preprocessing)\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "\n",
    "import csv\n",
    "\n",
    "metrics_folder = os.path.join(dr.Paths.DATA_DIR, \"metrics\")\n",
    "metrics = [\"bpm\", \"rmssd\", \"hf_rr\", \"lf_rr\", \"mean_SCL\", \"SCR_rate\"]\n",
    "phases = [\n",
    "    dr.Phases.BASE_REST, dr.Phases.BASE_SPEECH,\n",
    "    dr.Phases.BUG_RELAX, dr.Phases.BUG_ANTICIPATE, dr.Phases.BUG_EXPOSURE, dr.Phases.BUG_BREAK, dr.Phases.BUG_REFLECT,\n",
    "    dr.Phases.SPEECH_RELAX, dr.Phases.SPEECH_ANTICIPATE, dr.Phases.SPEECH_EXPOSURE, dr.Phases.SPEECH_BREAK, dr.Phases.SPEECH_REFLECT\n",
    "]\n",
    "\n",
    "clf = svm.SVC()\n",
    "\n",
    "for metric in metrics:\n",
    "    print(f\"SVM USING {metric} -----------------------------------\")\n",
    "    ha = []\n",
    "    la = []\n",
    "    for phase in phases:\n",
    "        file = os.path.join(metrics_folder, f\"{metric}_{phase}_ha.csv\")\n",
    "        arr = pd.read_csv(file, header=None, index_col=[0]).to_numpy()\n",
    "        arr = arr[1:, 1:]\n",
    "        # avg = np.nanmean(arr, axis=1)\n",
    "        # ha.append(avg)\n",
    "        col_mean = np.nanmean(arr, axis=1)\n",
    "        idx = np.where(np.isnan(arr))\n",
    "        arr[idx] = np.take(col_mean, idx[0])\n",
    "        arr = np.nan_to_num(arr)\n",
    "\n",
    "        ha.append(arr)\n",
    "\n",
    "        file = os.path.join(metrics_folder, f\"{metric}_{phase}_la.csv\")\n",
    "        arr = pd.read_csv(file, header=None, index_col=[0]).to_numpy()\n",
    "        arr = arr[1:, 1:]\n",
    "        # avg = np.nanmean(arr, axis=1)\n",
    "        # la.append(avg)\n",
    "        col_mean = np.nanmean(arr, axis=1)\n",
    "        idx = np.where(np.isnan(arr))\n",
    "        arr[idx] = np.take(col_mean, idx[0])\n",
    "        arr = np.nan_to_num(arr)\n",
    "\n",
    "        la.append(arr)\n",
    "\n",
    "    # ha_arr = np.asarray(ha).transpose()\n",
    "    # la_arr = np.asarray(la).transpose()\n",
    "    ha_arr = np.hstack(ha)\n",
    "    la_arr = np.hstack(la)\n",
    "\n",
    "    max_len = np.max([ha_arr.shape[1], la_arr.shape[1]])\n",
    "    ha_arr = np.pad(ha_arr, ((0, 0), (0, max_len - ha_arr.shape[1])), \"constant\", constant_values=0.0)\n",
    "    la_arr = np.pad(la_arr, ((0, 0), (0, max_len - la_arr.shape[1])), \"constant\", constant_values=0.0)\n",
    "\n",
    "    x = np.vstack([ha_arr, la_arr])\n",
    "    y = np.asarray([1 for _ in range(ha_arr.shape[0])] + [0 for _ in range(ha_arr.shape[0])])\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=16)\n",
    "\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    preds = clf.predict(x_test)\n",
    "    actual = y_test\n",
    "\n",
    "    # print(confusion_matrix(actual, preds))\n",
    "    # print(classification_report(actual, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy over 10 rounds: 0.6466666666666667\n"
     ]
    }
   ],
   "source": [
    "# SVM ENSEMBLE\n",
    "importlib.reload(preprocessing)\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "\n",
    "import csv\n",
    "import random\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "metrics_folder = os.path.join(dr.Paths.DATA_DIR, \"metrics\")\n",
    "metrics = [\"bpm\", \"rmssd\", \"hf_rr\", \"lf_rr\", \"mean_SCL\", \"SCR_rate\"]\n",
    "phases = [\n",
    "    dr.Phases.BASE_REST, dr.Phases.BASE_SPEECH,\n",
    "    # dr.Phases.BUG_RELAX, dr.Phases.BUG_ANTICIPATE, dr.Phases.BUG_EXPOSURE, dr.Phases.BUG_BREAK, dr.Phases.BUG_REFLECT,\n",
    "    # dr.Phases.SPEECH_RELAX, dr.Phases.SPEECH_ANTICIPATE, dr.Phases.SPEECH_EXPOSURE, dr.Phases.SPEECH_BREAK, dr.Phases.SPEECH_REFLECT\n",
    "]\n",
    "\n",
    "clfs = [svm.SVC(), svm.SVC(), svm.SVC(), svm.SVC(), svm.SVC(), svm.SVC()]\n",
    "x_y = []\n",
    "\n",
    "acc = []\n",
    "for _ in range(10):\n",
    "    for metric in metrics:\n",
    "        ha = []\n",
    "        la = []\n",
    "        for phase in phases:\n",
    "            file = os.path.join(metrics_folder, f\"{metric}_{phase}_ha.csv\")\n",
    "            arr = pd.read_csv(file, header=None, index_col=[0]).to_numpy()\n",
    "            arr = arr[1:, 1:]\n",
    "            col_mean = np.nanmean(arr, axis=1)\n",
    "            idx = np.where(np.isnan(arr))\n",
    "            arr[idx] = np.take(col_mean, idx[0])\n",
    "            arr = np.nan_to_num(arr)\n",
    "\n",
    "            ha.append(arr)\n",
    "\n",
    "            file = os.path.join(metrics_folder, f\"{metric}_{phase}_la.csv\")\n",
    "            arr = pd.read_csv(file, header=None, index_col=[0]).to_numpy()\n",
    "            arr = arr[1:, 1:]\n",
    "            col_mean = np.nanmean(arr, axis=1)\n",
    "            idx = np.where(np.isnan(arr))\n",
    "            arr[idx] = np.take(col_mean, idx[0])\n",
    "            arr = np.nan_to_num(arr)\n",
    "\n",
    "            la.append(arr)\n",
    "\n",
    "        ha_arr = np.hstack(ha)\n",
    "        la_arr = np.hstack(la)\n",
    "\n",
    "        max_len = np.max([ha_arr.shape[1], la_arr.shape[1]])\n",
    "        ha_arr = np.pad(ha_arr, ((0, 0), (0, max_len - ha_arr.shape[1])), \"constant\", constant_values=0.0)\n",
    "        la_arr = np.pad(la_arr, ((0, 0), (0, max_len - la_arr.shape[1])), \"constant\", constant_values=0.0)\n",
    "\n",
    "        x = np.vstack([ha_arr, la_arr])\n",
    "        y = np.asarray([1 for _ in range(ha_arr.shape[0])] + [0 for _ in range(ha_arr.shape[0])])\n",
    "\n",
    "        x_y.append([x, y])\n",
    "\n",
    "        all_preds = []\n",
    "        actual = []\n",
    "        test_size = 0.1\n",
    "        test_indices = random.sample(range(y.size), int(y.size*test_size))\n",
    "\n",
    "        for clf, train_data in zip(clfs, x_y):\n",
    "            x = train_data[0]\n",
    "            y = train_data[1]\n",
    "            x_train = [] \n",
    "            x_test = []\n",
    "            y_train = []\n",
    "            y_test = []\n",
    "            for i in range(y.size):\n",
    "                if i in test_indices:\n",
    "                    x_test.append(x[i, :])\n",
    "                    y_test.append(y[i])\n",
    "                else:\n",
    "                    x_train.append(x[i, :])\n",
    "                    y_train.append(y[i])\n",
    "            \n",
    "            x_train = np.asarray(x_train)\n",
    "            y_train = np.asarray(y_train)\n",
    "            x_test = np.asarray(x_test)\n",
    "            y_test = np.asarray(y_test)\n",
    "\n",
    "            clf.fit(x_train, y_train)\n",
    "            preds = clf.predict(x_test)\n",
    "\n",
    "            all_preds.append(preds)\n",
    "            actual.append(y_test)\n",
    "\n",
    "        all_preds = np.vstack(all_preds).mean(axis=0)\n",
    "        # Majority voting\n",
    "        all_preds[all_preds < 0.5] = 0\n",
    "        all_preds[all_preds > 0.5] = 1\n",
    "        all_preds = all_preds.astype(int)\n",
    "        actual = actual[0]\n",
    "\n",
    "        # print(confusion_matrix(actual, preds))\n",
    "        # print(classification_report(actual, preds))\n",
    "        acc.append(accuracy_score(actual, preds))\n",
    "\n",
    "print(f\"Accuracy over 10 rounds: {np.mean(acc)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM FFT\n",
    "importlib.reload(preprocessing)\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "\n",
    "import csv\n",
    "\n",
    "phases = [\n",
    "    dr.Phases.BASE_REST, dr.Phases.BASE_SPEECH,\n",
    "    dr.Phases.BUG_RELAX, dr.Phases.BUG_ANTICIPATE, dr.Phases.BUG_EXPOSURE, dr.Phases.BUG_BREAK, dr.Phases.BUG_REFLECT,\n",
    "    dr.Phases.SPEECH_RELAX, dr.Phases.SPEECH_ANTICIPATE, dr.Phases.SPEECH_EXPOSURE, dr.Phases.SPEECH_BREAK, dr.Phases.SPEECH_REFLECT\n",
    "]\n",
    "\n",
    "convert_sr = False\n",
    "tasks = [dr.Tasks.BASELINE, dr.Tasks.BUGS, dr.Tasks.SPEAKING]\n",
    "data_type = dr.DataTypes.ECG\n",
    "fs = preprocessing.FS_DICT[data_type]\n",
    "f_dim = preprocessing.DATA_TYPE_DIMENSIONS[data_type]\n",
    "\n",
    "ha = []\n",
    "la = []\n",
    "for task in tasks:\n",
    "    if task == dr.Tasks.BASELINE:\n",
    "        phases = [dr.Phases.BASE_REST, dr.Phases.BASE_SPEECH]\n",
    "    elif task == dr.Tasks.BUGS:\n",
    "        phases = [dr.Phases.BUG_RELAX, dr.Phases.BUG_ANTICIPATE, dr.Phases.BUG_EXPOSURE, dr.Phases.BUG_BREAK, dr.Phases.BUG_REFLECT]\n",
    "    else:\n",
    "        phases = [dr.Phases.SPEECH_RELAX, dr.Phases.SPEECH_ANTICIPATE, dr.Phases.SPEECH_EXPOSURE, dr.Phases.SPEECH_BREAK, dr.Phases.SPEECH_REFLECT]\n",
    "\n",
    "    for phase in phases:\n",
    "        ha_data, la_data = preprocessing.load_data(task, data_type, phase, convert_sr)\n",
    "        ha_fft = []\n",
    "        la_fft = []\n",
    "        for data in ha_data:\n",
    "            freq, amp = preprocessing.calculate_fft_1d(data, fs)\n",
    "            ha_fft.append(amp)\n",
    "        for data in la_data:\n",
    "            freq, amp = preprocessing.calculate_fft_1d(data, fs)\n",
    "            la_fft.append(amp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy over 10 rounds: 0.9033333333333334\n"
     ]
    }
   ],
   "source": [
    "# KNN ENSEMBLE\n",
    "importlib.reload(preprocessing)\n",
    "importlib.reload(dr)\n",
    "importlib.reload(dt)\n",
    "\n",
    "import csv\n",
    "import random\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "metrics_folder = os.path.join(dr.Paths.DATA_DIR, \"metrics\")\n",
    "metrics = [\"bpm\", \"rmssd\", \"hf_rr\", \"lf_rr\", \"mean_SCL\", \"SCR_rate\"]\n",
    "phases = [\n",
    "    dr.Phases.BASE_REST, dr.Phases.BASE_SPEECH,\n",
    "    dr.Phases.BUG_RELAX, dr.Phases.BUG_ANTICIPATE, dr.Phases.BUG_EXPOSURE, dr.Phases.BUG_BREAK, dr.Phases.BUG_REFLECT,\n",
    "    dr.Phases.SPEECH_RELAX, dr.Phases.SPEECH_ANTICIPATE, dr.Phases.SPEECH_EXPOSURE, dr.Phases.SPEECH_BREAK, dr.Phases.SPEECH_REFLECT\n",
    "]\n",
    "\n",
    "clfs = [KNeighborsClassifier(), KNeighborsClassifier(), KNeighborsClassifier(), KNeighborsClassifier(), KNeighborsClassifier(), KNeighborsClassifier()]\n",
    "x_y = []\n",
    "\n",
    "acc = []\n",
    "for _ in range(10):\n",
    "    for metric in metrics:\n",
    "        ha = []\n",
    "        la = []\n",
    "        for phase in phases:\n",
    "            file = os.path.join(metrics_folder, f\"{metric}_{phase}_ha.csv\")\n",
    "            arr = pd.read_csv(file, header=None, index_col=[0]).to_numpy()\n",
    "            arr = arr[1:, 1:]\n",
    "            col_mean = np.nanmean(arr, axis=1)\n",
    "            idx = np.where(np.isnan(arr))\n",
    "            arr[idx] = np.take(col_mean, idx[0])\n",
    "            arr = np.nan_to_num(arr)\n",
    "\n",
    "            ha.append(arr)\n",
    "\n",
    "            file = os.path.join(metrics_folder, f\"{metric}_{phase}_la.csv\")\n",
    "            arr = pd.read_csv(file, header=None, index_col=[0]).to_numpy()\n",
    "            arr = arr[1:, 1:]\n",
    "            col_mean = np.nanmean(arr, axis=1)\n",
    "            idx = np.where(np.isnan(arr))\n",
    "            arr[idx] = np.take(col_mean, idx[0])\n",
    "            arr = np.nan_to_num(arr)\n",
    "\n",
    "            la.append(arr)\n",
    "\n",
    "        ha_arr = np.hstack(ha)\n",
    "        la_arr = np.hstack(la)\n",
    "\n",
    "        max_len = np.max([ha_arr.shape[1], la_arr.shape[1]])\n",
    "        ha_arr = np.pad(ha_arr, ((0, 0), (0, max_len - ha_arr.shape[1])), \"constant\", constant_values=0.0)\n",
    "        la_arr = np.pad(la_arr, ((0, 0), (0, max_len - la_arr.shape[1])), \"constant\", constant_values=0.0)\n",
    "\n",
    "        x = np.vstack([ha_arr, la_arr])\n",
    "        y = np.asarray([1 for _ in range(ha_arr.shape[0])] + [0 for _ in range(ha_arr.shape[0])])\n",
    "\n",
    "        x_y.append([x, y])\n",
    "\n",
    "        all_preds = []\n",
    "        actual = []\n",
    "        test_size = 0.1\n",
    "        test_indices = random.sample(range(y.size), int(y.size*test_size))\n",
    "\n",
    "        for clf, train_data in zip(clfs, x_y):\n",
    "            x = train_data[0]\n",
    "            y = train_data[1]\n",
    "            x_train = [] \n",
    "            x_test = []\n",
    "            y_train = []\n",
    "            y_test = []\n",
    "            for i in range(y.size):\n",
    "                if i in test_indices:\n",
    "                    x_test.append(x[i, :])\n",
    "                    y_test.append(y[i])\n",
    "                else:\n",
    "                    x_train.append(x[i, :])\n",
    "                    y_train.append(y[i])\n",
    "            \n",
    "            x_train = np.asarray(x_train)\n",
    "            y_train = np.asarray(y_train)\n",
    "            x_test = np.asarray(x_test)\n",
    "            y_test = np.asarray(y_test)\n",
    "\n",
    "            clf.fit(x_train, y_train)\n",
    "            preds = clf.predict(x_test)\n",
    "\n",
    "            all_preds.append(preds)\n",
    "            actual.append(y_test)\n",
    "\n",
    "        all_preds = np.vstack(all_preds).mean(axis=0)\n",
    "        # Majority voting\n",
    "        all_preds[all_preds < 0.5] = 0\n",
    "        all_preds[all_preds > 0.5] = 1\n",
    "        all_preds = all_preds.astype(int)\n",
    "        actual = actual[0]\n",
    "\n",
    "        # print(confusion_matrix(actual, preds))\n",
    "        # print(classification_report(actual, preds))\n",
    "        acc.append(accuracy_score(actual, preds))\n",
    "\n",
    "print(f\"Accuracy over 10 rounds: {np.mean(acc)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0877744b127b3e06bbb46a4d58ff9f96d2144cab151d4d0cf00260a00e80ed7c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
